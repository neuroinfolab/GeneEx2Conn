{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98363b8f-1d61-429d-865a-3d8213cf3406",
   "metadata": {},
   "source": [
    "## VIDA Seminar Experiments Viz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83562164-b395-4948-85bd-0cc2a4d2c0e9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f908ee89-2a1f-4d33-b579-293af9abcb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b29dd74e-acf1-4701-bb72-ce3701d3d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e9b4435-baca-406a-b11b-c37e1c530d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from data import * \n",
    "from env import *\n",
    "from harmonize import *\n",
    "from sim import *\n",
    "from sim import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "566563ca-070f-4671-a98a-338fea600261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sim.plot' from '/scratch/asr655/neuroinformatics/GeneEx2Conn/sim/plot.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall imports\n",
    "import importlib\n",
    "import data\n",
    "\n",
    "# sim class\n",
    "# importlib.reload(sim)\n",
    "\n",
    "import sim.sim \n",
    "import sim.sim_utils\n",
    "from sim.sim_utils import bytes2human, print_system_usage\n",
    "from sim.sim import Simulation\n",
    "#importlib.reload(sim.sim_run)\n",
    "from sim.sim_run import single_sim_run, open_pickled_results\n",
    "importlib.reload(sim.sim)\n",
    "importlib.reload(sim.sim_utils)\n",
    "\n",
    "import sim.plot\n",
    "from sim.plot import (\n",
    "    plot_single_model_predictions_with_metrics,\n",
    "    plot_fold_performance,\n",
    "    plot_summary_measure_comparison, \n",
    "    compare_simulation_results,\n",
    "    get_sim_performance, \n",
    "    get_aggregate_performance\n",
    ")\n",
    "importlib.reload(sim.plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa8bad-5d12-46eb-a39f-18057f3923d7",
   "metadata": {},
   "source": [
    "#### Check job specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b7c8d67-a18c-4208-b20f-8ba13fd58e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage: 31.0%\n",
      "RAM Usage: 15.5%\n",
      "Available RAM: 318.5G\n",
      "Total RAM: 377.1G\n",
      "52.4G\n",
      "Number of available GPUs: 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not find an available GPU after 1 attempts with 900 seconds interval.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m GPUtil\u001b[38;5;241m.\u001b[39mgetGPUs()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of available GPUs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m DEVICE_ID_LIST \u001b[38;5;241m=\u001b[39m GPUtil\u001b[38;5;241m.\u001b[39mgetFirstAvailable()\n\u001b[1;32m     10\u001b[0m DEVICE_ID \u001b[38;5;241m=\u001b[39m DEVICE_ID_LIST[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# grab first element from list\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEVICE_ID \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m: \n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/GPUtil/GPUtil.py:203\u001b[0m, in \u001b[0;36mgetFirstAvailable\u001b[0;34m(order, maxLoad, maxMemory, attempts, interval, verbose, includeNan, excludeID, excludeUUID)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Check if an GPU was found, or if the attempts simply ran out. Throw error, if no GPU was found\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m(available)):\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find an available GPU after \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(attempts) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m attempts with \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(interval) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m seconds interval.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# Return found GPU\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m available\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not find an available GPU after 1 attempts with 900 seconds interval."
     ]
    }
   ],
   "source": [
    "print_system_usage()\n",
    "\n",
    "total = psutil.disk_usage('/').total\n",
    "print(bytes2human(total))\n",
    "\n",
    "GPUtil.getGPUs()\n",
    "print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "DEVICE_ID_LIST = GPUtil.getFirstAvailable()\n",
    "DEVICE_ID = DEVICE_ID_LIST[0] # grab first element from list\n",
    "if DEVICE_ID != None: \n",
    "    print('GPU found', DEVICE_ID)\n",
    "    use_gpu = True\n",
    "\n",
    "print(\"XGBoost version:\", xgboost.__version__)\n",
    "print(\"cupy version:\", cp.__version__)\n",
    "\n",
    "GPUtil.showUtilization()\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb4d65c",
   "metadata": {},
   "source": [
    "### Plots to create: \n",
    "- PLS, Ridge, XGBoost, MLP performance for structure with spectral embeddings and transcriptome\n",
    "(will have to add in bilinear later) for community splits \n",
    "- PLS, Ridge, XGBoost, MLP performance for combined structure with spectral embeddings and transcriptome for community splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42b0df04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/asr655/neuroinformatics/GeneEx2Conn/sim/sim_results/\n",
      "/scratch/asr655/neuroinformatics/GeneEx2Conn_backup/sim/sim_results/SFN_runs_mse/\n"
     ]
    }
   ],
   "source": [
    "feature_types = ['transcriptome', 'structural_spectralA_10']\n",
    "model_types = ['pls', 'ridge', 'xgboost', 'mlp']\n",
    "\n",
    "local_sim_path = os.getcwd() + '/sim/sim_results/'\n",
    "SFN_sim_path = os.path.join(os.path.dirname(os.getcwd()), 'GeneEx2Conn_backup/sim/sim_results/SFN_runs_mse/')\n",
    "print(local_sim_path)\n",
    "print(SFN_sim_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0f13f6",
   "metadata": {},
   "source": [
    "#### Model test performance \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "681105a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['structural_spectralA_-20_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_-60_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_10_FC_mlp_community101_42_grid_mse_search.pickle',\n",
       " 'transcriptome_FC_xgboost_random_2_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_-60_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'transcriptome_FC_mlp_community101_5_grid_mse_search.pickle',\n",
       " 'structural_spectralL_10_FC_ridge_random_42_grid_mse_search.pickle',\n",
       " 'structural_spectralL_3_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'transcriptome_SC_xgboost_community101_42_bayes_mse_search.pickle',\n",
       " 'transcriptome structural_spectralA_10_FC_mlp_community101_42_grid_mse_search.pickle',\n",
       " 'structural_spectralL_20_FC_ridge_random_42_grid_mse_search.pickle',\n",
       " 'transcriptome_mlp_community101_1_grid_pearsonsearch.pickle',\n",
       " 'transcriptome_mlp_random_42_grid_pearsonsearch.pickle',\n",
       " 'structural euclidean_SC_xgboost_random_2_bayes_pearson_search.pickle',\n",
       " 'structural_spectralA_110_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'transcriptomePCA structural_spectral_20_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural euclidean_SC_xgboost_community101_2_bayes_pearson_search.pickle',\n",
       " 'structural_spectralL_40_FC_ridge_random_42_grid_mse_search.pickle',\n",
       " 'structural_spectralL_5_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_5_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_SC_pls_community101_2_grid_pearson_search.pickle',\n",
       " 'transcriptome_FC_mlp_community101_2_grid_mse_search.pickle',\n",
       " 'structural_spectralL_100_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'transcriptome_FC_xgboost_community101_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_-100_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_-3_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'transcriptome_xgboost_random_1_bayessearch.pickle',\n",
       " 'structural_spectralL_10_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_-5_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'single_sim_results',\n",
       " 'transcriptome_FC_xgboost_random_42_bayes_pearson_search.pickle',\n",
       " '.ipynb_checkpoints',\n",
       " 'structural_spectralL_3_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_-40_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_60_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_SC_xgboost_community101_2_bayes_pearson_search.pickle',\n",
       " 'transcriptomePCA_xgboost_random_42_bayessearch.pickle',\n",
       " 'structural_spectralL_-100_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_10_FC_pls_community101_42_grid_mse_search.pickle',\n",
       " 'structural_spectralL_60_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_SC_mlp_community10_42_grid_pearson_search.pickle',\n",
       " 'structural_SC_ridge_random_2_grid_pearson_search.pickle',\n",
       " 'structural_spectralL_-3_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_10_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_-20_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'transcriptome structural_spectralA_10_FC_mlp_community101_2_grid_mse_search.pickle',\n",
       " 'structural_spectralA_10_FC_pls_community101_4_grid_mse_search.pickle',\n",
       " 'structural_spectralL_60_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'transcriptome structural_spectralA_10_FC_mlp_community101_4_grid_mse_search.pickle',\n",
       " 'structural_SC_xgboost_random_2_bayes_pearson_search.pickle',\n",
       " 'structural_spectralL_-10_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_100_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_20_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_-20_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_-10_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_40_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_3_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_10_FC_mlp_community101_4_grid_mse_search.pickle',\n",
       " 'transcriptome_SC_xgboost_random_42_bayes_pearson_search.pickle',\n",
       " 'structural_SC_xgboost_community101_2_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_-5_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'transcriptome_xgboost_random_42_bayessearch.pickle',\n",
       " 'transcriptome_FC_xgboost_community101_42_bayes_pearson_search.pickle',\n",
       " 'structural_SC_mlp_community10_42_grid_mse_search.pickle',\n",
       " 'transcriptome structural_spectral_20_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'transcriptome_FC_mlp_community101_1_grid_mse_search.pickle',\n",
       " 'structural_spectralL_3_FC_ridge_random_42_grid_mse_search.pickle',\n",
       " 'structural_spectralA_10_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_10_FC_ridge_community101_4_grid_mse_search.pickle',\n",
       " 'transcriptome_FC_mlp_community101_4_grid_mse_search.pickle',\n",
       " 'structural_spectralA_-10_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_100_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_40_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_3_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_-40_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_10_FC_ridge_community101_42_grid_mse_search.pickle',\n",
       " 'structural_spectralA_10_FC_ridge_community101_5_grid_mse_search.pickle',\n",
       " 'structural euclidean_SC_mlp_random_2_grid_pearson_search.pickle',\n",
       " 'structural_spectralA_10_FC_pls_community101_1_grid_mse_search.pickle',\n",
       " 'structural_spectralA_20_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_60_FC_ridge_random_42_grid_mse_search.pickle',\n",
       " 'structural_spectralA_10_FC_mlp_community101_1_grid_mse_search.pickle',\n",
       " 'transcriptome structural_spectralA_10_FC_mlp_community101_5_grid_mse_search.pickle',\n",
       " 'structural_spectralA_10_FC_ridge_community101_2_grid_mse_search.pickle',\n",
       " 'structural_spectralA_30_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_10_FC_mlp_community101_2_grid_mse_search.pickle',\n",
       " 'structural euclidean_SC_xgboost_community101_2_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_100_FC_ridge_random_42_grid_mse_search.pickle',\n",
       " 'structural_spectralA_40_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_-100_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_60_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_-60_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_100_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_10_FC_mlp_community101_5_grid_mse_search.pickle',\n",
       " 'transcriptome_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_10_FC_ridge_community101_1_grid_mse_search.pickle',\n",
       " 'structural_spectralA_10_FC_pls_community101_5_grid_mse_search.pickle',\n",
       " 'structural_spectralL_20_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_40_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_SC_ridge_community101_2_grid_pearson_search.pickle',\n",
       " 'structural_spectralL_-5_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_SC_pls_random_2_grid_pearson_search.pickle',\n",
       " 'structural_spectralA_20_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'transcriptome_SC_xgboost_community101_42_bayes_pearson_search.pickle',\n",
       " 'structural_spectralA_-40_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'transcriptome_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_10_FC_pls_community101_2_grid_mse_search.pickle',\n",
       " 'structural_spectralL_5_FC_ridge_random_42_grid_mse_search.pickle',\n",
       " 'transcriptome structural_spectralA_10_FC_mlp_community101_1_grid_mse_search.pickle',\n",
       " 'structural_spectralA_-2_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_10_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_5_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_5_SC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralL_-3_FC_xgboost_random_42_bayes_mse_search.pickle',\n",
       " 'structural_spectralA_2_SC_xgboost_random_42_bayes_mse_search.pickle']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(local_sim_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ef25a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Performance: 0.578 ± 0.043\n",
      "Test Performance: 0.616 ± 0.025\n"
     ]
    }
   ],
   "source": [
    "# Get performance stats for a single simulation\n",
    "stats = get_sim_performance(\n",
    "    feature_type='transcriptome structural_spectralA_10',\n",
    "    cv_type='community',\n",
    "    model_type='mlp',\n",
    "    #summary_measure='10',\n",
    "    resolution=1.01,\n",
    "    random_seed=5,\n",
    "    metric='pearson_corr'\n",
    ")\n",
    "\n",
    "if stats:\n",
    "    print(f\"Train Performance: {stats['train_mean']:.3f} ± {stats['train_stderr']:.3f}\")\n",
    "    print(f\"Test Performance: {stats['test_mean']:.3f} ± {stats['test_stderr']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c9a407",
   "metadata": {},
   "source": [
    "STILL TO RUN: \n",
    "- xgboost for structural spectralA [done]\n",
    "- ridge, pls, and xgboost for combined [running]\n",
    "- ridge, pls, xgboost for transcriptome alone [running]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6f0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get aggregate performance across multiple resolutions and seeds\n",
    "stats = get_aggregate_performance(\n",
    "    feature_type='structural_spectralA',\n",
    "    cv_type='community',\n",
    "    model_type='mlp',\n",
    "    resolutions=[1.01],\n",
    "    random_seeds=[1, 2, 4, 5, 42],\n",
    "    summary_measure='10',\n",
    "    metric='pearson_corr'\n",
    ")\n",
    "\n",
    "if stats:\n",
    "    print(f\"\\nAggregate Performance:\")\n",
    "    print(f\"Train: {stats['train_mean']:.3f} ± {stats['train_stderr']:.3f}\")\n",
    "    print(f\"Test:  {stats['test_mean']:.3f} ± {stats['test_stderr']:.3f}\")\n",
    "    print(f\"Based on {stats['n_runs']} successful runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f54a740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86f4712c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "648e8ab4",
   "metadata": {},
   "source": [
    "Genetics MLP runs for community splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744be82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolutions = [1.01]\n",
    "#seeds = [1, 2, 4, 5, 42]\n",
    "seeds = [42]\n",
    "\n",
    "for r in resolutions:\n",
    "    for s in seeds:\n",
    "        print('resolution', r)\n",
    "        print('seed', s)\n",
    "        single_sim_run(\n",
    "            cv_type='community',\n",
    "            random_seed=s,\n",
    "            resolution=r,\n",
    "            model_type='mlp',\n",
    "            feature_type=['transcriptome'],\n",
    "            use_gpu=True,\n",
    "            use_shared_regions=False,\n",
    "            test_shared_regions=False,\n",
    "            save_sim=True,\n",
    "            search_method=('grid', 'mse')\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa982a1",
   "metadata": {},
   "source": [
    "SpectralA MLP runs for community splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03074f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolution 1.01\n",
      "seed 1\n",
      "computing eig of laplacian\n",
      "computing eig of adjacency\n",
      "Number of components explaining 95.0% of the variance: 34\n",
      "\n",
      " Test fold num: 1\n",
      "(6320, 20) (6320,) (1122, 20) (1122,)\n",
      "SEARCH METHOD ('grid', 'mse')\n",
      "2\n",
      "3\n",
      "GPU model input size 20\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "Epoch [10/200], Loss: 0.0161\n",
      "Epoch [20/200], Loss: 0.0129\n",
      "Epoch [30/200], Loss: 0.0121\n",
      "Epoch [40/200], Loss: 0.0102\n",
      "Epoch [50/200], Loss: 0.0087\n",
      "Epoch [60/200], Loss: 0.0081\n",
      "Epoch [70/200], Loss: 0.0074\n",
      "Epoch [80/200], Loss: 0.0071\n",
      "Epoch [90/200], Loss: 0.0064\n",
      "Epoch [100/200], Loss: 0.0061\n",
      "Epoch [110/200], Loss: 0.0066\n",
      "Epoch [120/200], Loss: 0.0063\n",
      "Epoch [130/200], Loss: 0.0058\n",
      "Epoch [140/200], Loss: 0.0060\n",
      "Epoch [150/200], Loss: 0.0054\n",
      "Epoch [160/200], Loss: 0.0055\n",
      "Epoch [170/200], Loss: 0.0061\n",
      "Epoch [180/200], Loss: 0.0057\n",
      "Epoch [190/200], Loss: 0.0050\n",
      "Epoch [200/200], Loss: 0.0050\n",
      "[CV 1/2] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-204.837, test=-82.730) total time=  49.0s\n",
      "Epoch [10/200], Loss: 0.0134\n",
      "Epoch [20/200], Loss: 0.0097\n",
      "Epoch [30/200], Loss: 0.0073\n",
      "Epoch [40/200], Loss: 0.0070\n",
      "Epoch [50/200], Loss: 0.0071\n",
      "Epoch [60/200], Loss: 0.0057\n",
      "Epoch [70/200], Loss: 0.0055\n",
      "Epoch [80/200], Loss: 0.0049\n",
      "Epoch [90/200], Loss: 0.0046\n",
      "Epoch [100/200], Loss: 0.0045\n",
      "Epoch [110/200], Loss: 0.0048\n",
      "Epoch [120/200], Loss: 0.0038\n",
      "Epoch [130/200], Loss: 0.0037\n",
      "Epoch [140/200], Loss: 0.0040\n",
      "Epoch [150/200], Loss: 0.0036\n",
      "Epoch [160/200], Loss: 0.0035\n",
      "Epoch [170/200], Loss: 0.0037\n",
      "Epoch [180/200], Loss: 0.0034\n",
      "Epoch [190/200], Loss: 0.0030\n",
      "Epoch [200/200], Loss: 0.0029\n",
      "[CV 2/2] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-40.559, test=-166.868) total time=  12.2s\n",
      "Epoch [10/200], Loss: 0.0151\n",
      "Epoch [20/200], Loss: 0.0124\n",
      "Epoch [30/200], Loss: 0.0097\n",
      "Epoch [40/200], Loss: 0.0087\n",
      "Epoch [50/200], Loss: 0.0071\n",
      "Epoch [60/200], Loss: 0.0062\n",
      "Epoch [70/200], Loss: 0.0054\n",
      "Epoch [80/200], Loss: 0.0050\n",
      "Epoch [90/200], Loss: 0.0049\n",
      "Epoch [100/200], Loss: 0.0045\n",
      "Epoch [110/200], Loss: 0.0039\n",
      "Epoch [120/200], Loss: 0.0033\n",
      "Epoch [130/200], Loss: 0.0030\n",
      "Epoch [140/200], Loss: 0.0028\n",
      "Epoch [150/200], Loss: 0.0026\n",
      "Epoch [160/200], Loss: 0.0023\n",
      "Epoch [170/200], Loss: 0.0022\n",
      "Epoch [180/200], Loss: 0.0021\n",
      "Epoch [190/200], Loss: 0.0019\n",
      "Epoch [200/200], Loss: 0.0019\n",
      "[CV 1/2] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-177.707, test=-69.175) total time=  29.7s\n",
      "Epoch [10/200], Loss: 0.0158\n",
      "Epoch [20/200], Loss: 0.0104\n",
      "Epoch [30/200], Loss: 0.0078\n",
      "Epoch [40/200], Loss: 0.0068\n",
      "Epoch [50/200], Loss: 0.0061\n",
      "Epoch [60/200], Loss: 0.0056\n",
      "Epoch [70/200], Loss: 0.0052\n",
      "Epoch [80/200], Loss: 0.0048\n",
      "Epoch [90/200], Loss: 0.0044\n",
      "Epoch [100/200], Loss: 0.0042\n",
      "Epoch [110/200], Loss: 0.0031\n",
      "Epoch [120/200], Loss: 0.0034\n",
      "Epoch [130/200], Loss: 0.0032\n",
      "Epoch [140/200], Loss: 0.0031\n",
      "Epoch [150/200], Loss: 0.0029\n",
      "Epoch [160/200], Loss: 0.0027\n",
      "Epoch [170/200], Loss: 0.0028\n",
      "Epoch [180/200], Loss: 0.0025\n",
      "Epoch [190/200], Loss: 0.0023\n",
      "Epoch [200/200], Loss: 0.0022\n",
      "[CV 2/2] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-32.073, test=-130.678) total time=  11.9s\n",
      "Epoch [10/200], Loss: 0.0196\n",
      "Epoch [20/200], Loss: 0.0136\n",
      "Epoch [30/200], Loss: 0.0116\n",
      "Epoch [40/200], Loss: 0.0103\n",
      "Epoch [50/200], Loss: 0.0093\n",
      "Epoch [60/200], Loss: 0.0087\n",
      "Epoch [70/200], Loss: 0.0076\n",
      "Epoch [80/200], Loss: 0.0077\n",
      "Epoch [90/200], Loss: 0.0072\n",
      "Epoch [100/200], Loss: 0.0068\n",
      "Epoch [110/200], Loss: 0.0065\n",
      "Epoch [120/200], Loss: 0.0057\n",
      "Epoch [130/200], Loss: 0.0054\n",
      "Epoch [140/200], Loss: 0.0051\n",
      "Epoch [150/200], Loss: 0.0050\n",
      "Epoch [160/200], Loss: 0.0051\n",
      "Epoch [170/200], Loss: 0.0049\n",
      "Epoch [180/200], Loss: 0.0049\n",
      "Epoch [190/200], Loss: 0.0046\n",
      "Epoch [200/200], Loss: 0.0043\n",
      "[CV 1/2] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-140.540, test=-58.694) total time=  17.0s\n",
      "Epoch [10/200], Loss: 0.0194\n",
      "Epoch [20/200], Loss: 0.0129\n",
      "Epoch [30/200], Loss: 0.0100\n",
      "Epoch [40/200], Loss: 0.0089\n",
      "Epoch [50/200], Loss: 0.0068\n",
      "Epoch [60/200], Loss: 0.0057\n",
      "Epoch [70/200], Loss: 0.0055\n",
      "Epoch [80/200], Loss: 0.0060\n",
      "Epoch [90/200], Loss: 0.0049\n",
      "Epoch [100/200], Loss: 0.0052\n",
      "Epoch [110/200], Loss: 0.0047\n",
      "Epoch [120/200], Loss: 0.0042\n",
      "Epoch [130/200], Loss: 0.0045\n",
      "Epoch [140/200], Loss: 0.0041\n",
      "Epoch [150/200], Loss: 0.0037\n",
      "Epoch [160/200], Loss: 0.0039\n",
      "Epoch [170/200], Loss: 0.0035\n",
      "Epoch [180/200], Loss: 0.0044\n",
      "Epoch [190/200], Loss: 0.0038\n",
      "Epoch [200/200], Loss: 0.0037\n",
      "[CV 2/2] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-35.388, test=-187.282) total time=   6.8s\n",
      "Epoch [10/200], Loss: 0.0200\n",
      "Epoch [20/200], Loss: 0.0153\n",
      "Epoch [30/200], Loss: 0.0127\n",
      "Epoch [40/200], Loss: 0.0109\n",
      "Epoch [50/200], Loss: 0.0099\n",
      "Epoch [60/200], Loss: 0.0086\n",
      "Epoch [70/200], Loss: 0.0073\n",
      "Epoch [80/200], Loss: 0.0069\n",
      "Epoch [90/200], Loss: 0.0064\n",
      "Epoch [100/200], Loss: 0.0058\n",
      "Epoch [110/200], Loss: 0.0057\n",
      "Epoch [120/200], Loss: 0.0053\n",
      "Epoch [130/200], Loss: 0.0048\n",
      "Epoch [140/200], Loss: 0.0046\n",
      "Epoch [150/200], Loss: 0.0042\n",
      "Epoch [160/200], Loss: 0.0041\n",
      "Epoch [170/200], Loss: 0.0037\n",
      "Epoch [180/200], Loss: 0.0038\n",
      "Epoch [190/200], Loss: 0.0032\n",
      "Epoch [200/200], Loss: 0.0031\n",
      "[CV 1/2] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-169.458, test=-60.121) total time=  16.6s\n",
      "Epoch [10/200], Loss: 0.0185\n",
      "Epoch [20/200], Loss: 0.0117\n",
      "Epoch [30/200], Loss: 0.0091\n",
      "Epoch [40/200], Loss: 0.0078\n",
      "Epoch [50/200], Loss: 0.0065\n",
      "Epoch [60/200], Loss: 0.0066\n",
      "Epoch [70/200], Loss: 0.0048\n",
      "Epoch [80/200], Loss: 0.0048\n",
      "Epoch [90/200], Loss: 0.0045\n",
      "Epoch [100/200], Loss: 0.0043\n",
      "Epoch [110/200], Loss: 0.0039\n",
      "Epoch [120/200], Loss: 0.0039\n",
      "Epoch [130/200], Loss: 0.0035\n",
      "Epoch [140/200], Loss: 0.0032\n",
      "Epoch [150/200], Loss: 0.0033\n",
      "Epoch [160/200], Loss: 0.0032\n",
      "Epoch [170/200], Loss: 0.0033\n",
      "Epoch [180/200], Loss: 0.0031\n",
      "Epoch [190/200], Loss: 0.0026\n",
      "Epoch [200/200], Loss: 0.0026\n",
      "[CV 2/2] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-33.026, test=-203.055) total time=   6.7s\n",
      "\n",
      "Parameter Search CV Results:\n",
      "=============================\n",
      "Best Parameters:  {'batch_size': 32, 'epochs': 200, 'l2_reg': 0, 'lr': 0.001}\n",
      "Best Cross-Validation Score:  -99.92613084977819\n",
      "Epoch [10/200], Loss: 0.0199\n",
      "Epoch [20/200], Loss: 0.0152\n",
      "Epoch [30/200], Loss: 0.0120\n",
      "Epoch [40/200], Loss: 0.0100\n",
      "Epoch [50/200], Loss: 0.0088\n",
      "Epoch [60/200], Loss: 0.0079\n",
      "Epoch [70/200], Loss: 0.0070\n",
      "Epoch [80/200], Loss: 0.0064\n",
      "Epoch [90/200], Loss: 0.0060\n",
      "Epoch [100/200], Loss: 0.0054\n",
      "Epoch [110/200], Loss: 0.0052\n",
      "Epoch [120/200], Loss: 0.0050\n",
      "Epoch [130/200], Loss: 0.0047\n",
      "Epoch [140/200], Loss: 0.0046\n",
      "Epoch [150/200], Loss: 0.0044\n",
      "Epoch [160/200], Loss: 0.0042\n",
      "Epoch [170/200], Loss: 0.0039\n",
      "Epoch [180/200], Loss: 0.0037\n",
      "Epoch [190/200], Loss: 0.0038\n",
      "Epoch [200/200], Loss: 0.0039\n",
      "\n",
      "Train Metrics: {'mse': 0.09452880159558927, 'mae': 0.23167966467129003, 'r2': -8.762100871157623, 'pearson_corr': 0.5421459523444532, 'connectome_corr': 0.4198136736680921, 'connectome_r2': -9.249792341986183, 'geodesic_distance': 11.33065465930805}\n",
      "Test Metrics: {'mse': 0.09099141965898727, 'mae': 0.23320510854183762, 'r2': -5.326996589749477, 'pearson_corr': 0.37075214711708704, 'connectome_corr': 0.34454045755251655, 'connectome_r2': -7.1043295520187675, 'geodesic_distance': 7.1184683676308245}\n",
      "BEST VAL SCORE -99.92613084977819\n",
      "BEST MODEL PARAMS {'batch_size': 32, 'dropout': 0.05, 'epochs': 200, 'hidden_dims': [128, 64], 'input_dim': 20, 'l2_reg': 0, 'lr': 0.001, 'max_grad_norm': 1.0, 'output_dim': 1}\n",
      "CPU Usage: 16.9%\n",
      "RAM Usage: 20.1%\n",
      "Available RAM: 804.9G\n",
      "Total RAM: 1007.0G\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  1% |\n",
      "\n",
      " Test fold num: 2\n",
      "(6806, 20) (6806,) (930, 20) (930,)\n",
      "SEARCH METHOD ('grid', 'mse')\n",
      "1\n",
      "3\n",
      "GPU model input size 20\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "Epoch [10/200], Loss: 0.0153\n",
      "Epoch [20/200], Loss: 0.0125\n",
      "Epoch [30/200], Loss: 0.0114\n",
      "Epoch [40/200], Loss: 0.0098\n",
      "Epoch [50/200], Loss: 0.0083\n",
      "Epoch [60/200], Loss: 0.0078\n",
      "Epoch [70/200], Loss: 0.0069\n",
      "Epoch [80/200], Loss: 0.0064\n",
      "Epoch [90/200], Loss: 0.0066\n",
      "Epoch [100/200], Loss: 0.0058\n",
      "Epoch [110/200], Loss: 0.0060\n",
      "Epoch [120/200], Loss: 0.0054\n",
      "Epoch [130/200], Loss: 0.0059\n",
      "Epoch [140/200], Loss: 0.0055\n",
      "Epoch [150/200], Loss: 0.0052\n",
      "Epoch [160/200], Loss: 0.0053\n",
      "Epoch [170/200], Loss: 0.0055\n",
      "Epoch [180/200], Loss: 0.0052\n",
      "Epoch [190/200], Loss: 0.0048\n",
      "Epoch [200/200], Loss: 0.0051\n",
      "[CV 1/2] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-220.812, test=-163.939) total time=  30.1s\n",
      "Epoch [10/200], Loss: 0.0261\n",
      "Epoch [20/200], Loss: 0.0217\n",
      "Epoch [30/200], Loss: 0.0209\n",
      "Epoch [40/200], Loss: 0.0203\n",
      "Epoch [50/200], Loss: 0.0189\n",
      "Epoch [60/200], Loss: 0.0183\n",
      "Epoch [70/200], Loss: 0.0183\n",
      "Epoch [80/200], Loss: 0.0162\n",
      "Epoch [90/200], Loss: 0.0166\n",
      "Epoch [100/200], Loss: 0.0158\n",
      "Epoch [110/200], Loss: 0.0142\n",
      "Epoch [120/200], Loss: 0.0163\n",
      "Epoch [130/200], Loss: 0.0148\n",
      "Epoch [140/200], Loss: 0.0128\n",
      "Epoch [150/200], Loss: 0.0122\n",
      "Epoch [160/200], Loss: 0.0124\n",
      "Epoch [170/200], Loss: 0.0125\n",
      "Epoch [180/200], Loss: 0.0115\n",
      "Epoch [190/200], Loss: 0.0094\n",
      "Epoch [200/200], Loss: 0.0092\n",
      "[CV 2/2] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-94.269, test=-195.116) total time=  14.8s\n",
      "Epoch [10/200], Loss: 0.0159\n",
      "Epoch [20/200], Loss: 0.0119\n",
      "Epoch [30/200], Loss: 0.0100\n",
      "Epoch [40/200], Loss: 0.0087\n",
      "Epoch [50/200], Loss: 0.0071\n",
      "Epoch [60/200], Loss: 0.0061\n",
      "Epoch [70/200], Loss: 0.0055\n",
      "Epoch [80/200], Loss: 0.0054\n",
      "Epoch [90/200], Loss: 0.0049\n",
      "Epoch [100/200], Loss: 0.0044\n",
      "Epoch [110/200], Loss: 0.0042\n",
      "Epoch [120/200], Loss: 0.0037\n",
      "Epoch [130/200], Loss: 0.0034\n",
      "Epoch [140/200], Loss: 0.0030\n",
      "Epoch [150/200], Loss: 0.0027\n",
      "Epoch [160/200], Loss: 0.0026\n",
      "Epoch [170/200], Loss: 0.0024\n",
      "Epoch [180/200], Loss: 0.0021\n",
      "Epoch [190/200], Loss: 0.0020\n",
      "Epoch [200/200], Loss: 0.0020\n",
      "[CV 1/2] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-152.739, test=-176.547) total time=  29.6s\n",
      "Epoch [10/200], Loss: 0.0282\n",
      "Epoch [20/200], Loss: 0.0214\n",
      "Epoch [30/200], Loss: 0.0208\n",
      "Epoch [40/200], Loss: 0.0224\n",
      "Epoch [50/200], Loss: 0.0195\n",
      "Epoch [60/200], Loss: 0.0203\n",
      "Epoch [70/200], Loss: 0.0177\n",
      "Epoch [80/200], Loss: 0.0153\n",
      "Epoch [90/200], Loss: 0.0158\n",
      "Epoch [100/200], Loss: 0.0151\n",
      "Epoch [110/200], Loss: 0.0144\n",
      "Epoch [120/200], Loss: 0.0145\n",
      "Epoch [130/200], Loss: 0.0137\n",
      "Epoch [140/200], Loss: 0.0146\n",
      "Epoch [150/200], Loss: 0.0121\n",
      "Epoch [160/200], Loss: 0.0114\n",
      "Epoch [170/200], Loss: 0.0111\n",
      "Epoch [180/200], Loss: 0.0118\n",
      "Epoch [190/200], Loss: 0.0114\n",
      "Epoch [200/200], Loss: 0.0102\n",
      "[CV 2/2] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-101.800, test=-213.203) total time=  14.5s\n",
      "Epoch [10/200], Loss: 0.0198\n",
      "Epoch [20/200], Loss: 0.0143\n",
      "Epoch [30/200], Loss: 0.0117\n",
      "Epoch [40/200], Loss: 0.0107\n",
      "Epoch [50/200], Loss: 0.0089\n",
      "Epoch [60/200], Loss: 0.0089\n",
      "Epoch [70/200], Loss: 0.0077\n",
      "Epoch [80/200], Loss: 0.0073\n",
      "Epoch [90/200], Loss: 0.0076\n",
      "Epoch [100/200], Loss: 0.0064\n",
      "Epoch [110/200], Loss: 0.0059\n",
      "Epoch [120/200], Loss: 0.0055\n",
      "Epoch [130/200], Loss: 0.0058\n",
      "Epoch [140/200], Loss: 0.0058\n",
      "Epoch [150/200], Loss: 0.0051\n",
      "Epoch [160/200], Loss: 0.0051\n",
      "Epoch [170/200], Loss: 0.0051\n",
      "Epoch [180/200], Loss: 0.0045\n",
      "Epoch [190/200], Loss: 0.0045\n",
      "Epoch [200/200], Loss: 0.0038\n",
      "[CV 1/2] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-157.550, test=-199.348) total time=  16.8s\n",
      "Epoch [10/200], Loss: 0.0228\n",
      "Epoch [20/200], Loss: 0.0186\n",
      "Epoch [30/200], Loss: 0.0177\n",
      "Epoch [40/200], Loss: 0.0138\n",
      "Epoch [50/200], Loss: 0.0127\n",
      "Epoch [60/200], Loss: 0.0132\n",
      "Epoch [70/200], Loss: 0.0134\n",
      "Epoch [80/200], Loss: 0.0123\n",
      "Epoch [90/200], Loss: 0.0129\n",
      "Epoch [100/200], Loss: 0.0118\n",
      "Epoch [110/200], Loss: 0.0098\n",
      "Epoch [120/200], Loss: 0.0129\n",
      "Epoch [130/200], Loss: 0.0095\n",
      "Epoch [140/200], Loss: 0.0116\n",
      "Epoch [150/200], Loss: 0.0114\n",
      "Epoch [160/200], Loss: 0.0111\n",
      "Epoch [170/200], Loss: 0.0093\n",
      "Epoch [180/200], Loss: 0.0100\n",
      "Epoch [190/200], Loss: 0.0102\n",
      "Epoch [200/200], Loss: 0.0109\n",
      "[CV 2/2] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-105.330, test=-226.329) total time=   8.5s\n",
      "Epoch [10/200], Loss: 0.0205\n",
      "Epoch [20/200], Loss: 0.0151\n",
      "Epoch [30/200], Loss: 0.0128\n",
      "Epoch [40/200], Loss: 0.0102\n",
      "Epoch [50/200], Loss: 0.0088\n",
      "Epoch [60/200], Loss: 0.0079\n",
      "Epoch [70/200], Loss: 0.0068\n",
      "Epoch [80/200], Loss: 0.0059\n",
      "Epoch [90/200], Loss: 0.0057\n",
      "Epoch [100/200], Loss: 0.0054\n",
      "Epoch [110/200], Loss: 0.0048\n",
      "Epoch [120/200], Loss: 0.0044\n",
      "Epoch [130/200], Loss: 0.0044\n",
      "Epoch [140/200], Loss: 0.0041\n",
      "Epoch [150/200], Loss: 0.0040\n",
      "Epoch [160/200], Loss: 0.0036\n",
      "Epoch [170/200], Loss: 0.0038\n",
      "Epoch [180/200], Loss: 0.0037\n",
      "Epoch [190/200], Loss: 0.0032\n",
      "Epoch [200/200], Loss: 0.0030\n",
      "[CV 1/2] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-153.866, test=-193.566) total time=  16.7s\n",
      "Epoch [10/200], Loss: 0.0234\n",
      "Epoch [20/200], Loss: 0.0178\n",
      "Epoch [30/200], Loss: 0.0156\n",
      "Epoch [40/200], Loss: 0.0143\n",
      "Epoch [50/200], Loss: 0.0126\n",
      "Epoch [60/200], Loss: 0.0123\n",
      "Epoch [70/200], Loss: 0.0115\n",
      "Epoch [80/200], Loss: 0.0105\n",
      "Epoch [90/200], Loss: 0.0112\n",
      "Epoch [100/200], Loss: 0.0100\n",
      "Epoch [110/200], Loss: 0.0108\n",
      "Epoch [120/200], Loss: 0.0097\n",
      "Epoch [130/200], Loss: 0.0089\n",
      "Epoch [140/200], Loss: 0.0099\n",
      "Epoch [150/200], Loss: 0.0086\n",
      "Epoch [160/200], Loss: 0.0090\n",
      "Epoch [170/200], Loss: 0.0085\n",
      "Epoch [180/200], Loss: 0.0095\n",
      "Epoch [190/200], Loss: 0.0086\n",
      "Epoch [200/200], Loss: 0.0082\n",
      "[CV 2/2] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-108.162, test=-233.966) total time=   7.9s\n",
      "\n",
      "Parameter Search CV Results:\n",
      "=============================\n",
      "Best Parameters:  {'batch_size': 32, 'epochs': 200, 'l2_reg': 0.001, 'lr': 0.001}\n",
      "Best Cross-Validation Score:  -179.52745595463892\n",
      "Epoch [10/200], Loss: 0.0198\n",
      "Epoch [20/200], Loss: 0.0162\n",
      "Epoch [30/200], Loss: 0.0136\n",
      "Epoch [40/200], Loss: 0.0120\n",
      "Epoch [50/200], Loss: 0.0113\n",
      "Epoch [60/200], Loss: 0.0113\n",
      "Epoch [70/200], Loss: 0.0112\n",
      "Epoch [80/200], Loss: 0.0111\n",
      "Epoch [90/200], Loss: 0.0109\n",
      "Epoch [100/200], Loss: 0.0109\n",
      "Epoch [110/200], Loss: 0.0106\n",
      "Epoch [120/200], Loss: 0.0107\n",
      "Epoch [130/200], Loss: 0.0104\n",
      "Epoch [140/200], Loss: 0.0102\n",
      "Epoch [150/200], Loss: 0.0104\n",
      "Epoch [160/200], Loss: 0.0104\n",
      "Epoch [170/200], Loss: 0.0103\n",
      "Epoch [180/200], Loss: 0.0105\n",
      "Epoch [190/200], Loss: 0.0102\n",
      "Epoch [200/200], Loss: 0.0102\n",
      "\n",
      "Train Metrics: {'mse': 0.03423951455027102, 'mae': 0.1393107606215425, 'r2': -6.378173233090557, 'pearson_corr': 0.47957617642770806, 'connectome_corr': 0.41244937079934235, 'connectome_r2': -6.795799126787356, 'geodesic_distance': 11.7993283085162}\n",
      "Test Metrics: {'mse': 0.03081292535304503, 'mae': 0.13493168012744558, 'r2': -0.33643890739869586, 'pearson_corr': 0.3928672287841235, 'connectome_corr': 0.14773593272390714, 'connectome_r2': -1.0103679883338657, 'geodesic_distance': 5.655366578025195}\n",
      "BEST VAL SCORE -179.52745595463892\n",
      "BEST MODEL PARAMS {'batch_size': 32, 'dropout': 0.05, 'epochs': 200, 'hidden_dims': [128, 64], 'input_dim': 20, 'l2_reg': 0.001, 'lr': 0.001, 'max_grad_norm': 1.0, 'output_dim': 1}\n",
      "CPU Usage: 16.7%\n",
      "RAM Usage: 20.4%\n",
      "Available RAM: 801.3G\n",
      "Total RAM: 1007.0G\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  1% |\n",
      "\n",
      " Test fold num: 3\n",
      "(4160, 20) (4160,) (2352, 20) (2352,)\n",
      "SEARCH METHOD ('grid', 'mse')\n",
      "1\n",
      "2\n",
      "GPU model input size 20\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "Epoch [10/200], Loss: 0.0159\n",
      "Epoch [20/200], Loss: 0.0106\n",
      "Epoch [30/200], Loss: 0.0087\n",
      "Epoch [40/200], Loss: 0.0074\n",
      "Epoch [50/200], Loss: 0.0072\n",
      "Epoch [60/200], Loss: 0.0062\n",
      "Epoch [70/200], Loss: 0.0059\n",
      "Epoch [80/200], Loss: 0.0054\n",
      "Epoch [90/200], Loss: 0.0062\n",
      "Epoch [100/200], Loss: 0.0052\n",
      "Epoch [110/200], Loss: 0.0047\n",
      "Epoch [120/200], Loss: 0.0040\n",
      "Epoch [130/200], Loss: 0.0046\n",
      "Epoch [140/200], Loss: 0.0037\n",
      "Epoch [150/200], Loss: 0.0038\n",
      "Epoch [160/200], Loss: 0.0048\n",
      "Epoch [170/200], Loss: 0.0042\n",
      "Epoch [180/200], Loss: 0.0037\n",
      "Epoch [190/200], Loss: 0.0030\n",
      "Epoch [200/200], Loss: 0.0038\n",
      "[CV 1/2] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-37.828, test=-95.261) total time=  12.3s\n",
      "Epoch [10/200], Loss: 0.0296\n",
      "Epoch [20/200], Loss: 0.0239\n",
      "Epoch [30/200], Loss: 0.0207\n",
      "Epoch [40/200], Loss: 0.0179\n",
      "Epoch [50/200], Loss: 0.0181\n",
      "Epoch [60/200], Loss: 0.0177\n",
      "Epoch [70/200], Loss: 0.0175\n",
      "Epoch [80/200], Loss: 0.0170\n",
      "Epoch [90/200], Loss: 0.0162\n",
      "Epoch [100/200], Loss: 0.0164\n",
      "Epoch [110/200], Loss: 0.0165\n",
      "Epoch [120/200], Loss: 0.0153\n",
      "Epoch [130/200], Loss: 0.0151\n",
      "Epoch [140/200], Loss: 0.0159\n",
      "Epoch [150/200], Loss: 0.0129\n",
      "Epoch [160/200], Loss: 0.0121\n",
      "Epoch [170/200], Loss: 0.0131\n",
      "Epoch [180/200], Loss: 0.0121\n",
      "Epoch [190/200], Loss: 0.0111\n",
      "Epoch [200/200], Loss: 0.0099\n",
      "[CV 2/2] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-101.159, test=-30.348) total time=  14.7s\n",
      "Epoch [10/200], Loss: 0.0167\n",
      "Epoch [20/200], Loss: 0.0106\n",
      "Epoch [30/200], Loss: 0.0090\n",
      "Epoch [40/200], Loss: 0.0079\n",
      "Epoch [50/200], Loss: 0.0066\n",
      "Epoch [60/200], Loss: 0.0065\n",
      "Epoch [70/200], Loss: 0.0053\n",
      "Epoch [80/200], Loss: 0.0053\n",
      "Epoch [90/200], Loss: 0.0040\n",
      "Epoch [100/200], Loss: 0.0045\n",
      "Epoch [110/200], Loss: 0.0038\n",
      "Epoch [120/200], Loss: 0.0038\n",
      "Epoch [130/200], Loss: 0.0036\n",
      "Epoch [140/200], Loss: 0.0036\n",
      "Epoch [150/200], Loss: 0.0030\n",
      "Epoch [160/200], Loss: 0.0034\n",
      "Epoch [170/200], Loss: 0.0029\n",
      "Epoch [180/200], Loss: 0.0025\n",
      "Epoch [190/200], Loss: 0.0026\n",
      "Epoch [200/200], Loss: 0.0023\n",
      "[CV 1/2] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-31.538, test=-79.453) total time=  11.9s\n",
      "Epoch [10/200], Loss: 0.0298\n",
      "Epoch [20/200], Loss: 0.0230\n",
      "Epoch [30/200], Loss: 0.0218\n",
      "Epoch [40/200], Loss: 0.0193\n",
      "Epoch [50/200], Loss: 0.0182\n",
      "Epoch [60/200], Loss: 0.0185\n",
      "Epoch [70/200], Loss: 0.0169\n",
      "Epoch [80/200], Loss: 0.0154\n",
      "Epoch [90/200], Loss: 0.0146\n",
      "Epoch [100/200], Loss: 0.0135\n",
      "Epoch [110/200], Loss: 0.0150\n",
      "Epoch [120/200], Loss: 0.0147\n",
      "Epoch [130/200], Loss: 0.0122\n",
      "Epoch [140/200], Loss: 0.0131\n",
      "Epoch [150/200], Loss: 0.0108\n",
      "Epoch [160/200], Loss: 0.0103\n",
      "Epoch [170/200], Loss: 0.0093\n",
      "Epoch [180/200], Loss: 0.0089\n",
      "Epoch [190/200], Loss: 0.0093\n",
      "Epoch [200/200], Loss: 0.0074\n",
      "[CV 2/2] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-98.402, test=-42.907) total time=  14.8s\n",
      "Epoch [10/200], Loss: 0.0173\n",
      "Epoch [20/200], Loss: 0.0113\n",
      "Epoch [30/200], Loss: 0.0093\n",
      "Epoch [40/200], Loss: 0.0073\n",
      "Epoch [50/200], Loss: 0.0061\n",
      "Epoch [60/200], Loss: 0.0052\n",
      "Epoch [70/200], Loss: 0.0054\n",
      "Epoch [80/200], Loss: 0.0051\n",
      "Epoch [90/200], Loss: 0.0052\n",
      "Epoch [100/200], Loss: 0.0044\n",
      "Epoch [110/200], Loss: 0.0040\n",
      "Epoch [120/200], Loss: 0.0038\n",
      "Epoch [130/200], Loss: 0.0041\n",
      "Epoch [140/200], Loss: 0.0034\n",
      "Epoch [150/200], Loss: 0.0039\n",
      "Epoch [160/200], Loss: 0.0037\n",
      "Epoch [170/200], Loss: 0.0036\n",
      "Epoch [180/200], Loss: 0.0038\n",
      "Epoch [190/200], Loss: 0.0030\n",
      "Epoch [200/200], Loss: 0.0029\n",
      "[CV 1/2] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-33.347, test=-74.901) total time=   6.9s\n",
      "Epoch [10/200], Loss: 0.0230\n",
      "Epoch [20/200], Loss: 0.0187\n",
      "Epoch [30/200], Loss: 0.0166\n",
      "Epoch [40/200], Loss: 0.0137\n",
      "Epoch [50/200], Loss: 0.0133\n",
      "Epoch [60/200], Loss: 0.0125\n",
      "Epoch [70/200], Loss: 0.0132\n",
      "Epoch [80/200], Loss: 0.0127\n",
      "Epoch [90/200], Loss: 0.0120\n",
      "Epoch [100/200], Loss: 0.0122\n",
      "Epoch [110/200], Loss: 0.0116\n",
      "Epoch [120/200], Loss: 0.0110\n",
      "Epoch [130/200], Loss: 0.0107\n",
      "Epoch [140/200], Loss: 0.0131\n",
      "Epoch [150/200], Loss: 0.0112\n",
      "Epoch [160/200], Loss: 0.0117\n",
      "Epoch [170/200], Loss: 0.0120\n",
      "Epoch [180/200], Loss: 0.0104\n",
      "Epoch [190/200], Loss: 0.0113\n",
      "Epoch [200/200], Loss: 0.0105\n",
      "[CV 2/2] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-121.332, test=-47.990) total time=   8.3s\n",
      "Epoch [10/200], Loss: 0.0178\n",
      "Epoch [20/200], Loss: 0.0125\n",
      "Epoch [30/200], Loss: 0.0097\n",
      "Epoch [40/200], Loss: 0.0082\n",
      "Epoch [50/200], Loss: 0.0069\n",
      "Epoch [60/200], Loss: 0.0056\n",
      "Epoch [70/200], Loss: 0.0053\n",
      "Epoch [80/200], Loss: 0.0048\n",
      "Epoch [90/200], Loss: 0.0044\n",
      "Epoch [100/200], Loss: 0.0048\n",
      "Epoch [110/200], Loss: 0.0039\n",
      "Epoch [120/200], Loss: 0.0039\n",
      "Epoch [130/200], Loss: 0.0037\n",
      "Epoch [140/200], Loss: 0.0032\n",
      "Epoch [150/200], Loss: 0.0030\n",
      "Epoch [160/200], Loss: 0.0032\n",
      "Epoch [170/200], Loss: 0.0031\n",
      "Epoch [180/200], Loss: 0.0031\n",
      "Epoch [190/200], Loss: 0.0027\n",
      "Epoch [200/200], Loss: 0.0027\n",
      "[CV 1/2] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-30.393, test=-74.672) total time=   6.7s\n",
      "Epoch [10/200], Loss: 0.0234\n",
      "Epoch [20/200], Loss: 0.0182\n",
      "Epoch [30/200], Loss: 0.0155\n",
      "Epoch [40/200], Loss: 0.0141\n",
      "Epoch [50/200], Loss: 0.0136\n",
      "Epoch [60/200], Loss: 0.0124\n",
      "Epoch [70/200], Loss: 0.0110\n",
      "Epoch [80/200], Loss: 0.0113\n",
      "Epoch [90/200], Loss: 0.0108\n",
      "Epoch [100/200], Loss: 0.0112\n",
      "Epoch [110/200], Loss: 0.0100\n",
      "Epoch [120/200], Loss: 0.0099\n",
      "Epoch [130/200], Loss: 0.0094\n",
      "Epoch [140/200], Loss: 0.0095\n",
      "Epoch [150/200], Loss: 0.0097\n",
      "Epoch [160/200], Loss: 0.0090\n",
      "Epoch [170/200], Loss: 0.0084\n",
      "Epoch [180/200], Loss: 0.0082\n",
      "Epoch [190/200], Loss: 0.0080\n",
      "Epoch [200/200], Loss: 0.0084\n",
      "[CV 2/2] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-111.639, test=-33.048) total time=   8.3s\n",
      "\n",
      "Parameter Search CV Results:\n",
      "=============================\n",
      "Best Parameters:  {'batch_size': 64, 'epochs': 200, 'l2_reg': 0, 'lr': 0.001}\n",
      "Best Cross-Validation Score:  -53.86007722771275\n",
      "Epoch [10/200], Loss: 0.0187\n",
      "Epoch [20/200], Loss: 0.0151\n",
      "Epoch [30/200], Loss: 0.0134\n",
      "Epoch [40/200], Loss: 0.0117\n",
      "Epoch [50/200], Loss: 0.0108\n",
      "Epoch [60/200], Loss: 0.0099\n",
      "Epoch [70/200], Loss: 0.0092\n",
      "Epoch [80/200], Loss: 0.0086\n",
      "Epoch [90/200], Loss: 0.0083\n",
      "Epoch [100/200], Loss: 0.0077\n",
      "Epoch [110/200], Loss: 0.0064\n",
      "Epoch [120/200], Loss: 0.0056\n",
      "Epoch [130/200], Loss: 0.0054\n",
      "Epoch [140/200], Loss: 0.0052\n",
      "Epoch [150/200], Loss: 0.0049\n",
      "Epoch [160/200], Loss: 0.0048\n",
      "Epoch [170/200], Loss: 0.0042\n",
      "Epoch [180/200], Loss: 0.0043\n",
      "Epoch [190/200], Loss: 0.0040\n",
      "Epoch [200/200], Loss: 0.0038\n",
      "\n",
      "Train Metrics: {'mse': 0.014289899025654045, 'mae': 0.08834126423952898, 'r2': 0.274121493636933, 'pearson_corr': 0.7853088811857438, 'connectome_corr': 0.725237247528959, 'connectome_r2': 0.19934079377140393, 'geodesic_distance': 8.126920785551308}\n",
      "Test Metrics: {'mse': 0.047791018178404726, 'mae': 0.1810666654907653, 'r2': -17.607775835517938, 'pearson_corr': 0.4126603318371562, 'connectome_corr': 0.4130371809518307, 'connectome_r2': -19.21168787054723, 'geodesic_distance': 8.455973741529125}\n",
      "BEST VAL SCORE -53.86007722771275\n",
      "BEST MODEL PARAMS {'batch_size': 64, 'dropout': 0.05, 'epochs': 200, 'hidden_dims': [128, 64], 'input_dim': 20, 'l2_reg': 0, 'lr': 0.001, 'max_grad_norm': 1.0, 'output_dim': 1}\n",
      "CPU Usage: 16.5%\n",
      "RAM Usage: 20.3%\n",
      "Available RAM: 802.7G\n",
      "Total RAM: 1007.0G\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  1% |\n",
      "Simulation results have been saved.\n",
      "resolution 1.01\n",
      "seed 2\n",
      "computing eig of laplacian\n",
      "computing eig of adjacency\n",
      "Number of components explaining 95.0% of the variance: 34\n",
      "\n",
      " Test fold num: 1\n",
      "(8930, 20) (8930,) (342, 20) (342,)\n",
      "SEARCH METHOD ('grid', 'mse')\n",
      "2\n",
      "3\n",
      "4\n",
      "GPU model input size 20\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Epoch [10/200], Loss: 0.0215\n",
      "Epoch [20/200], Loss: 0.0182\n",
      "Epoch [30/200], Loss: 0.0160\n",
      "Epoch [40/200], Loss: 0.0138\n",
      "Epoch [50/200], Loss: 0.0113\n",
      "Epoch [60/200], Loss: 0.0102\n",
      "Epoch [70/200], Loss: 0.0085\n",
      "Epoch [80/200], Loss: 0.0082\n",
      "Epoch [90/200], Loss: 0.0075\n",
      "Epoch [100/200], Loss: 0.0070\n",
      "Epoch [110/200], Loss: 0.0070\n",
      "Epoch [120/200], Loss: 0.0067\n",
      "Epoch [130/200], Loss: 0.0066\n",
      "Epoch [140/200], Loss: 0.0064\n",
      "Epoch [150/200], Loss: 0.0065\n",
      "Epoch [160/200], Loss: 0.0057\n",
      "Epoch [170/200], Loss: 0.0060\n",
      "Epoch [180/200], Loss: 0.0056\n",
      "Epoch [190/200], Loss: 0.0058\n",
      "Epoch [200/200], Loss: 0.0055\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-134.847, test=-163.621) total time=  27.1s\n",
      "Epoch [10/200], Loss: 0.0256\n",
      "Epoch [20/200], Loss: 0.0187\n",
      "Epoch [30/200], Loss: 0.0156\n",
      "Epoch [40/200], Loss: 0.0142\n",
      "Epoch [50/200], Loss: 0.0133\n",
      "Epoch [60/200], Loss: 0.0125\n",
      "Epoch [70/200], Loss: 0.0116\n",
      "Epoch [80/200], Loss: 0.0119\n",
      "Epoch [90/200], Loss: 0.0117\n",
      "Epoch [100/200], Loss: 0.0114\n",
      "Epoch [110/200], Loss: 0.0113\n",
      "Epoch [120/200], Loss: 0.0111\n",
      "Epoch [130/200], Loss: 0.0113\n",
      "Epoch [140/200], Loss: 0.0111\n",
      "Epoch [150/200], Loss: 0.0113\n",
      "Epoch [160/200], Loss: 0.0114\n",
      "Epoch [170/200], Loss: 0.0105\n",
      "Epoch [180/200], Loss: 0.0106\n",
      "Epoch [190/200], Loss: 0.0101\n",
      "Epoch [200/200], Loss: 0.0106\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-417.019, test=-36.646) total time= 1.2min\n",
      "Epoch [10/200], Loss: 0.0211\n",
      "Epoch [20/200], Loss: 0.0166\n",
      "Epoch [30/200], Loss: 0.0131\n",
      "Epoch [40/200], Loss: 0.0112\n",
      "Epoch [50/200], Loss: 0.0107\n",
      "Epoch [60/200], Loss: 0.0093\n",
      "Epoch [70/200], Loss: 0.0090\n",
      "Epoch [80/200], Loss: 0.0084\n",
      "Epoch [90/200], Loss: 0.0084\n",
      "Epoch [100/200], Loss: 0.0080\n",
      "Epoch [110/200], Loss: 0.0078\n",
      "Epoch [120/200], Loss: 0.0076\n",
      "Epoch [130/200], Loss: 0.0075\n",
      "Epoch [140/200], Loss: 0.0083\n",
      "Epoch [150/200], Loss: 0.0076\n",
      "Epoch [160/200], Loss: 0.0080\n",
      "Epoch [170/200], Loss: 0.0075\n",
      "Epoch [180/200], Loss: 0.0083\n",
      "Epoch [190/200], Loss: 0.0080\n",
      "Epoch [200/200], Loss: 0.0073\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-449.067, test=-37.293) total time=  59.2s\n",
      "Epoch [10/200], Loss: 0.0214\n",
      "Epoch [20/200], Loss: 0.0164\n",
      "Epoch [30/200], Loss: 0.0139\n",
      "Epoch [40/200], Loss: 0.0122\n",
      "Epoch [50/200], Loss: 0.0104\n",
      "Epoch [60/200], Loss: 0.0091\n",
      "Epoch [70/200], Loss: 0.0077\n",
      "Epoch [80/200], Loss: 0.0065\n",
      "Epoch [90/200], Loss: 0.0057\n",
      "Epoch [100/200], Loss: 0.0048\n",
      "Epoch [110/200], Loss: 0.0041\n",
      "Epoch [120/200], Loss: 0.0042\n",
      "Epoch [130/200], Loss: 0.0037\n",
      "Epoch [140/200], Loss: 0.0034\n",
      "Epoch [150/200], Loss: 0.0033\n",
      "Epoch [160/200], Loss: 0.0032\n",
      "Epoch [170/200], Loss: 0.0029\n",
      "Epoch [180/200], Loss: 0.0029\n",
      "Epoch [190/200], Loss: 0.0025\n",
      "Epoch [200/200], Loss: 0.0025\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-148.145, test=-133.262) total time=  26.6s\n",
      "Epoch [10/200], Loss: 0.0249\n",
      "Epoch [20/200], Loss: 0.0165\n",
      "Epoch [30/200], Loss: 0.0117\n",
      "Epoch [40/200], Loss: 0.0089\n",
      "Epoch [50/200], Loss: 0.0075\n",
      "Epoch [60/200], Loss: 0.0067\n",
      "Epoch [70/200], Loss: 0.0060\n",
      "Epoch [80/200], Loss: 0.0056\n",
      "Epoch [90/200], Loss: 0.0049\n",
      "Epoch [100/200], Loss: 0.0046\n",
      "Epoch [110/200], Loss: 0.0044\n",
      "Epoch [120/200], Loss: 0.0043\n",
      "Epoch [130/200], Loss: 0.0040\n",
      "Epoch [140/200], Loss: 0.0040\n",
      "Epoch [150/200], Loss: 0.0039\n",
      "Epoch [160/200], Loss: 0.0037\n",
      "Epoch [170/200], Loss: 0.0035\n",
      "Epoch [180/200], Loss: 0.0037\n",
      "Epoch [190/200], Loss: 0.0032\n",
      "Epoch [200/200], Loss: 0.0033\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-318.979, test=-36.506) total time= 1.2min\n",
      "Epoch [10/200], Loss: 0.0221\n",
      "Epoch [20/200], Loss: 0.0149\n",
      "Epoch [30/200], Loss: 0.0106\n",
      "Epoch [40/200], Loss: 0.0081\n",
      "Epoch [50/200], Loss: 0.0065\n",
      "Epoch [60/200], Loss: 0.0055\n",
      "Epoch [70/200], Loss: 0.0050\n",
      "Epoch [80/200], Loss: 0.0045\n",
      "Epoch [90/200], Loss: 0.0041\n",
      "Epoch [100/200], Loss: 0.0037\n",
      "Epoch [110/200], Loss: 0.0036\n",
      "Epoch [120/200], Loss: 0.0034\n",
      "Epoch [130/200], Loss: 0.0031\n",
      "Epoch [140/200], Loss: 0.0029\n",
      "Epoch [150/200], Loss: 0.0030\n",
      "Epoch [160/200], Loss: 0.0027\n",
      "Epoch [170/200], Loss: 0.0027\n",
      "Epoch [180/200], Loss: 0.0025\n",
      "Epoch [190/200], Loss: 0.0025\n",
      "Epoch [200/200], Loss: 0.0023\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-478.765, test=-48.625) total time=  58.3s\n",
      "Epoch [10/200], Loss: 0.0238\n",
      "Epoch [20/200], Loss: 0.0181\n",
      "Epoch [30/200], Loss: 0.0133\n",
      "Epoch [40/200], Loss: 0.0129\n",
      "Epoch [50/200], Loss: 0.0128\n",
      "Epoch [60/200], Loss: 0.0103\n",
      "Epoch [70/200], Loss: 0.0099\n",
      "Epoch [80/200], Loss: 0.0098\n",
      "Epoch [90/200], Loss: 0.0090\n",
      "Epoch [100/200], Loss: 0.0078\n",
      "Epoch [110/200], Loss: 0.0071\n",
      "Epoch [120/200], Loss: 0.0075\n",
      "Epoch [130/200], Loss: 0.0069\n",
      "Epoch [140/200], Loss: 0.0068\n",
      "Epoch [150/200], Loss: 0.0053\n",
      "Epoch [160/200], Loss: 0.0060\n",
      "Epoch [170/200], Loss: 0.0070\n",
      "Epoch [180/200], Loss: 0.0052\n",
      "Epoch [190/200], Loss: 0.0056\n",
      "Epoch [200/200], Loss: 0.0050\n",
      "[CV 1/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-137.875, test=-122.329) total time=  15.3s\n",
      "Epoch [10/200], Loss: 0.0261\n",
      "Epoch [20/200], Loss: 0.0202\n",
      "Epoch [30/200], Loss: 0.0165\n",
      "Epoch [40/200], Loss: 0.0129\n",
      "Epoch [50/200], Loss: 0.0110\n",
      "Epoch [60/200], Loss: 0.0098\n",
      "Epoch [70/200], Loss: 0.0094\n",
      "Epoch [80/200], Loss: 0.0089\n",
      "Epoch [90/200], Loss: 0.0089\n",
      "Epoch [100/200], Loss: 0.0084\n",
      "Epoch [110/200], Loss: 0.0083\n",
      "Epoch [120/200], Loss: 0.0082\n",
      "Epoch [130/200], Loss: 0.0083\n",
      "Epoch [140/200], Loss: 0.0078\n",
      "Epoch [150/200], Loss: 0.0080\n",
      "Epoch [160/200], Loss: 0.0079\n",
      "Epoch [170/200], Loss: 0.0078\n",
      "Epoch [180/200], Loss: 0.0080\n",
      "Epoch [190/200], Loss: 0.0076\n",
      "Epoch [200/200], Loss: 0.0081\n",
      "[CV 2/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-253.926, test=-52.916) total time=  41.8s\n",
      "Epoch [10/200], Loss: 0.0216\n",
      "Epoch [20/200], Loss: 0.0166\n",
      "Epoch [30/200], Loss: 0.0128\n",
      "Epoch [40/200], Loss: 0.0107\n",
      "Epoch [50/200], Loss: 0.0092\n",
      "Epoch [60/200], Loss: 0.0082\n",
      "Epoch [70/200], Loss: 0.0079\n",
      "Epoch [80/200], Loss: 0.0077\n",
      "Epoch [90/200], Loss: 0.0075\n",
      "Epoch [100/200], Loss: 0.0067\n",
      "Epoch [110/200], Loss: 0.0073\n",
      "Epoch [120/200], Loss: 0.0063\n",
      "Epoch [130/200], Loss: 0.0067\n",
      "Epoch [140/200], Loss: 0.0063\n",
      "Epoch [150/200], Loss: 0.0061\n",
      "Epoch [160/200], Loss: 0.0058\n",
      "Epoch [170/200], Loss: 0.0067\n",
      "Epoch [180/200], Loss: 0.0061\n",
      "Epoch [190/200], Loss: 0.0061\n",
      "Epoch [200/200], Loss: 0.0069\n",
      "[CV 3/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-507.053, test=-55.875) total time=  33.4s\n",
      "Epoch [10/200], Loss: 0.0258\n",
      "Epoch [20/200], Loss: 0.0190\n",
      "Epoch [30/200], Loss: 0.0150\n",
      "Epoch [40/200], Loss: 0.0129\n",
      "Epoch [50/200], Loss: 0.0119\n",
      "Epoch [60/200], Loss: 0.0094\n",
      "Epoch [70/200], Loss: 0.0090\n",
      "Epoch [80/200], Loss: 0.0080\n",
      "Epoch [90/200], Loss: 0.0071\n",
      "Epoch [100/200], Loss: 0.0064\n",
      "Epoch [110/200], Loss: 0.0062\n",
      "Epoch [120/200], Loss: 0.0061\n",
      "Epoch [130/200], Loss: 0.0050\n",
      "Epoch [140/200], Loss: 0.0048\n",
      "Epoch [150/200], Loss: 0.0046\n",
      "Epoch [160/200], Loss: 0.0042\n",
      "Epoch [170/200], Loss: 0.0041\n",
      "Epoch [180/200], Loss: 0.0037\n",
      "Epoch [190/200], Loss: 0.0039\n",
      "Epoch [200/200], Loss: 0.0037\n",
      "[CV 1/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-148.101, test=-137.304) total time=  14.8s\n",
      "Epoch [10/200], Loss: 0.0290\n",
      "Epoch [20/200], Loss: 0.0228\n",
      "Epoch [30/200], Loss: 0.0165\n",
      "Epoch [40/200], Loss: 0.0127\n",
      "Epoch [50/200], Loss: 0.0105\n",
      "Epoch [60/200], Loss: 0.0090\n",
      "Epoch [70/200], Loss: 0.0078\n",
      "Epoch [80/200], Loss: 0.0069\n",
      "Epoch [90/200], Loss: 0.0062\n",
      "Epoch [100/200], Loss: 0.0058\n",
      "Epoch [110/200], Loss: 0.0053\n",
      "Epoch [120/200], Loss: 0.0052\n",
      "Epoch [130/200], Loss: 0.0049\n",
      "Epoch [140/200], Loss: 0.0045\n",
      "Epoch [150/200], Loss: 0.0046\n",
      "Epoch [160/200], Loss: 0.0042\n",
      "Epoch [170/200], Loss: 0.0042\n",
      "Epoch [180/200], Loss: 0.0038\n",
      "Epoch [190/200], Loss: 0.0038\n",
      "Epoch [200/200], Loss: 0.0037\n",
      "[CV 2/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-307.033, test=-47.485) total time=  40.9s\n",
      "Epoch [10/200], Loss: 0.0237\n",
      "Epoch [20/200], Loss: 0.0179\n",
      "Epoch [30/200], Loss: 0.0138\n",
      "Epoch [40/200], Loss: 0.0105\n",
      "Epoch [50/200], Loss: 0.0085\n",
      "Epoch [60/200], Loss: 0.0075\n",
      "Epoch [70/200], Loss: 0.0064\n",
      "Epoch [80/200], Loss: 0.0057\n",
      "Epoch [90/200], Loss: 0.0054\n",
      "Epoch [100/200], Loss: 0.0051\n",
      "Epoch [110/200], Loss: 0.0045\n",
      "Epoch [120/200], Loss: 0.0045\n",
      "Epoch [130/200], Loss: 0.0042\n",
      "Epoch [140/200], Loss: 0.0039\n",
      "Epoch [150/200], Loss: 0.0036\n",
      "Epoch [160/200], Loss: 0.0037\n",
      "Epoch [170/200], Loss: 0.0032\n",
      "Epoch [180/200], Loss: 0.0032\n",
      "Epoch [190/200], Loss: 0.0032\n",
      "Epoch [200/200], Loss: 0.0029\n",
      "[CV 3/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-498.348, test=-46.571) total time=  32.4s\n",
      "\n",
      "Parameter Search CV Results:\n",
      "=============================\n",
      "Best Parameters:  {'batch_size': 32, 'epochs': 200, 'l2_reg': 0, 'lr': 0.001}\n",
      "Best Cross-Validation Score:  -72.79758871930709\n",
      "Epoch [10/200], Loss: 0.0206\n",
      "Epoch [20/200], Loss: 0.0137\n",
      "Epoch [30/200], Loss: 0.0107\n",
      "Epoch [40/200], Loss: 0.0089\n",
      "Epoch [50/200], Loss: 0.0076\n",
      "Epoch [60/200], Loss: 0.0069\n",
      "Epoch [70/200], Loss: 0.0064\n",
      "Epoch [80/200], Loss: 0.0059\n",
      "Epoch [90/200], Loss: 0.0055\n",
      "Epoch [100/200], Loss: 0.0052\n",
      "Epoch [110/200], Loss: 0.0050\n",
      "Epoch [120/200], Loss: 0.0049\n",
      "Epoch [130/200], Loss: 0.0046\n",
      "Epoch [140/200], Loss: 0.0044\n",
      "Epoch [150/200], Loss: 0.0043\n",
      "Epoch [160/200], Loss: 0.0043\n",
      "Epoch [170/200], Loss: 0.0043\n",
      "Epoch [180/200], Loss: 0.0041\n",
      "Epoch [190/200], Loss: 0.0040\n",
      "Epoch [200/200], Loss: 0.0038\n",
      "\n",
      "Train Metrics: {'mse': 0.05462683090822239, 'mae': 0.18993410576522618, 'r2': -12.962950322268942, 'pearson_corr': 0.5327346902875946, 'connectome_corr': 0.4448817069372197, 'connectome_r2': -13.6648613979767, 'geodesic_distance': 12.851313960586351}\n",
      "Test Metrics: {'mse': 0.11251857683864067, 'mae': 0.26616310551435335, 'r2': -0.8399382301343289, 'pearson_corr': 0.5327204643667798, 'connectome_corr': 0.268747749349483, 'connectome_r2': -2.135307339653735, 'geodesic_distance': 4.8510975928050915}\n",
      "BEST VAL SCORE -72.79758871930709\n",
      "BEST MODEL PARAMS {'batch_size': 32, 'dropout': 0.05, 'epochs': 200, 'hidden_dims': [128, 64], 'input_dim': 20, 'l2_reg': 0, 'lr': 0.001, 'max_grad_norm': 1.0, 'output_dim': 1}\n",
      "CPU Usage: 16.7%\n",
      "RAM Usage: 20.8%\n",
      "Available RAM: 797.9G\n",
      "Total RAM: 1007.0G\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  1% |\n",
      "\n",
      " Test fold num: 2\n",
      "(4160, 20) (4160,) (2352, 20) (2352,)\n",
      "SEARCH METHOD ('grid', 'mse')\n",
      "1\n",
      "3\n",
      "4\n",
      "GPU model input size 20\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Epoch [10/200], Loss: 0.0211\n",
      "Epoch [20/200], Loss: 0.0177\n",
      "Epoch [30/200], Loss: 0.0162\n",
      "Epoch [40/200], Loss: 0.0135\n",
      "Epoch [50/200], Loss: 0.0103\n",
      "Epoch [60/200], Loss: 0.0096\n",
      "Epoch [70/200], Loss: 0.0082\n",
      "Epoch [80/200], Loss: 0.0073\n",
      "Epoch [90/200], Loss: 0.0070\n",
      "Epoch [100/200], Loss: 0.0065\n",
      "Epoch [110/200], Loss: 0.0069\n",
      "Epoch [120/200], Loss: 0.0063\n",
      "Epoch [130/200], Loss: 0.0064\n",
      "Epoch [140/200], Loss: 0.0060\n",
      "Epoch [150/200], Loss: 0.0056\n",
      "Epoch [160/200], Loss: 0.0060\n",
      "Epoch [170/200], Loss: 0.0060\n",
      "Epoch [180/200], Loss: 0.0057\n",
      "Epoch [190/200], Loss: 0.0063\n",
      "Epoch [200/200], Loss: 0.0061\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-153.782, test=-94.004) total time=  27.2s\n",
      "Epoch [10/200], Loss: 0.0182\n",
      "Epoch [20/200], Loss: 0.0135\n",
      "Epoch [30/200], Loss: 0.0120\n",
      "Epoch [40/200], Loss: 0.0112\n",
      "Epoch [50/200], Loss: 0.0102\n",
      "Epoch [60/200], Loss: 0.0093\n",
      "Epoch [70/200], Loss: 0.0087\n",
      "Epoch [80/200], Loss: 0.0087\n",
      "Epoch [90/200], Loss: 0.0079\n",
      "Epoch [100/200], Loss: 0.0079\n",
      "Epoch [110/200], Loss: 0.0074\n",
      "Epoch [120/200], Loss: 0.0070\n",
      "Epoch [130/200], Loss: 0.0066\n",
      "Epoch [140/200], Loss: 0.0068\n",
      "Epoch [150/200], Loss: 0.0062\n",
      "Epoch [160/200], Loss: 0.0059\n",
      "Epoch [170/200], Loss: 0.0062\n",
      "Epoch [180/200], Loss: 0.0058\n",
      "Epoch [190/200], Loss: 0.0059\n",
      "Epoch [200/200], Loss: 0.0058\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-150.042, test=-28.373) total time=  26.5s\n",
      "Epoch [10/200], Loss: 0.0221\n",
      "Epoch [20/200], Loss: 0.0179\n",
      "Epoch [30/200], Loss: 0.0150\n",
      "Epoch [40/200], Loss: 0.0141\n",
      "Epoch [50/200], Loss: 0.0133\n",
      "Epoch [60/200], Loss: 0.0118\n",
      "Epoch [70/200], Loss: 0.0108\n",
      "Epoch [80/200], Loss: 0.0111\n",
      "Epoch [90/200], Loss: 0.0100\n",
      "Epoch [100/200], Loss: 0.0088\n",
      "Epoch [110/200], Loss: 0.0089\n",
      "Epoch [120/200], Loss: 0.0082\n",
      "Epoch [130/200], Loss: 0.0081\n",
      "Epoch [140/200], Loss: 0.0077\n",
      "Epoch [150/200], Loss: 0.0074\n",
      "Epoch [160/200], Loss: 0.0075\n",
      "Epoch [170/200], Loss: 0.0078\n",
      "Epoch [180/200], Loss: 0.0065\n",
      "Epoch [190/200], Loss: 0.0072\n",
      "Epoch [200/200], Loss: 0.0072\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-109.786, test=-25.263) total time=  18.6s\n",
      "Epoch [10/200], Loss: 0.0215\n",
      "Epoch [20/200], Loss: 0.0165\n",
      "Epoch [30/200], Loss: 0.0144\n",
      "Epoch [40/200], Loss: 0.0125\n",
      "Epoch [50/200], Loss: 0.0107\n",
      "Epoch [60/200], Loss: 0.0092\n",
      "Epoch [70/200], Loss: 0.0078\n",
      "Epoch [80/200], Loss: 0.0071\n",
      "Epoch [90/200], Loss: 0.0062\n",
      "Epoch [100/200], Loss: 0.0051\n",
      "Epoch [110/200], Loss: 0.0048\n",
      "Epoch [120/200], Loss: 0.0041\n",
      "Epoch [130/200], Loss: 0.0038\n",
      "Epoch [140/200], Loss: 0.0033\n",
      "Epoch [150/200], Loss: 0.0033\n",
      "Epoch [160/200], Loss: 0.0033\n",
      "Epoch [170/200], Loss: 0.0032\n",
      "Epoch [180/200], Loss: 0.0031\n",
      "Epoch [190/200], Loss: 0.0029\n",
      "Epoch [200/200], Loss: 0.0024\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-149.037, test=-113.738) total time=  26.3s\n",
      "Epoch [10/200], Loss: 0.0183\n",
      "Epoch [20/200], Loss: 0.0134\n",
      "Epoch [30/200], Loss: 0.0115\n",
      "Epoch [40/200], Loss: 0.0098\n",
      "Epoch [50/200], Loss: 0.0085\n",
      "Epoch [60/200], Loss: 0.0081\n",
      "Epoch [70/200], Loss: 0.0070\n",
      "Epoch [80/200], Loss: 0.0066\n",
      "Epoch [90/200], Loss: 0.0060\n",
      "Epoch [100/200], Loss: 0.0055\n",
      "Epoch [110/200], Loss: 0.0054\n",
      "Epoch [120/200], Loss: 0.0050\n",
      "Epoch [130/200], Loss: 0.0047\n",
      "Epoch [140/200], Loss: 0.0043\n",
      "Epoch [150/200], Loss: 0.0040\n",
      "Epoch [160/200], Loss: 0.0043\n",
      "Epoch [170/200], Loss: 0.0038\n",
      "Epoch [180/200], Loss: 0.0034\n",
      "Epoch [190/200], Loss: 0.0032\n",
      "Epoch [200/200], Loss: 0.0030\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-157.323, test=-26.839) total time=  26.5s\n",
      "Epoch [10/200], Loss: 0.0238\n",
      "Epoch [20/200], Loss: 0.0175\n",
      "Epoch [30/200], Loss: 0.0153\n",
      "Epoch [40/200], Loss: 0.0124\n",
      "Epoch [50/200], Loss: 0.0120\n",
      "Epoch [60/200], Loss: 0.0108\n",
      "Epoch [70/200], Loss: 0.0089\n",
      "Epoch [80/200], Loss: 0.0084\n",
      "Epoch [90/200], Loss: 0.0075\n",
      "Epoch [100/200], Loss: 0.0077\n",
      "Epoch [110/200], Loss: 0.0066\n",
      "Epoch [120/200], Loss: 0.0060\n",
      "Epoch [130/200], Loss: 0.0063\n",
      "Epoch [140/200], Loss: 0.0059\n",
      "Epoch [150/200], Loss: 0.0053\n",
      "Epoch [160/200], Loss: 0.0053\n",
      "Epoch [170/200], Loss: 0.0047\n",
      "Epoch [180/200], Loss: 0.0043\n",
      "Epoch [190/200], Loss: 0.0043\n",
      "Epoch [200/200], Loss: 0.0043\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-124.663, test=-28.345) total time=  17.5s\n",
      "Epoch [10/200], Loss: 0.0264\n",
      "Epoch [20/200], Loss: 0.0180\n",
      "Epoch [30/200], Loss: 0.0151\n",
      "Epoch [40/200], Loss: 0.0129\n",
      "Epoch [50/200], Loss: 0.0128\n",
      "Epoch [60/200], Loss: 0.0120\n",
      "Epoch [70/200], Loss: 0.0107\n",
      "Epoch [80/200], Loss: 0.0094\n",
      "Epoch [90/200], Loss: 0.0084\n",
      "Epoch [100/200], Loss: 0.0083\n",
      "Epoch [110/200], Loss: 0.0077\n",
      "Epoch [120/200], Loss: 0.0068\n",
      "Epoch [130/200], Loss: 0.0071\n",
      "Epoch [140/200], Loss: 0.0059\n",
      "Epoch [150/200], Loss: 0.0080\n",
      "Epoch [160/200], Loss: 0.0063\n",
      "Epoch [170/200], Loss: 0.0050\n",
      "Epoch [180/200], Loss: 0.0058\n",
      "Epoch [190/200], Loss: 0.0057\n",
      "Epoch [200/200], Loss: 0.0058\n",
      "[CV 1/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-156.441, test=-102.227) total time=  15.3s\n",
      "Epoch [10/200], Loss: 0.0182\n",
      "Epoch [20/200], Loss: 0.0136\n",
      "Epoch [30/200], Loss: 0.0110\n",
      "Epoch [40/200], Loss: 0.0099\n",
      "Epoch [50/200], Loss: 0.0094\n",
      "Epoch [60/200], Loss: 0.0090\n",
      "Epoch [70/200], Loss: 0.0080\n",
      "Epoch [80/200], Loss: 0.0084\n",
      "Epoch [90/200], Loss: 0.0075\n",
      "Epoch [100/200], Loss: 0.0072\n",
      "Epoch [110/200], Loss: 0.0066\n",
      "Epoch [120/200], Loss: 0.0065\n",
      "Epoch [130/200], Loss: 0.0063\n",
      "Epoch [140/200], Loss: 0.0057\n",
      "Epoch [150/200], Loss: 0.0057\n",
      "Epoch [160/200], Loss: 0.0060\n",
      "Epoch [170/200], Loss: 0.0049\n",
      "Epoch [180/200], Loss: 0.0067\n",
      "Epoch [190/200], Loss: 0.0056\n",
      "Epoch [200/200], Loss: 0.0048\n",
      "[CV 2/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-170.218, test=-32.451) total time=  15.4s\n",
      "Epoch [10/200], Loss: 0.0236\n",
      "Epoch [20/200], Loss: 0.0147\n",
      "Epoch [30/200], Loss: 0.0138\n",
      "Epoch [40/200], Loss: 0.0125\n",
      "Epoch [50/200], Loss: 0.0125\n",
      "Epoch [60/200], Loss: 0.0105\n",
      "Epoch [70/200], Loss: 0.0092\n",
      "Epoch [80/200], Loss: 0.0105\n",
      "Epoch [90/200], Loss: 0.0096\n",
      "Epoch [100/200], Loss: 0.0090\n",
      "Epoch [110/200], Loss: 0.0097\n",
      "Epoch [120/200], Loss: 0.0092\n",
      "Epoch [130/200], Loss: 0.0095\n",
      "Epoch [140/200], Loss: 0.0092\n",
      "Epoch [150/200], Loss: 0.0081\n",
      "Epoch [160/200], Loss: 0.0075\n",
      "Epoch [170/200], Loss: 0.0084\n",
      "Epoch [180/200], Loss: 0.0082\n",
      "Epoch [190/200], Loss: 0.0072\n",
      "Epoch [200/200], Loss: 0.0070\n",
      "[CV 3/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-155.521, test=-20.925) total time=  10.1s\n",
      "Epoch [10/200], Loss: 0.0268\n",
      "Epoch [20/200], Loss: 0.0198\n",
      "Epoch [30/200], Loss: 0.0163\n",
      "Epoch [40/200], Loss: 0.0144\n",
      "Epoch [50/200], Loss: 0.0126\n",
      "Epoch [60/200], Loss: 0.0104\n",
      "Epoch [70/200], Loss: 0.0094\n",
      "Epoch [80/200], Loss: 0.0080\n",
      "Epoch [90/200], Loss: 0.0080\n",
      "Epoch [100/200], Loss: 0.0070\n",
      "Epoch [110/200], Loss: 0.0065\n",
      "Epoch [120/200], Loss: 0.0061\n",
      "Epoch [130/200], Loss: 0.0059\n",
      "Epoch [140/200], Loss: 0.0052\n",
      "Epoch [150/200], Loss: 0.0057\n",
      "Epoch [160/200], Loss: 0.0048\n",
      "Epoch [170/200], Loss: 0.0043\n",
      "Epoch [180/200], Loss: 0.0039\n",
      "Epoch [190/200], Loss: 0.0041\n",
      "Epoch [200/200], Loss: 0.0035\n",
      "[CV 1/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-141.208, test=-143.078) total time=  14.9s\n",
      "Epoch [10/200], Loss: 0.0187\n",
      "Epoch [20/200], Loss: 0.0139\n",
      "Epoch [30/200], Loss: 0.0116\n",
      "Epoch [40/200], Loss: 0.0101\n",
      "Epoch [50/200], Loss: 0.0085\n",
      "Epoch [60/200], Loss: 0.0077\n",
      "Epoch [70/200], Loss: 0.0076\n",
      "Epoch [80/200], Loss: 0.0068\n",
      "Epoch [90/200], Loss: 0.0067\n",
      "Epoch [100/200], Loss: 0.0057\n",
      "Epoch [110/200], Loss: 0.0057\n",
      "Epoch [120/200], Loss: 0.0053\n",
      "Epoch [130/200], Loss: 0.0051\n",
      "Epoch [140/200], Loss: 0.0044\n",
      "Epoch [150/200], Loss: 0.0047\n",
      "Epoch [160/200], Loss: 0.0046\n",
      "Epoch [170/200], Loss: 0.0043\n",
      "Epoch [180/200], Loss: 0.0040\n",
      "Epoch [190/200], Loss: 0.0036\n",
      "Epoch [200/200], Loss: 0.0036\n",
      "[CV 2/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-143.678, test=-29.540) total time=  15.1s\n",
      "Epoch [10/200], Loss: 0.0214\n",
      "Epoch [20/200], Loss: 0.0165\n",
      "Epoch [30/200], Loss: 0.0133\n",
      "Epoch [40/200], Loss: 0.0118\n",
      "Epoch [50/200], Loss: 0.0107\n",
      "Epoch [60/200], Loss: 0.0102\n",
      "Epoch [70/200], Loss: 0.0093\n",
      "Epoch [80/200], Loss: 0.0090\n",
      "Epoch [90/200], Loss: 0.0083\n",
      "Epoch [100/200], Loss: 0.0071\n",
      "Epoch [110/200], Loss: 0.0076\n",
      "Epoch [120/200], Loss: 0.0070\n",
      "Epoch [130/200], Loss: 0.0066\n",
      "Epoch [140/200], Loss: 0.0064\n",
      "Epoch [150/200], Loss: 0.0068\n",
      "Epoch [160/200], Loss: 0.0058\n",
      "Epoch [170/200], Loss: 0.0055\n",
      "Epoch [180/200], Loss: 0.0051\n",
      "Epoch [190/200], Loss: 0.0054\n",
      "Epoch [200/200], Loss: 0.0054\n",
      "[CV 3/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-122.422, test=-25.064) total time=  10.4s\n",
      "\n",
      "Parameter Search CV Results:\n",
      "=============================\n",
      "Best Parameters:  {'batch_size': 32, 'epochs': 200, 'l2_reg': 0.001, 'lr': 0.001}\n",
      "Best Cross-Validation Score:  -49.213443553849054\n",
      "Epoch [10/200], Loss: 0.0189\n",
      "Epoch [20/200], Loss: 0.0161\n",
      "Epoch [30/200], Loss: 0.0146\n",
      "Epoch [40/200], Loss: 0.0133\n",
      "Epoch [50/200], Loss: 0.0123\n",
      "Epoch [60/200], Loss: 0.0118\n",
      "Epoch [70/200], Loss: 0.0112\n",
      "Epoch [80/200], Loss: 0.0106\n",
      "Epoch [90/200], Loss: 0.0106\n",
      "Epoch [100/200], Loss: 0.0102\n",
      "Epoch [110/200], Loss: 0.0101\n",
      "Epoch [120/200], Loss: 0.0101\n",
      "Epoch [130/200], Loss: 0.0097\n",
      "Epoch [140/200], Loss: 0.0102\n",
      "Epoch [150/200], Loss: 0.0098\n",
      "Epoch [160/200], Loss: 0.0097\n",
      "Epoch [170/200], Loss: 0.0102\n",
      "Epoch [180/200], Loss: 0.0100\n",
      "Epoch [190/200], Loss: 0.0097\n",
      "Epoch [200/200], Loss: 0.0095\n",
      "\n",
      "Train Metrics: {'mse': 0.02375623073401588, 'mae': 0.11508202629395332, 'r2': -0.16482499747681015, 'pearson_corr': 0.7450749277438146, 'connectome_corr': 0.6734323294946571, 'connectome_r2': -0.289385009746147, 'geodesic_distance': 7.868363818494742}\n",
      "Test Metrics: {'mse': 0.05448890729790134, 'mae': 0.19113567547370308, 'r2': -18.357480739642597, 'pearson_corr': 0.3622322742088604, 'connectome_corr': 0.3027689592572685, 'connectome_r2': -20.057260855671206, 'geodesic_distance': 8.662461843199498}\n",
      "BEST VAL SCORE -49.213443553849054\n",
      "BEST MODEL PARAMS {'batch_size': 32, 'dropout': 0.05, 'epochs': 200, 'hidden_dims': [128, 64], 'input_dim': 20, 'l2_reg': 0.001, 'lr': 0.001, 'max_grad_norm': 1.0, 'output_dim': 1}\n",
      "CPU Usage: 25.7%\n",
      "RAM Usage: 20.3%\n",
      "Available RAM: 802.8G\n",
      "Total RAM: 1007.0G\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  1% |\n",
      "\n",
      " Test fold num: 3\n",
      "(8930, 20) (8930,) (342, 20) (342,)\n",
      "SEARCH METHOD ('grid', 'mse')\n",
      "1\n",
      "2\n",
      "4\n",
      "GPU model input size 20\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Epoch [10/200], Loss: 0.0256\n",
      "Epoch [20/200], Loss: 0.0195\n",
      "Epoch [30/200], Loss: 0.0163\n",
      "Epoch [40/200], Loss: 0.0139\n",
      "Epoch [50/200], Loss: 0.0128\n",
      "Epoch [60/200], Loss: 0.0123\n",
      "Epoch [70/200], Loss: 0.0119\n",
      "Epoch [80/200], Loss: 0.0118\n",
      "Epoch [90/200], Loss: 0.0112\n",
      "Epoch [100/200], Loss: 0.0113\n",
      "Epoch [110/200], Loss: 0.0108\n",
      "Epoch [120/200], Loss: 0.0113\n",
      "Epoch [130/200], Loss: 0.0109\n",
      "Epoch [140/200], Loss: 0.0110\n",
      "Epoch [150/200], Loss: 0.0109\n",
      "Epoch [160/200], Loss: 0.0107\n",
      "Epoch [170/200], Loss: 0.0105\n",
      "Epoch [180/200], Loss: 0.0107\n",
      "Epoch [190/200], Loss: 0.0107\n",
      "Epoch [200/200], Loss: 0.0103\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-400.717, test=-59.015) total time= 1.2min\n",
      "Epoch [10/200], Loss: 0.0164\n",
      "Epoch [20/200], Loss: 0.0131\n",
      "Epoch [30/200], Loss: 0.0117\n",
      "Epoch [40/200], Loss: 0.0114\n",
      "Epoch [50/200], Loss: 0.0101\n",
      "Epoch [60/200], Loss: 0.0091\n",
      "Epoch [70/200], Loss: 0.0080\n",
      "Epoch [80/200], Loss: 0.0079\n",
      "Epoch [90/200], Loss: 0.0075\n",
      "Epoch [100/200], Loss: 0.0072\n",
      "Epoch [110/200], Loss: 0.0072\n",
      "Epoch [120/200], Loss: 0.0068\n",
      "Epoch [130/200], Loss: 0.0066\n",
      "Epoch [140/200], Loss: 0.0061\n",
      "Epoch [150/200], Loss: 0.0063\n",
      "Epoch [160/200], Loss: 0.0059\n",
      "Epoch [170/200], Loss: 0.0062\n",
      "Epoch [180/200], Loss: 0.0058\n",
      "Epoch [190/200], Loss: 0.0056\n",
      "Epoch [200/200], Loss: 0.0058\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-183.466, test=-285.350) total time=  26.5s\n",
      "Epoch [10/200], Loss: 0.0215\n",
      "Epoch [20/200], Loss: 0.0187\n",
      "Epoch [30/200], Loss: 0.0160\n",
      "Epoch [40/200], Loss: 0.0137\n",
      "Epoch [50/200], Loss: 0.0126\n",
      "Epoch [60/200], Loss: 0.0113\n",
      "Epoch [70/200], Loss: 0.0109\n",
      "Epoch [80/200], Loss: 0.0102\n",
      "Epoch [90/200], Loss: 0.0101\n",
      "Epoch [100/200], Loss: 0.0100\n",
      "Epoch [110/200], Loss: 0.0097\n",
      "Epoch [120/200], Loss: 0.0098\n",
      "Epoch [130/200], Loss: 0.0093\n",
      "Epoch [140/200], Loss: 0.0095\n",
      "Epoch [150/200], Loss: 0.0095\n",
      "Epoch [160/200], Loss: 0.0088\n",
      "Epoch [170/200], Loss: 0.0091\n",
      "Epoch [180/200], Loss: 0.0094\n",
      "Epoch [190/200], Loss: 0.0093\n",
      "Epoch [200/200], Loss: 0.0092\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-349.659, test=-46.229) total time=  58.4s\n",
      "Epoch [10/200], Loss: 0.0254\n",
      "Epoch [20/200], Loss: 0.0166\n",
      "Epoch [30/200], Loss: 0.0118\n",
      "Epoch [40/200], Loss: 0.0092\n",
      "Epoch [50/200], Loss: 0.0079\n",
      "Epoch [60/200], Loss: 0.0069\n",
      "Epoch [70/200], Loss: 0.0057\n",
      "Epoch [80/200], Loss: 0.0056\n",
      "Epoch [90/200], Loss: 0.0052\n",
      "Epoch [100/200], Loss: 0.0047\n",
      "Epoch [110/200], Loss: 0.0046\n",
      "Epoch [120/200], Loss: 0.0043\n",
      "Epoch [130/200], Loss: 0.0042\n",
      "Epoch [140/200], Loss: 0.0039\n",
      "Epoch [150/200], Loss: 0.0040\n",
      "Epoch [160/200], Loss: 0.0038\n",
      "Epoch [170/200], Loss: 0.0037\n",
      "Epoch [180/200], Loss: 0.0035\n",
      "Epoch [190/200], Loss: 0.0035\n",
      "Epoch [200/200], Loss: 0.0033\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-352.851, test=-60.830) total time= 1.2min\n",
      "Epoch [10/200], Loss: 0.0183\n",
      "Epoch [20/200], Loss: 0.0134\n",
      "Epoch [30/200], Loss: 0.0108\n",
      "Epoch [40/200], Loss: 0.0094\n",
      "Epoch [50/200], Loss: 0.0076\n",
      "Epoch [60/200], Loss: 0.0076\n",
      "Epoch [70/200], Loss: 0.0071\n",
      "Epoch [80/200], Loss: 0.0063\n",
      "Epoch [90/200], Loss: 0.0058\n",
      "Epoch [100/200], Loss: 0.0054\n",
      "Epoch [110/200], Loss: 0.0049\n",
      "Epoch [120/200], Loss: 0.0047\n",
      "Epoch [130/200], Loss: 0.0046\n",
      "Epoch [140/200], Loss: 0.0041\n",
      "Epoch [150/200], Loss: 0.0042\n",
      "Epoch [160/200], Loss: 0.0037\n",
      "Epoch [170/200], Loss: 0.0038\n",
      "Epoch [180/200], Loss: 0.0032\n",
      "Epoch [190/200], Loss: 0.0035\n",
      "Epoch [200/200], Loss: 0.0029\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-151.888, test=-258.482) total time=  25.6s\n",
      "Epoch [10/200], Loss: 0.0214\n",
      "Epoch [20/200], Loss: 0.0164\n",
      "Epoch [30/200], Loss: 0.0124\n",
      "Epoch [40/200], Loss: 0.0101\n",
      "Epoch [50/200], Loss: 0.0083\n",
      "Epoch [60/200], Loss: 0.0072\n",
      "Epoch [70/200], Loss: 0.0064\n",
      "Epoch [80/200], Loss: 0.0057\n",
      "Epoch [90/200], Loss: 0.0052\n",
      "Epoch [100/200], Loss: 0.0049\n",
      "Epoch [110/200], Loss: 0.0044\n",
      "Epoch [120/200], Loss: 0.0044\n",
      "Epoch [130/200], Loss: 0.0040\n",
      "Epoch [140/200], Loss: 0.0038\n",
      "Epoch [150/200], Loss: 0.0037\n",
      "Epoch [160/200], Loss: 0.0035\n",
      "Epoch [170/200], Loss: 0.0032\n",
      "Epoch [180/200], Loss: 0.0032\n",
      "Epoch [190/200], Loss: 0.0031\n",
      "Epoch [200/200], Loss: 0.0030\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-383.857, test=-39.012) total time=  56.6s\n",
      "Epoch [10/200], Loss: 0.0259\n",
      "Epoch [20/200], Loss: 0.0195\n",
      "Epoch [30/200], Loss: 0.0156\n",
      "Epoch [40/200], Loss: 0.0133\n",
      "Epoch [50/200], Loss: 0.0112\n",
      "Epoch [60/200], Loss: 0.0106\n",
      "Epoch [70/200], Loss: 0.0095\n",
      "Epoch [80/200], Loss: 0.0088\n",
      "Epoch [90/200], Loss: 0.0089\n",
      "Epoch [100/200], Loss: 0.0090\n",
      "Epoch [110/200], Loss: 0.0085\n",
      "Epoch [120/200], Loss: 0.0090\n",
      "Epoch [130/200], Loss: 0.0087\n",
      "Epoch [140/200], Loss: 0.0085\n",
      "Epoch [150/200], Loss: 0.0082\n",
      "Epoch [160/200], Loss: 0.0081\n",
      "Epoch [170/200], Loss: 0.0086\n",
      "Epoch [180/200], Loss: 0.0082\n",
      "Epoch [190/200], Loss: 0.0074\n",
      "Epoch [200/200], Loss: 0.0080\n",
      "[CV 1/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-270.432, test=-73.867) total time=  41.5s\n",
      "Epoch [10/200], Loss: 0.0183\n",
      "Epoch [20/200], Loss: 0.0133\n",
      "Epoch [30/200], Loss: 0.0108\n",
      "Epoch [40/200], Loss: 0.0100\n",
      "Epoch [50/200], Loss: 0.0103\n",
      "Epoch [60/200], Loss: 0.0095\n",
      "Epoch [70/200], Loss: 0.0086\n",
      "Epoch [80/200], Loss: 0.0076\n",
      "Epoch [90/200], Loss: 0.0077\n",
      "Epoch [100/200], Loss: 0.0073\n",
      "Epoch [110/200], Loss: 0.0080\n",
      "Epoch [120/200], Loss: 0.0069\n",
      "Epoch [130/200], Loss: 0.0067\n",
      "Epoch [140/200], Loss: 0.0066\n",
      "Epoch [150/200], Loss: 0.0062\n",
      "Epoch [160/200], Loss: 0.0067\n",
      "Epoch [170/200], Loss: 0.0066\n",
      "Epoch [180/200], Loss: 0.0060\n",
      "Epoch [190/200], Loss: 0.0057\n",
      "Epoch [200/200], Loss: 0.0055\n",
      "[CV 2/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-114.817, test=-194.570) total time=  15.2s\n",
      "Epoch [10/200], Loss: 0.0224\n",
      "Epoch [20/200], Loss: 0.0176\n",
      "Epoch [30/200], Loss: 0.0158\n",
      "Epoch [40/200], Loss: 0.0143\n",
      "Epoch [50/200], Loss: 0.0133\n",
      "Epoch [60/200], Loss: 0.0119\n",
      "Epoch [70/200], Loss: 0.0110\n",
      "Epoch [80/200], Loss: 0.0104\n",
      "Epoch [90/200], Loss: 0.0096\n",
      "Epoch [100/200], Loss: 0.0093\n",
      "Epoch [110/200], Loss: 0.0092\n",
      "Epoch [120/200], Loss: 0.0085\n",
      "Epoch [130/200], Loss: 0.0088\n",
      "Epoch [140/200], Loss: 0.0081\n",
      "Epoch [150/200], Loss: 0.0084\n",
      "Epoch [160/200], Loss: 0.0082\n",
      "Epoch [170/200], Loss: 0.0081\n",
      "Epoch [180/200], Loss: 0.0077\n",
      "Epoch [190/200], Loss: 0.0078\n",
      "Epoch [200/200], Loss: 0.0076\n",
      "[CV 3/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-506.479, test=-52.976) total time=  33.2s\n",
      "Epoch [10/200], Loss: 0.0281\n",
      "Epoch [20/200], Loss: 0.0227\n",
      "Epoch [30/200], Loss: 0.0162\n",
      "Epoch [40/200], Loss: 0.0127\n",
      "Epoch [50/200], Loss: 0.0107\n",
      "Epoch [60/200], Loss: 0.0083\n",
      "Epoch [70/200], Loss: 0.0079\n",
      "Epoch [80/200], Loss: 0.0072\n",
      "Epoch [90/200], Loss: 0.0062\n",
      "Epoch [100/200], Loss: 0.0060\n",
      "Epoch [110/200], Loss: 0.0056\n",
      "Epoch [120/200], Loss: 0.0050\n",
      "Epoch [130/200], Loss: 0.0048\n",
      "Epoch [140/200], Loss: 0.0048\n",
      "Epoch [150/200], Loss: 0.0042\n",
      "Epoch [160/200], Loss: 0.0044\n",
      "Epoch [170/200], Loss: 0.0041\n",
      "Epoch [180/200], Loss: 0.0040\n",
      "Epoch [190/200], Loss: 0.0038\n",
      "Epoch [200/200], Loss: 0.0036\n",
      "[CV 1/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-292.699, test=-72.997) total time=  40.2s\n",
      "Epoch [10/200], Loss: 0.0174\n",
      "Epoch [20/200], Loss: 0.0129\n",
      "Epoch [30/200], Loss: 0.0114\n",
      "Epoch [40/200], Loss: 0.0100\n",
      "Epoch [50/200], Loss: 0.0091\n",
      "Epoch [60/200], Loss: 0.0077\n",
      "Epoch [70/200], Loss: 0.0070\n",
      "Epoch [80/200], Loss: 0.0067\n",
      "Epoch [90/200], Loss: 0.0063\n",
      "Epoch [100/200], Loss: 0.0059\n",
      "Epoch [110/200], Loss: 0.0060\n",
      "Epoch [120/200], Loss: 0.0056\n",
      "Epoch [130/200], Loss: 0.0050\n",
      "Epoch [140/200], Loss: 0.0047\n",
      "Epoch [150/200], Loss: 0.0046\n",
      "Epoch [160/200], Loss: 0.0042\n",
      "Epoch [170/200], Loss: 0.0040\n",
      "Epoch [180/200], Loss: 0.0040\n",
      "Epoch [190/200], Loss: 0.0036\n",
      "Epoch [200/200], Loss: 0.0036\n",
      "[CV 2/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-135.131, test=-227.986) total time=  14.7s\n",
      "Epoch [10/200], Loss: 0.0247\n",
      "Epoch [20/200], Loss: 0.0183\n",
      "Epoch [30/200], Loss: 0.0153\n",
      "Epoch [40/200], Loss: 0.0121\n",
      "Epoch [50/200], Loss: 0.0105\n",
      "Epoch [60/200], Loss: 0.0093\n",
      "Epoch [70/200], Loss: 0.0083\n",
      "Epoch [80/200], Loss: 0.0073\n",
      "Epoch [90/200], Loss: 0.0065\n",
      "Epoch [100/200], Loss: 0.0062\n",
      "Epoch [110/200], Loss: 0.0056\n",
      "Epoch [120/200], Loss: 0.0053\n",
      "Epoch [130/200], Loss: 0.0052\n",
      "Epoch [140/200], Loss: 0.0045\n",
      "Epoch [150/200], Loss: 0.0045\n",
      "Epoch [160/200], Loss: 0.0042\n",
      "Epoch [170/200], Loss: 0.0040\n",
      "Epoch [180/200], Loss: 0.0037\n",
      "Epoch [190/200], Loss: 0.0036\n",
      "Epoch [200/200], Loss: 0.0034\n",
      "[CV 3/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-342.217, test=-51.133) total time=  31.1s\n",
      "\n",
      "Parameter Search CV Results:\n",
      "=============================\n",
      "Best Parameters:  {'batch_size': 64, 'epochs': 200, 'l2_reg': 0.001, 'lr': 0.001}\n",
      "Best Cross-Validation Score:  -107.13747675391495\n",
      "Epoch [10/200], Loss: 0.0258\n",
      "Epoch [20/200], Loss: 0.0226\n",
      "Epoch [30/200], Loss: 0.0196\n",
      "Epoch [40/200], Loss: 0.0174\n",
      "Epoch [50/200], Loss: 0.0169\n",
      "Epoch [60/200], Loss: 0.0154\n",
      "Epoch [70/200], Loss: 0.0151\n",
      "Epoch [80/200], Loss: 0.0150\n",
      "Epoch [90/200], Loss: 0.0144\n",
      "Epoch [100/200], Loss: 0.0144\n",
      "Epoch [110/200], Loss: 0.0139\n",
      "Epoch [120/200], Loss: 0.0138\n",
      "Epoch [130/200], Loss: 0.0135\n",
      "Epoch [140/200], Loss: 0.0137\n",
      "Epoch [150/200], Loss: 0.0135\n",
      "Epoch [160/200], Loss: 0.0131\n",
      "Epoch [170/200], Loss: 0.0131\n",
      "Epoch [180/200], Loss: 0.0135\n",
      "Epoch [190/200], Loss: 0.0129\n",
      "Epoch [200/200], Loss: 0.0132\n",
      "\n",
      "Train Metrics: {'mse': 0.027394291428263707, 'mae': 0.1272055736053761, 'r2': -3.441259933328136, 'pearson_corr': 0.5358865190971842, 'connectome_corr': 0.41617191668775366, 'connectome_r2': -3.6737339614658535, 'geodesic_distance': 12.710602467007792}\n",
      "Test Metrics: {'mse': 0.07033477166206178, 'mae': 0.21219141730906496, 'r2': -3.1781719593708067, 'pearson_corr': 0.5281798731598681, 'connectome_corr': 0.3448189614660617, 'connectome_r2': -11.20198577260532, 'geodesic_distance': 6.800185928065098}\n",
      "BEST VAL SCORE -107.13747675391495\n",
      "BEST MODEL PARAMS {'batch_size': 64, 'dropout': 0.05, 'epochs': 200, 'hidden_dims': [128, 64], 'input_dim': 20, 'l2_reg': 0.001, 'lr': 0.001, 'max_grad_norm': 1.0, 'output_dim': 1}\n",
      "CPU Usage: 22.4%\n",
      "RAM Usage: 19.5%\n",
      "Available RAM: 810.6G\n",
      "Total RAM: 1007.0G\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  1% |\n",
      "\n",
      " Test fold num: 4\n",
      "(7482, 20) (7482,) (702, 20) (702,)\n",
      "SEARCH METHOD ('grid', 'mse')\n",
      "1\n",
      "2\n",
      "3\n",
      "GPU model input size 20\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Epoch [10/200], Loss: 0.0219\n",
      "Epoch [20/200], Loss: 0.0174\n",
      "Epoch [30/200], Loss: 0.0134\n",
      "Epoch [40/200], Loss: 0.0115\n",
      "Epoch [50/200], Loss: 0.0100\n",
      "Epoch [60/200], Loss: 0.0090\n",
      "Epoch [70/200], Loss: 0.0089\n",
      "Epoch [80/200], Loss: 0.0088\n",
      "Epoch [90/200], Loss: 0.0085\n",
      "Epoch [100/200], Loss: 0.0077\n",
      "Epoch [110/200], Loss: 0.0086\n",
      "Epoch [120/200], Loss: 0.0087\n",
      "Epoch [130/200], Loss: 0.0081\n",
      "Epoch [140/200], Loss: 0.0077\n",
      "Epoch [150/200], Loss: 0.0080\n",
      "Epoch [160/200], Loss: 0.0075\n",
      "Epoch [170/200], Loss: 0.0077\n",
      "Epoch [180/200], Loss: 0.0080\n",
      "Epoch [190/200], Loss: 0.0077\n",
      "Epoch [200/200], Loss: 0.0074\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-463.332, test=-74.487) total time=  56.1s\n",
      "Epoch [10/200], Loss: 0.0223\n",
      "Epoch [20/200], Loss: 0.0182\n",
      "Epoch [30/200], Loss: 0.0152\n",
      "Epoch [40/200], Loss: 0.0134\n",
      "Epoch [50/200], Loss: 0.0136\n",
      "Epoch [60/200], Loss: 0.0119\n",
      "Epoch [70/200], Loss: 0.0116\n",
      "Epoch [80/200], Loss: 0.0103\n",
      "Epoch [90/200], Loss: 0.0108\n",
      "Epoch [100/200], Loss: 0.0103\n",
      "Epoch [110/200], Loss: 0.0084\n",
      "Epoch [120/200], Loss: 0.0084\n",
      "Epoch [130/200], Loss: 0.0084\n",
      "Epoch [140/200], Loss: 0.0079\n",
      "Epoch [150/200], Loss: 0.0079\n",
      "Epoch [160/200], Loss: 0.0071\n",
      "Epoch [170/200], Loss: 0.0071\n",
      "Epoch [180/200], Loss: 0.0074\n",
      "Epoch [190/200], Loss: 0.0076\n",
      "Epoch [200/200], Loss: 0.0075\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-116.350, test=-211.487) total time=  17.3s\n",
      "Epoch [10/200], Loss: 0.0215\n",
      "Epoch [20/200], Loss: 0.0190\n",
      "Epoch [30/200], Loss: 0.0155\n",
      "Epoch [40/200], Loss: 0.0137\n",
      "Epoch [50/200], Loss: 0.0125\n",
      "Epoch [60/200], Loss: 0.0114\n",
      "Epoch [70/200], Loss: 0.0108\n",
      "Epoch [80/200], Loss: 0.0105\n",
      "Epoch [90/200], Loss: 0.0100\n",
      "Epoch [100/200], Loss: 0.0105\n",
      "Epoch [110/200], Loss: 0.0098\n",
      "Epoch [120/200], Loss: 0.0108\n",
      "Epoch [130/200], Loss: 0.0097\n",
      "Epoch [140/200], Loss: 0.0088\n",
      "Epoch [150/200], Loss: 0.0088\n",
      "Epoch [160/200], Loss: 0.0091\n",
      "Epoch [170/200], Loss: 0.0093\n",
      "Epoch [180/200], Loss: 0.0093\n",
      "Epoch [190/200], Loss: 0.0090\n",
      "Epoch [200/200], Loss: 0.0090\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-497.911, test=-51.289) total time=  56.3s\n",
      "Epoch [10/200], Loss: 0.0218\n",
      "Epoch [20/200], Loss: 0.0146\n",
      "Epoch [30/200], Loss: 0.0095\n",
      "Epoch [40/200], Loss: 0.0078\n",
      "Epoch [50/200], Loss: 0.0065\n",
      "Epoch [60/200], Loss: 0.0057\n",
      "Epoch [70/200], Loss: 0.0051\n",
      "Epoch [80/200], Loss: 0.0045\n",
      "Epoch [90/200], Loss: 0.0042\n",
      "Epoch [100/200], Loss: 0.0039\n",
      "Epoch [110/200], Loss: 0.0036\n",
      "Epoch [120/200], Loss: 0.0035\n",
      "Epoch [130/200], Loss: 0.0032\n",
      "Epoch [140/200], Loss: 0.0030\n",
      "Epoch [150/200], Loss: 0.0029\n",
      "Epoch [160/200], Loss: 0.0028\n",
      "Epoch [170/200], Loss: 0.0028\n",
      "Epoch [180/200], Loss: 0.0025\n",
      "Epoch [190/200], Loss: 0.0024\n",
      "Epoch [200/200], Loss: 0.0024\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-452.161, test=-71.330) total time=  54.9s\n",
      "Epoch [10/200], Loss: 0.0237\n",
      "Epoch [20/200], Loss: 0.0194\n",
      "Epoch [30/200], Loss: 0.0160\n",
      "Epoch [40/200], Loss: 0.0144\n",
      "Epoch [50/200], Loss: 0.0124\n",
      "Epoch [60/200], Loss: 0.0115\n",
      "Epoch [70/200], Loss: 0.0106\n",
      "Epoch [80/200], Loss: 0.0091\n",
      "Epoch [90/200], Loss: 0.0086\n",
      "Epoch [100/200], Loss: 0.0084\n",
      "Epoch [110/200], Loss: 0.0071\n",
      "Epoch [120/200], Loss: 0.0072\n",
      "Epoch [130/200], Loss: 0.0067\n",
      "Epoch [140/200], Loss: 0.0060\n",
      "Epoch [150/200], Loss: 0.0058\n",
      "Epoch [160/200], Loss: 0.0051\n",
      "Epoch [170/200], Loss: 0.0052\n",
      "Epoch [180/200], Loss: 0.0049\n",
      "Epoch [190/200], Loss: 0.0048\n",
      "Epoch [200/200], Loss: 0.0047\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-113.658, test=-272.584) total time=  17.0s\n",
      "Epoch [10/200], Loss: 0.0218\n",
      "Epoch [20/200], Loss: 0.0164\n",
      "Epoch [30/200], Loss: 0.0126\n",
      "Epoch [40/200], Loss: 0.0104\n",
      "Epoch [50/200], Loss: 0.0086\n",
      "Epoch [60/200], Loss: 0.0075\n",
      "Epoch [70/200], Loss: 0.0065\n",
      "Epoch [80/200], Loss: 0.0058\n",
      "Epoch [90/200], Loss: 0.0052\n",
      "Epoch [100/200], Loss: 0.0048\n",
      "Epoch [110/200], Loss: 0.0045\n",
      "Epoch [120/200], Loss: 0.0044\n",
      "Epoch [130/200], Loss: 0.0042\n",
      "Epoch [140/200], Loss: 0.0039\n",
      "Epoch [150/200], Loss: 0.0038\n",
      "Epoch [160/200], Loss: 0.0035\n",
      "Epoch [170/200], Loss: 0.0034\n",
      "Epoch [180/200], Loss: 0.0032\n",
      "Epoch [190/200], Loss: 0.0032\n",
      "Epoch [200/200], Loss: 0.0031\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-410.048, test=-49.600) total time=  54.8s\n",
      "Epoch [10/200], Loss: 0.0207\n",
      "Epoch [20/200], Loss: 0.0163\n",
      "Epoch [30/200], Loss: 0.0135\n",
      "Epoch [40/200], Loss: 0.0104\n",
      "Epoch [50/200], Loss: 0.0090\n",
      "Epoch [60/200], Loss: 0.0081\n",
      "Epoch [70/200], Loss: 0.0083\n",
      "Epoch [80/200], Loss: 0.0070\n",
      "Epoch [90/200], Loss: 0.0070\n",
      "Epoch [100/200], Loss: 0.0066\n",
      "Epoch [110/200], Loss: 0.0062\n",
      "Epoch [120/200], Loss: 0.0071\n",
      "Epoch [130/200], Loss: 0.0070\n",
      "Epoch [140/200], Loss: 0.0054\n",
      "Epoch [150/200], Loss: 0.0061\n",
      "Epoch [160/200], Loss: 0.0062\n",
      "Epoch [170/200], Loss: 0.0063\n",
      "Epoch [180/200], Loss: 0.0063\n",
      "Epoch [190/200], Loss: 0.0062\n",
      "Epoch [200/200], Loss: 0.0062\n",
      "[CV 1/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-536.075, test=-76.609) total time=  31.5s\n",
      "Epoch [10/200], Loss: 0.0229\n",
      "Epoch [20/200], Loss: 0.0167\n",
      "Epoch [30/200], Loss: 0.0135\n",
      "Epoch [40/200], Loss: 0.0122\n",
      "Epoch [50/200], Loss: 0.0120\n",
      "Epoch [60/200], Loss: 0.0105\n",
      "Epoch [70/200], Loss: 0.0101\n",
      "Epoch [80/200], Loss: 0.0095\n",
      "Epoch [90/200], Loss: 0.0100\n",
      "Epoch [100/200], Loss: 0.0096\n",
      "Epoch [110/200], Loss: 0.0093\n",
      "Epoch [120/200], Loss: 0.0093\n",
      "Epoch [130/200], Loss: 0.0082\n",
      "Epoch [140/200], Loss: 0.0083\n",
      "Epoch [150/200], Loss: 0.0083\n",
      "Epoch [160/200], Loss: 0.0082\n",
      "Epoch [170/200], Loss: 0.0075\n",
      "Epoch [180/200], Loss: 0.0073\n",
      "Epoch [190/200], Loss: 0.0074\n",
      "Epoch [200/200], Loss: 0.0069\n",
      "[CV 2/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-141.971, test=-245.425) total time=   9.7s\n",
      "Epoch [10/200], Loss: 0.0228\n",
      "Epoch [20/200], Loss: 0.0174\n",
      "Epoch [30/200], Loss: 0.0153\n",
      "Epoch [40/200], Loss: 0.0137\n",
      "Epoch [50/200], Loss: 0.0128\n",
      "Epoch [60/200], Loss: 0.0118\n",
      "Epoch [70/200], Loss: 0.0105\n",
      "Epoch [80/200], Loss: 0.0104\n",
      "Epoch [90/200], Loss: 0.0098\n",
      "Epoch [100/200], Loss: 0.0096\n",
      "Epoch [110/200], Loss: 0.0085\n",
      "Epoch [120/200], Loss: 0.0082\n",
      "Epoch [130/200], Loss: 0.0081\n",
      "Epoch [140/200], Loss: 0.0084\n",
      "Epoch [150/200], Loss: 0.0080\n",
      "Epoch [160/200], Loss: 0.0079\n",
      "Epoch [170/200], Loss: 0.0080\n",
      "Epoch [180/200], Loss: 0.0077\n",
      "Epoch [190/200], Loss: 0.0076\n",
      "Epoch [200/200], Loss: 0.0079\n",
      "[CV 3/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-460.590, test=-77.960) total time=  31.4s\n",
      "Epoch [10/200], Loss: 0.0235\n",
      "Epoch [20/200], Loss: 0.0181\n",
      "Epoch [30/200], Loss: 0.0136\n",
      "Epoch [40/200], Loss: 0.0107\n",
      "Epoch [50/200], Loss: 0.0080\n",
      "Epoch [60/200], Loss: 0.0070\n",
      "Epoch [70/200], Loss: 0.0062\n",
      "Epoch [80/200], Loss: 0.0058\n",
      "Epoch [90/200], Loss: 0.0051\n",
      "Epoch [100/200], Loss: 0.0048\n",
      "Epoch [110/200], Loss: 0.0046\n",
      "Epoch [120/200], Loss: 0.0041\n",
      "Epoch [130/200], Loss: 0.0039\n",
      "Epoch [140/200], Loss: 0.0037\n",
      "Epoch [150/200], Loss: 0.0033\n",
      "Epoch [160/200], Loss: 0.0033\n",
      "Epoch [170/200], Loss: 0.0032\n",
      "Epoch [180/200], Loss: 0.0030\n",
      "Epoch [190/200], Loss: 0.0029\n",
      "Epoch [200/200], Loss: 0.0026\n",
      "[CV 1/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-590.317, test=-69.289) total time=  30.8s\n",
      "Epoch [10/200], Loss: 0.0202\n",
      "Epoch [20/200], Loss: 0.0155\n",
      "Epoch [30/200], Loss: 0.0136\n",
      "Epoch [40/200], Loss: 0.0116\n",
      "Epoch [50/200], Loss: 0.0111\n",
      "Epoch [60/200], Loss: 0.0102\n",
      "Epoch [70/200], Loss: 0.0096\n",
      "Epoch [80/200], Loss: 0.0087\n",
      "Epoch [90/200], Loss: 0.0074\n",
      "Epoch [100/200], Loss: 0.0087\n",
      "Epoch [110/200], Loss: 0.0068\n",
      "Epoch [120/200], Loss: 0.0071\n",
      "Epoch [130/200], Loss: 0.0069\n",
      "Epoch [140/200], Loss: 0.0061\n",
      "Epoch [150/200], Loss: 0.0067\n",
      "Epoch [160/200], Loss: 0.0057\n",
      "Epoch [170/200], Loss: 0.0057\n",
      "Epoch [180/200], Loss: 0.0058\n",
      "Epoch [190/200], Loss: 0.0051\n",
      "Epoch [200/200], Loss: 0.0053\n",
      "[CV 2/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-123.559, test=-223.994) total time=   9.5s\n",
      "Epoch [10/200], Loss: 0.0237\n",
      "Epoch [20/200], Loss: 0.0182\n",
      "Epoch [30/200], Loss: 0.0143\n",
      "Epoch [40/200], Loss: 0.0119\n",
      "Epoch [50/200], Loss: 0.0104\n",
      "Epoch [60/200], Loss: 0.0090\n",
      "Epoch [70/200], Loss: 0.0084\n",
      "Epoch [80/200], Loss: 0.0078\n",
      "Epoch [90/200], Loss: 0.0066\n",
      "Epoch [100/200], Loss: 0.0061\n",
      "Epoch [110/200], Loss: 0.0060\n",
      "Epoch [120/200], Loss: 0.0056\n",
      "Epoch [130/200], Loss: 0.0052\n",
      "Epoch [140/200], Loss: 0.0047\n",
      "Epoch [150/200], Loss: 0.0047\n",
      "Epoch [160/200], Loss: 0.0043\n",
      "Epoch [170/200], Loss: 0.0042\n",
      "Epoch [180/200], Loss: 0.0040\n",
      "Epoch [190/200], Loss: 0.0039\n",
      "Epoch [200/200], Loss: 0.0036\n",
      "[CV 3/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-409.651, test=-60.590) total time=  31.0s\n",
      "\n",
      "Parameter Search CV Results:\n",
      "=============================\n",
      "Best Parameters:  {'batch_size': 32, 'epochs': 200, 'l2_reg': 0.001, 'lr': 0.001}\n",
      "Best Cross-Validation Score:  -112.42072044313177\n",
      "Epoch [10/200], Loss: 0.0247\n",
      "Epoch [20/200], Loss: 0.0218\n",
      "Epoch [30/200], Loss: 0.0186\n",
      "Epoch [40/200], Loss: 0.0161\n",
      "Epoch [50/200], Loss: 0.0148\n",
      "Epoch [60/200], Loss: 0.0140\n",
      "Epoch [70/200], Loss: 0.0141\n",
      "Epoch [80/200], Loss: 0.0140\n",
      "Epoch [90/200], Loss: 0.0134\n",
      "Epoch [100/200], Loss: 0.0129\n",
      "Epoch [110/200], Loss: 0.0131\n",
      "Epoch [120/200], Loss: 0.0130\n",
      "Epoch [130/200], Loss: 0.0130\n",
      "Epoch [140/200], Loss: 0.0132\n",
      "Epoch [150/200], Loss: 0.0129\n",
      "Epoch [160/200], Loss: 0.0126\n",
      "Epoch [170/200], Loss: 0.0130\n",
      "Epoch [180/200], Loss: 0.0132\n",
      "Epoch [190/200], Loss: 0.0130\n",
      "Epoch [200/200], Loss: 0.0127\n",
      "\n",
      "Train Metrics: {'mse': 0.05106342010252817, 'mae': 0.17742411440499284, 'r2': -9.137704621181179, 'pearson_corr': 0.35237503052790115, 'connectome_corr': 0.3310116249952212, 'connectome_r2': -9.685639472274703, 'geodesic_distance': 12.019932609227286}\n",
      "Test Metrics: {'mse': 0.05077018175877098, 'mae': 0.17368601385300378, 'r2': -1.318285738694002, 'pearson_corr': 0.26765712031967376, 'connectome_corr': 0.0010321838471232117, 'connectome_r2': -2.685259036598441, 'geodesic_distance': 5.246824204526885}\n",
      "BEST VAL SCORE -112.42072044313177\n",
      "BEST MODEL PARAMS {'batch_size': 32, 'dropout': 0.05, 'epochs': 200, 'hidden_dims': [128, 64], 'input_dim': 20, 'l2_reg': 0.001, 'lr': 0.001, 'max_grad_norm': 1.0, 'output_dim': 1}\n",
      "CPU Usage: 23.2%\n",
      "RAM Usage: 19.1%\n",
      "Available RAM: 814.2G\n",
      "Total RAM: 1007.0G\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  1% |\n",
      "Simulation results have been saved.\n",
      "resolution 1.01\n",
      "seed 4\n",
      "computing eig of laplacian\n",
      "computing eig of adjacency\n",
      "Number of components explaining 95.0% of the variance: 34\n",
      "\n",
      " Test fold num: 1\n",
      "(8930, 20) (8930,) (342, 20) (342,)\n",
      "SEARCH METHOD ('grid', 'mse')\n",
      "2\n",
      "3\n",
      "4\n",
      "GPU model input size 20\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Epoch [10/200], Loss: 0.0253\n",
      "Epoch [20/200], Loss: 0.0190\n",
      "Epoch [30/200], Loss: 0.0158\n",
      "Epoch [40/200], Loss: 0.0140\n",
      "Epoch [50/200], Loss: 0.0130\n",
      "Epoch [60/200], Loss: 0.0124\n",
      "Epoch [70/200], Loss: 0.0121\n",
      "Epoch [80/200], Loss: 0.0122\n",
      "Epoch [90/200], Loss: 0.0116\n",
      "Epoch [100/200], Loss: 0.0118\n",
      "Epoch [110/200], Loss: 0.0112\n",
      "Epoch [120/200], Loss: 0.0114\n",
      "Epoch [130/200], Loss: 0.0113\n",
      "Epoch [140/200], Loss: 0.0116\n",
      "Epoch [150/200], Loss: 0.0111\n",
      "Epoch [160/200], Loss: 0.0110\n",
      "Epoch [170/200], Loss: 0.0108\n",
      "Epoch [180/200], Loss: 0.0105\n",
      "Epoch [190/200], Loss: 0.0108\n",
      "Epoch [200/200], Loss: 0.0107\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-427.667, test=-39.917) total time= 1.2min\n",
      "Epoch [10/200], Loss: 0.0202\n",
      "Epoch [20/200], Loss: 0.0174\n",
      "Epoch [30/200], Loss: 0.0160\n",
      "Epoch [40/200], Loss: 0.0131\n",
      "Epoch [50/200], Loss: 0.0109\n",
      "Epoch [60/200], Loss: 0.0113\n",
      "Epoch [70/200], Loss: 0.0093\n",
      "Epoch [80/200], Loss: 0.0080\n",
      "Epoch [90/200], Loss: 0.0071\n",
      "Epoch [100/200], Loss: 0.0071\n",
      "Epoch [110/200], Loss: 0.0070\n",
      "Epoch [120/200], Loss: 0.0065\n",
      "Epoch [130/200], Loss: 0.0068\n",
      "Epoch [140/200], Loss: 0.0066\n",
      "Epoch [150/200], Loss: 0.0066\n",
      "Epoch [160/200], Loss: 0.0062\n",
      "Epoch [170/200], Loss: 0.0065\n",
      "Epoch [180/200], Loss: 0.0056\n",
      "Epoch [190/200], Loss: 0.0057\n",
      "Epoch [200/200], Loss: 0.0058\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-147.540, test=-194.445) total time=  25.5s\n",
      "Epoch [10/200], Loss: 0.0159\n",
      "Epoch [20/200], Loss: 0.0137\n",
      "Epoch [30/200], Loss: 0.0119\n",
      "Epoch [40/200], Loss: 0.0103\n",
      "Epoch [50/200], Loss: 0.0092\n",
      "Epoch [60/200], Loss: 0.0089\n",
      "Epoch [70/200], Loss: 0.0083\n",
      "Epoch [80/200], Loss: 0.0082\n",
      "Epoch [90/200], Loss: 0.0079\n",
      "Epoch [100/200], Loss: 0.0080\n",
      "Epoch [110/200], Loss: 0.0077\n",
      "Epoch [120/200], Loss: 0.0078\n",
      "Epoch [130/200], Loss: 0.0074\n",
      "Epoch [140/200], Loss: 0.0078\n",
      "Epoch [150/200], Loss: 0.0075\n",
      "Epoch [160/200], Loss: 0.0075\n",
      "Epoch [170/200], Loss: 0.0074\n",
      "Epoch [180/200], Loss: 0.0073\n",
      "Epoch [190/200], Loss: 0.0075\n",
      "Epoch [200/200], Loss: 0.0078\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-732.421, test=-106.543) total time=  56.1s\n",
      "Epoch [10/200], Loss: 0.0248\n",
      "Epoch [20/200], Loss: 0.0165\n",
      "Epoch [30/200], Loss: 0.0116\n",
      "Epoch [40/200], Loss: 0.0093\n",
      "Epoch [50/200], Loss: 0.0076\n",
      "Epoch [60/200], Loss: 0.0068\n",
      "Epoch [70/200], Loss: 0.0061\n",
      "Epoch [80/200], Loss: 0.0056\n",
      "Epoch [90/200], Loss: 0.0054\n",
      "Epoch [100/200], Loss: 0.0049\n",
      "Epoch [110/200], Loss: 0.0046\n",
      "Epoch [120/200], Loss: 0.0041\n",
      "Epoch [130/200], Loss: 0.0039\n",
      "Epoch [140/200], Loss: 0.0040\n",
      "Epoch [150/200], Loss: 0.0037\n",
      "Epoch [160/200], Loss: 0.0038\n",
      "Epoch [170/200], Loss: 0.0038\n",
      "Epoch [180/200], Loss: 0.0035\n",
      "Epoch [190/200], Loss: 0.0034\n",
      "Epoch [200/200], Loss: 0.0032\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-340.467, test=-35.517) total time= 1.1min\n",
      "Epoch [10/200], Loss: 0.0211\n",
      "Epoch [20/200], Loss: 0.0163\n",
      "Epoch [30/200], Loss: 0.0136\n",
      "Epoch [40/200], Loss: 0.0118\n",
      "Epoch [50/200], Loss: 0.0100\n",
      "Epoch [60/200], Loss: 0.0088\n",
      "Epoch [70/200], Loss: 0.0071\n",
      "Epoch [80/200], Loss: 0.0063\n",
      "Epoch [90/200], Loss: 0.0053\n",
      "Epoch [100/200], Loss: 0.0049\n",
      "Epoch [110/200], Loss: 0.0045\n",
      "Epoch [120/200], Loss: 0.0040\n",
      "Epoch [130/200], Loss: 0.0035\n",
      "Epoch [140/200], Loss: 0.0036\n",
      "Epoch [150/200], Loss: 0.0033\n",
      "Epoch [160/200], Loss: 0.0033\n",
      "Epoch [170/200], Loss: 0.0032\n",
      "Epoch [180/200], Loss: 0.0028\n",
      "Epoch [190/200], Loss: 0.0027\n",
      "Epoch [200/200], Loss: 0.0028\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-133.992, test=-147.733) total time=  25.1s\n",
      "Epoch [10/200], Loss: 0.0161\n",
      "Epoch [20/200], Loss: 0.0120\n",
      "Epoch [30/200], Loss: 0.0097\n",
      "Epoch [40/200], Loss: 0.0078\n",
      "Epoch [50/200], Loss: 0.0068\n",
      "Epoch [60/200], Loss: 0.0060\n",
      "Epoch [70/200], Loss: 0.0052\n",
      "Epoch [80/200], Loss: 0.0047\n",
      "Epoch [90/200], Loss: 0.0043\n",
      "Epoch [100/200], Loss: 0.0038\n",
      "Epoch [110/200], Loss: 0.0035\n",
      "Epoch [120/200], Loss: 0.0032\n",
      "Epoch [130/200], Loss: 0.0032\n",
      "Epoch [140/200], Loss: 0.0030\n",
      "Epoch [150/200], Loss: 0.0030\n",
      "Epoch [160/200], Loss: 0.0027\n",
      "Epoch [170/200], Loss: 0.0025\n",
      "Epoch [180/200], Loss: 0.0024\n",
      "Epoch [190/200], Loss: 0.0023\n",
      "Epoch [200/200], Loss: 0.0022\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-311.870, test=-42.408) total time=  55.1s\n",
      "Epoch [10/200], Loss: 0.0260\n",
      "Epoch [20/200], Loss: 0.0197\n",
      "Epoch [30/200], Loss: 0.0149\n",
      "Epoch [40/200], Loss: 0.0125\n",
      "Epoch [50/200], Loss: 0.0102\n",
      "Epoch [60/200], Loss: 0.0101\n",
      "Epoch [70/200], Loss: 0.0102\n",
      "Epoch [80/200], Loss: 0.0089\n",
      "Epoch [90/200], Loss: 0.0088\n",
      "Epoch [100/200], Loss: 0.0084\n",
      "Epoch [110/200], Loss: 0.0082\n",
      "Epoch [120/200], Loss: 0.0082\n",
      "Epoch [130/200], Loss: 0.0086\n",
      "Epoch [140/200], Loss: 0.0077\n",
      "Epoch [150/200], Loss: 0.0082\n",
      "Epoch [160/200], Loss: 0.0085\n",
      "Epoch [170/200], Loss: 0.0079\n",
      "Epoch [180/200], Loss: 0.0081\n",
      "Epoch [190/200], Loss: 0.0081\n",
      "Epoch [200/200], Loss: 0.0079\n",
      "[CV 1/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-268.029, test=-47.940) total time=  40.2s\n",
      "Epoch [10/200], Loss: 0.0257\n",
      "Epoch [20/200], Loss: 0.0186\n",
      "Epoch [30/200], Loss: 0.0147\n",
      "Epoch [40/200], Loss: 0.0131\n",
      "Epoch [50/200], Loss: 0.0124\n",
      "Epoch [60/200], Loss: 0.0104\n",
      "Epoch [70/200], Loss: 0.0100\n",
      "Epoch [80/200], Loss: 0.0097\n",
      "Epoch [90/200], Loss: 0.0103\n",
      "Epoch [100/200], Loss: 0.0083\n",
      "Epoch [110/200], Loss: 0.0079\n",
      "Epoch [120/200], Loss: 0.0075\n",
      "Epoch [130/200], Loss: 0.0072\n",
      "Epoch [140/200], Loss: 0.0066\n",
      "Epoch [150/200], Loss: 0.0069\n",
      "Epoch [160/200], Loss: 0.0059\n",
      "Epoch [170/200], Loss: 0.0059\n",
      "Epoch [180/200], Loss: 0.0060\n",
      "Epoch [190/200], Loss: 0.0065\n",
      "Epoch [200/200], Loss: 0.0059\n",
      "[CV 2/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-156.747, test=-126.795) total time=  14.6s\n",
      "Epoch [10/200], Loss: 0.0155\n",
      "Epoch [20/200], Loss: 0.0128\n",
      "Epoch [30/200], Loss: 0.0113\n",
      "Epoch [40/200], Loss: 0.0100\n",
      "Epoch [50/200], Loss: 0.0092\n",
      "Epoch [60/200], Loss: 0.0081\n",
      "Epoch [70/200], Loss: 0.0075\n",
      "Epoch [80/200], Loss: 0.0069\n",
      "Epoch [90/200], Loss: 0.0066\n",
      "Epoch [100/200], Loss: 0.0060\n",
      "Epoch [110/200], Loss: 0.0059\n",
      "Epoch [120/200], Loss: 0.0063\n",
      "Epoch [130/200], Loss: 0.0057\n",
      "Epoch [140/200], Loss: 0.0056\n",
      "Epoch [150/200], Loss: 0.0056\n",
      "Epoch [160/200], Loss: 0.0058\n",
      "Epoch [170/200], Loss: 0.0052\n",
      "Epoch [180/200], Loss: 0.0058\n",
      "Epoch [190/200], Loss: 0.0056\n",
      "Epoch [200/200], Loss: 0.0057\n",
      "[CV 3/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-536.736, test=-68.657) total time=  31.7s\n",
      "Epoch [10/200], Loss: 0.0283\n",
      "Epoch [20/200], Loss: 0.0215\n",
      "Epoch [30/200], Loss: 0.0148\n",
      "Epoch [40/200], Loss: 0.0116\n",
      "Epoch [50/200], Loss: 0.0093\n",
      "Epoch [60/200], Loss: 0.0084\n",
      "Epoch [70/200], Loss: 0.0070\n",
      "Epoch [80/200], Loss: 0.0064\n",
      "Epoch [90/200], Loss: 0.0058\n",
      "Epoch [100/200], Loss: 0.0056\n",
      "Epoch [110/200], Loss: 0.0050\n",
      "Epoch [120/200], Loss: 0.0046\n",
      "Epoch [130/200], Loss: 0.0046\n",
      "Epoch [140/200], Loss: 0.0045\n",
      "Epoch [150/200], Loss: 0.0041\n",
      "Epoch [160/200], Loss: 0.0039\n",
      "Epoch [170/200], Loss: 0.0037\n",
      "Epoch [180/200], Loss: 0.0037\n",
      "Epoch [190/200], Loss: 0.0034\n",
      "Epoch [200/200], Loss: 0.0034\n",
      "[CV 1/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-308.652, test=-41.829) total time=  38.8s\n",
      "Epoch [10/200], Loss: 0.0255\n",
      "Epoch [20/200], Loss: 0.0191\n",
      "Epoch [30/200], Loss: 0.0159\n",
      "Epoch [40/200], Loss: 0.0141\n",
      "Epoch [50/200], Loss: 0.0118\n",
      "Epoch [60/200], Loss: 0.0097\n",
      "Epoch [70/200], Loss: 0.0087\n",
      "Epoch [80/200], Loss: 0.0086\n",
      "Epoch [90/200], Loss: 0.0080\n",
      "Epoch [100/200], Loss: 0.0067\n",
      "Epoch [110/200], Loss: 0.0059\n",
      "Epoch [120/200], Loss: 0.0059\n",
      "Epoch [130/200], Loss: 0.0049\n",
      "Epoch [140/200], Loss: 0.0052\n",
      "Epoch [150/200], Loss: 0.0052\n",
      "Epoch [160/200], Loss: 0.0043\n",
      "Epoch [170/200], Loss: 0.0039\n",
      "Epoch [180/200], Loss: 0.0037\n",
      "Epoch [190/200], Loss: 0.0041\n",
      "Epoch [200/200], Loss: 0.0038\n",
      "[CV 2/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-148.866, test=-138.979) total time=  14.1s\n",
      "Epoch [10/200], Loss: 0.0172\n",
      "Epoch [20/200], Loss: 0.0126\n",
      "Epoch [30/200], Loss: 0.0099\n",
      "Epoch [40/200], Loss: 0.0084\n",
      "Epoch [50/200], Loss: 0.0074\n",
      "Epoch [60/200], Loss: 0.0065\n",
      "Epoch [70/200], Loss: 0.0056\n",
      "Epoch [80/200], Loss: 0.0051\n",
      "Epoch [90/200], Loss: 0.0047\n",
      "Epoch [100/200], Loss: 0.0045\n",
      "Epoch [110/200], Loss: 0.0042\n",
      "Epoch [120/200], Loss: 0.0041\n",
      "Epoch [130/200], Loss: 0.0038\n",
      "Epoch [140/200], Loss: 0.0035\n",
      "Epoch [150/200], Loss: 0.0032\n",
      "Epoch [160/200], Loss: 0.0029\n",
      "Epoch [170/200], Loss: 0.0026\n",
      "Epoch [180/200], Loss: 0.0026\n",
      "Epoch [190/200], Loss: 0.0025\n",
      "Epoch [200/200], Loss: 0.0024\n",
      "[CV 3/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-335.778, test=-41.185) total time=  31.0s\n",
      "\n",
      "Parameter Search CV Results:\n",
      "=============================\n",
      "Best Parameters:  {'batch_size': 64, 'epochs': 200, 'l2_reg': 0, 'lr': 0.001}\n",
      "Best Cross-Validation Score:  -73.9977438086683\n",
      "Epoch [10/200], Loss: 0.0239\n",
      "Epoch [20/200], Loss: 0.0176\n",
      "Epoch [30/200], Loss: 0.0142\n",
      "Epoch [40/200], Loss: 0.0116\n",
      "Epoch [50/200], Loss: 0.0100\n",
      "Epoch [60/200], Loss: 0.0087\n",
      "Epoch [70/200], Loss: 0.0078\n",
      "Epoch [80/200], Loss: 0.0068\n",
      "Epoch [90/200], Loss: 0.0065\n",
      "Epoch [100/200], Loss: 0.0059\n",
      "Epoch [110/200], Loss: 0.0055\n",
      "Epoch [120/200], Loss: 0.0052\n",
      "Epoch [130/200], Loss: 0.0049\n",
      "Epoch [140/200], Loss: 0.0047\n",
      "Epoch [150/200], Loss: 0.0045\n",
      "Epoch [160/200], Loss: 0.0043\n",
      "Epoch [170/200], Loss: 0.0041\n",
      "Epoch [180/200], Loss: 0.0039\n",
      "Epoch [190/200], Loss: 0.0038\n",
      "Epoch [200/200], Loss: 0.0037\n",
      "\n",
      "Train Metrics: {'mse': 0.018220260142491958, 'mae': 0.1030113907397163, 'r2': -1.2605701692791065, 'pearson_corr': 0.7164875667449206, 'connectome_corr': 0.6164964562355217, 'connectome_r2': -1.36499385287906, 'geodesic_distance': 12.806282332929547}\n",
      "Test Metrics: {'mse': 0.2036531856658865, 'mae': 0.39167985888883355, 'r2': -2.362490501631928, 'pearson_corr': 0.5314672238509497, 'connectome_corr': 0.35170393362781605, 'connectome_r2': -4.794939560160529, 'geodesic_distance': 7.438157006311159}\n",
      "BEST VAL SCORE -73.9977438086683\n",
      "BEST MODEL PARAMS {'batch_size': 64, 'dropout': 0.05, 'epochs': 200, 'hidden_dims': [128, 64], 'input_dim': 20, 'l2_reg': 0, 'lr': 0.001, 'max_grad_norm': 1.0, 'output_dim': 1}\n",
      "CPU Usage: 15.8%\n",
      "RAM Usage: 19.1%\n",
      "Available RAM: 815.1G\n",
      "Total RAM: 1007.0G\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  1% |\n",
      "\n",
      " Test fold num: 2\n",
      "(8930, 20) (8930,) (342, 20) (342,)\n",
      "SEARCH METHOD ('grid', 'mse')\n",
      "1\n",
      "3\n",
      "4\n",
      "GPU model input size 20\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Epoch [10/200], Loss: 0.0251\n",
      "Epoch [20/200], Loss: 0.0182\n",
      "Epoch [30/200], Loss: 0.0148\n",
      "Epoch [40/200], Loss: 0.0129\n",
      "Epoch [50/200], Loss: 0.0129\n",
      "Epoch [60/200], Loss: 0.0117\n",
      "Epoch [70/200], Loss: 0.0115\n",
      "Epoch [80/200], Loss: 0.0114\n",
      "Epoch [90/200], Loss: 0.0109\n",
      "Epoch [100/200], Loss: 0.0112\n",
      "Epoch [110/200], Loss: 0.0109\n",
      "Epoch [120/200], Loss: 0.0111\n",
      "Epoch [130/200], Loss: 0.0106\n",
      "Epoch [140/200], Loss: 0.0109\n",
      "Epoch [150/200], Loss: 0.0116\n",
      "Epoch [160/200], Loss: 0.0108\n",
      "Epoch [170/200], Loss: 0.0107\n",
      "Epoch [180/200], Loss: 0.0110\n",
      "Epoch [190/200], Loss: 0.0107\n",
      "Epoch [200/200], Loss: 0.0105\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-381.078, test=-68.026) total time= 1.2min\n",
      "Epoch [10/200], Loss: 0.0194\n",
      "Epoch [20/200], Loss: 0.0143\n",
      "Epoch [30/200], Loss: 0.0127\n",
      "Epoch [40/200], Loss: 0.0114\n",
      "Epoch [50/200], Loss: 0.0108\n",
      "Epoch [60/200], Loss: 0.0098\n",
      "Epoch [70/200], Loss: 0.0094\n",
      "Epoch [80/200], Loss: 0.0091\n",
      "Epoch [90/200], Loss: 0.0087\n",
      "Epoch [100/200], Loss: 0.0079\n",
      "Epoch [110/200], Loss: 0.0081\n",
      "Epoch [120/200], Loss: 0.0075\n",
      "Epoch [130/200], Loss: 0.0072\n",
      "Epoch [140/200], Loss: 0.0070\n",
      "Epoch [150/200], Loss: 0.0073\n",
      "Epoch [160/200], Loss: 0.0071\n",
      "Epoch [170/200], Loss: 0.0067\n",
      "Epoch [180/200], Loss: 0.0064\n",
      "Epoch [190/200], Loss: 0.0061\n",
      "Epoch [200/200], Loss: 0.0066\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-115.361, test=-239.924) total time=  25.4s\n",
      "Epoch [10/200], Loss: 0.0216\n",
      "Epoch [20/200], Loss: 0.0191\n",
      "Epoch [30/200], Loss: 0.0169\n",
      "Epoch [40/200], Loss: 0.0149\n",
      "Epoch [50/200], Loss: 0.0139\n",
      "Epoch [60/200], Loss: 0.0121\n",
      "Epoch [70/200], Loss: 0.0120\n",
      "Epoch [80/200], Loss: 0.0105\n",
      "Epoch [90/200], Loss: 0.0109\n",
      "Epoch [100/200], Loss: 0.0105\n",
      "Epoch [110/200], Loss: 0.0104\n",
      "Epoch [120/200], Loss: 0.0104\n",
      "Epoch [130/200], Loss: 0.0098\n",
      "Epoch [140/200], Loss: 0.0096\n",
      "Epoch [150/200], Loss: 0.0095\n",
      "Epoch [160/200], Loss: 0.0090\n",
      "Epoch [170/200], Loss: 0.0097\n",
      "Epoch [180/200], Loss: 0.0093\n",
      "Epoch [190/200], Loss: 0.0093\n",
      "Epoch [200/200], Loss: 0.0099\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-441.962, test=-37.727) total time=  55.7s\n",
      "Epoch [10/200], Loss: 0.0255\n",
      "Epoch [20/200], Loss: 0.0159\n",
      "Epoch [30/200], Loss: 0.0113\n",
      "Epoch [40/200], Loss: 0.0090\n",
      "Epoch [50/200], Loss: 0.0074\n",
      "Epoch [60/200], Loss: 0.0065\n",
      "Epoch [70/200], Loss: 0.0058\n",
      "Epoch [80/200], Loss: 0.0052\n",
      "Epoch [90/200], Loss: 0.0049\n",
      "Epoch [100/200], Loss: 0.0046\n",
      "Epoch [110/200], Loss: 0.0042\n",
      "Epoch [120/200], Loss: 0.0042\n",
      "Epoch [130/200], Loss: 0.0039\n",
      "Epoch [140/200], Loss: 0.0039\n",
      "Epoch [150/200], Loss: 0.0037\n",
      "Epoch [160/200], Loss: 0.0037\n",
      "Epoch [170/200], Loss: 0.0035\n",
      "Epoch [180/200], Loss: 0.0033\n",
      "Epoch [190/200], Loss: 0.0032\n",
      "Epoch [200/200], Loss: 0.0032\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-384.997, test=-63.067) total time= 1.1min\n",
      "Epoch [10/200], Loss: 0.0198\n",
      "Epoch [20/200], Loss: 0.0154\n",
      "Epoch [30/200], Loss: 0.0121\n",
      "Epoch [40/200], Loss: 0.0109\n",
      "Epoch [50/200], Loss: 0.0098\n",
      "Epoch [60/200], Loss: 0.0086\n",
      "Epoch [70/200], Loss: 0.0079\n",
      "Epoch [80/200], Loss: 0.0069\n",
      "Epoch [90/200], Loss: 0.0064\n",
      "Epoch [100/200], Loss: 0.0059\n",
      "Epoch [110/200], Loss: 0.0056\n",
      "Epoch [120/200], Loss: 0.0050\n",
      "Epoch [130/200], Loss: 0.0048\n",
      "Epoch [140/200], Loss: 0.0047\n",
      "Epoch [150/200], Loss: 0.0043\n",
      "Epoch [160/200], Loss: 0.0039\n",
      "Epoch [170/200], Loss: 0.0037\n",
      "Epoch [180/200], Loss: 0.0035\n",
      "Epoch [190/200], Loss: 0.0034\n",
      "Epoch [200/200], Loss: 0.0034\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-117.268, test=-214.219) total time=  24.5s\n",
      "Epoch [10/200], Loss: 0.0216\n",
      "Epoch [20/200], Loss: 0.0172\n",
      "Epoch [30/200], Loss: 0.0138\n",
      "Epoch [40/200], Loss: 0.0109\n",
      "Epoch [50/200], Loss: 0.0091\n",
      "Epoch [60/200], Loss: 0.0083\n",
      "Epoch [70/200], Loss: 0.0073\n",
      "Epoch [80/200], Loss: 0.0067\n",
      "Epoch [90/200], Loss: 0.0062\n",
      "Epoch [100/200], Loss: 0.0057\n",
      "Epoch [110/200], Loss: 0.0053\n",
      "Epoch [120/200], Loss: 0.0052\n",
      "Epoch [130/200], Loss: 0.0045\n",
      "Epoch [140/200], Loss: 0.0043\n",
      "Epoch [150/200], Loss: 0.0041\n",
      "Epoch [160/200], Loss: 0.0041\n",
      "Epoch [170/200], Loss: 0.0038\n",
      "Epoch [180/200], Loss: 0.0038\n",
      "Epoch [190/200], Loss: 0.0035\n",
      "Epoch [200/200], Loss: 0.0035\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-467.453, test=-59.157) total time=  54.6s\n",
      "Epoch [10/200], Loss: 0.0259\n",
      "Epoch [20/200], Loss: 0.0202\n",
      "Epoch [30/200], Loss: 0.0159\n",
      "Epoch [40/200], Loss: 0.0133\n",
      "Epoch [50/200], Loss: 0.0119\n",
      "Epoch [60/200], Loss: 0.0101\n",
      "Epoch [70/200], Loss: 0.0096\n",
      "Epoch [80/200], Loss: 0.0087\n",
      "Epoch [90/200], Loss: 0.0094\n",
      "Epoch [100/200], Loss: 0.0094\n",
      "Epoch [110/200], Loss: 0.0090\n",
      "Epoch [120/200], Loss: 0.0090\n",
      "Epoch [130/200], Loss: 0.0084\n",
      "Epoch [140/200], Loss: 0.0090\n",
      "Epoch [150/200], Loss: 0.0087\n",
      "Epoch [160/200], Loss: 0.0085\n",
      "Epoch [170/200], Loss: 0.0086\n",
      "Epoch [180/200], Loss: 0.0083\n",
      "Epoch [190/200], Loss: 0.0086\n",
      "Epoch [200/200], Loss: 0.0085\n",
      "[CV 1/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-265.591, test=-81.476) total time=  39.6s\n",
      "Epoch [10/200], Loss: 0.0183\n",
      "Epoch [20/200], Loss: 0.0133\n",
      "Epoch [30/200], Loss: 0.0115\n",
      "Epoch [40/200], Loss: 0.0101\n",
      "Epoch [50/200], Loss: 0.0099\n",
      "Epoch [60/200], Loss: 0.0099\n",
      "Epoch [70/200], Loss: 0.0099\n",
      "Epoch [80/200], Loss: 0.0086\n",
      "Epoch [90/200], Loss: 0.0079\n",
      "Epoch [100/200], Loss: 0.0077\n",
      "Epoch [110/200], Loss: 0.0075\n",
      "Epoch [120/200], Loss: 0.0077\n",
      "Epoch [130/200], Loss: 0.0066\n",
      "Epoch [140/200], Loss: 0.0072\n",
      "Epoch [150/200], Loss: 0.0068\n",
      "Epoch [160/200], Loss: 0.0065\n",
      "Epoch [170/200], Loss: 0.0066\n",
      "Epoch [180/200], Loss: 0.0061\n",
      "Epoch [190/200], Loss: 0.0059\n",
      "Epoch [200/200], Loss: 0.0058\n",
      "[CV 2/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-200.079, test=-312.450) total time=  14.6s\n",
      "Epoch [10/200], Loss: 0.0224\n",
      "Epoch [20/200], Loss: 0.0179\n",
      "Epoch [30/200], Loss: 0.0162\n",
      "Epoch [40/200], Loss: 0.0150\n",
      "Epoch [50/200], Loss: 0.0133\n",
      "Epoch [60/200], Loss: 0.0122\n",
      "Epoch [70/200], Loss: 0.0109\n",
      "Epoch [80/200], Loss: 0.0105\n",
      "Epoch [90/200], Loss: 0.0097\n",
      "Epoch [100/200], Loss: 0.0096\n",
      "Epoch [110/200], Loss: 0.0085\n",
      "Epoch [120/200], Loss: 0.0083\n",
      "Epoch [130/200], Loss: 0.0080\n",
      "Epoch [140/200], Loss: 0.0083\n",
      "Epoch [150/200], Loss: 0.0075\n",
      "Epoch [160/200], Loss: 0.0084\n",
      "Epoch [170/200], Loss: 0.0074\n",
      "Epoch [180/200], Loss: 0.0072\n",
      "Epoch [190/200], Loss: 0.0075\n",
      "Epoch [200/200], Loss: 0.0077\n",
      "[CV 3/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-514.905, test=-55.420) total time=  32.1s\n",
      "Epoch [10/200], Loss: 0.0280\n",
      "Epoch [20/200], Loss: 0.0211\n",
      "Epoch [30/200], Loss: 0.0153\n",
      "Epoch [40/200], Loss: 0.0119\n",
      "Epoch [50/200], Loss: 0.0097\n",
      "Epoch [60/200], Loss: 0.0084\n",
      "Epoch [70/200], Loss: 0.0072\n",
      "Epoch [80/200], Loss: 0.0064\n",
      "Epoch [90/200], Loss: 0.0062\n",
      "Epoch [100/200], Loss: 0.0058\n",
      "Epoch [110/200], Loss: 0.0056\n",
      "Epoch [120/200], Loss: 0.0051\n",
      "Epoch [130/200], Loss: 0.0048\n",
      "Epoch [140/200], Loss: 0.0044\n",
      "Epoch [150/200], Loss: 0.0042\n",
      "Epoch [160/200], Loss: 0.0040\n",
      "Epoch [170/200], Loss: 0.0039\n",
      "Epoch [180/200], Loss: 0.0040\n",
      "Epoch [190/200], Loss: 0.0038\n",
      "Epoch [200/200], Loss: 0.0037\n",
      "[CV 1/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-288.561, test=-81.166) total time=  38.7s\n",
      "Epoch [10/200], Loss: 0.0180\n",
      "Epoch [20/200], Loss: 0.0132\n",
      "Epoch [30/200], Loss: 0.0117\n",
      "Epoch [40/200], Loss: 0.0100\n",
      "Epoch [50/200], Loss: 0.0087\n",
      "Epoch [60/200], Loss: 0.0086\n",
      "Epoch [70/200], Loss: 0.0079\n",
      "Epoch [80/200], Loss: 0.0072\n",
      "Epoch [90/200], Loss: 0.0072\n",
      "Epoch [100/200], Loss: 0.0066\n",
      "Epoch [110/200], Loss: 0.0061\n",
      "Epoch [120/200], Loss: 0.0057\n",
      "Epoch [130/200], Loss: 0.0059\n",
      "Epoch [140/200], Loss: 0.0056\n",
      "Epoch [150/200], Loss: 0.0049\n",
      "Epoch [160/200], Loss: 0.0050\n",
      "Epoch [170/200], Loss: 0.0050\n",
      "Epoch [180/200], Loss: 0.0046\n",
      "Epoch [190/200], Loss: 0.0043\n",
      "Epoch [200/200], Loss: 0.0044\n",
      "[CV 2/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-119.027, test=-269.723) total time=  14.5s\n",
      "Epoch [10/200], Loss: 0.0237\n",
      "Epoch [20/200], Loss: 0.0180\n",
      "Epoch [30/200], Loss: 0.0143\n",
      "Epoch [40/200], Loss: 0.0123\n",
      "Epoch [50/200], Loss: 0.0105\n",
      "Epoch [60/200], Loss: 0.0093\n",
      "Epoch [70/200], Loss: 0.0082\n",
      "Epoch [80/200], Loss: 0.0076\n",
      "Epoch [90/200], Loss: 0.0070\n",
      "Epoch [100/200], Loss: 0.0063\n",
      "Epoch [110/200], Loss: 0.0057\n",
      "Epoch [120/200], Loss: 0.0054\n",
      "Epoch [130/200], Loss: 0.0050\n",
      "Epoch [140/200], Loss: 0.0048\n",
      "Epoch [150/200], Loss: 0.0047\n",
      "Epoch [160/200], Loss: 0.0042\n",
      "Epoch [170/200], Loss: 0.0042\n",
      "Epoch [180/200], Loss: 0.0038\n",
      "Epoch [190/200], Loss: 0.0037\n",
      "Epoch [200/200], Loss: 0.0034\n",
      "[CV 3/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-365.996, test=-49.597) total time=  31.1s\n",
      "\n",
      "Parameter Search CV Results:\n",
      "=============================\n",
      "Best Parameters:  {'batch_size': 32, 'epochs': 200, 'l2_reg': 0, 'lr': 0.001}\n",
      "Best Cross-Validation Score:  -112.14780450179137\n",
      "Epoch [10/200], Loss: 0.0234\n",
      "Epoch [20/200], Loss: 0.0181\n",
      "Epoch [30/200], Loss: 0.0141\n",
      "Epoch [40/200], Loss: 0.0114\n",
      "Epoch [50/200], Loss: 0.0102\n",
      "Epoch [60/200], Loss: 0.0088\n",
      "Epoch [70/200], Loss: 0.0082\n",
      "Epoch [80/200], Loss: 0.0078\n",
      "Epoch [90/200], Loss: 0.0074\n",
      "Epoch [100/200], Loss: 0.0070\n",
      "Epoch [110/200], Loss: 0.0066\n",
      "Epoch [120/200], Loss: 0.0064\n",
      "Epoch [130/200], Loss: 0.0063\n",
      "Epoch [140/200], Loss: 0.0060\n",
      "Epoch [150/200], Loss: 0.0057\n",
      "Epoch [160/200], Loss: 0.0055\n",
      "Epoch [170/200], Loss: 0.0054\n",
      "Epoch [180/200], Loss: 0.0054\n",
      "Epoch [190/200], Loss: 0.0053\n",
      "Epoch [200/200], Loss: 0.0053\n",
      "\n",
      "Train Metrics: {'mse': 0.05275764493536941, 'mae': 0.18223730282548317, 'r2': -9.2536766982981, 'pearson_corr': 0.38837029423696107, 'connectome_corr': 0.35669560833016306, 'connectome_r2': -9.851600422579736, 'geodesic_distance': 13.425928352081373}\n",
      "Test Metrics: {'mse': 0.06273985061955556, 'mae': 0.1985290323162224, 'r2': -3.108768024069173, 'pearson_corr': 0.5798053425215446, 'connectome_corr': 0.3842090036306401, 'connectome_r2': -10.942062649028488, 'geodesic_distance': 5.002814488548128}\n",
      "BEST VAL SCORE -112.14780450179137\n",
      "BEST MODEL PARAMS {'batch_size': 32, 'dropout': 0.05, 'epochs': 200, 'hidden_dims': [128, 64], 'input_dim': 20, 'l2_reg': 0, 'lr': 0.001, 'max_grad_norm': 1.0, 'output_dim': 1}\n",
      "CPU Usage: 14.9%\n",
      "RAM Usage: 19.1%\n",
      "Available RAM: 814.6G\n",
      "Total RAM: 1007.0G\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  1% |\n",
      "\n",
      " Test fold num: 3\n",
      "(4160, 20) (4160,) (2352, 20) (2352,)\n",
      "SEARCH METHOD ('grid', 'mse')\n",
      "1\n",
      "2\n",
      "4\n",
      "GPU model input size 20\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Epoch [10/200], Loss: 0.0206\n",
      "Epoch [20/200], Loss: 0.0178\n",
      "Epoch [30/200], Loss: 0.0165\n",
      "Epoch [40/200], Loss: 0.0135\n",
      "Epoch [50/200], Loss: 0.0110\n",
      "Epoch [60/200], Loss: 0.0095\n",
      "Epoch [70/200], Loss: 0.0086\n",
      "Epoch [80/200], Loss: 0.0076\n",
      "Epoch [90/200], Loss: 0.0079\n",
      "Epoch [100/200], Loss: 0.0069\n",
      "Epoch [110/200], Loss: 0.0068\n",
      "Epoch [120/200], Loss: 0.0069\n",
      "Epoch [130/200], Loss: 0.0070\n",
      "Epoch [140/200], Loss: 0.0064\n",
      "Epoch [150/200], Loss: 0.0068\n",
      "Epoch [160/200], Loss: 0.0065\n",
      "Epoch [170/200], Loss: 0.0068\n",
      "Epoch [180/200], Loss: 0.0064\n",
      "Epoch [190/200], Loss: 0.0069\n",
      "Epoch [200/200], Loss: 0.0064\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-169.517, test=-95.293) total time=  25.8s\n",
      "Epoch [10/200], Loss: 0.0185\n",
      "Epoch [20/200], Loss: 0.0139\n",
      "Epoch [30/200], Loss: 0.0136\n",
      "Epoch [40/200], Loss: 0.0114\n",
      "Epoch [50/200], Loss: 0.0111\n",
      "Epoch [60/200], Loss: 0.0101\n",
      "Epoch [70/200], Loss: 0.0093\n",
      "Epoch [80/200], Loss: 0.0086\n",
      "Epoch [90/200], Loss: 0.0083\n",
      "Epoch [100/200], Loss: 0.0084\n",
      "Epoch [110/200], Loss: 0.0084\n",
      "Epoch [120/200], Loss: 0.0080\n",
      "Epoch [130/200], Loss: 0.0080\n",
      "Epoch [140/200], Loss: 0.0077\n",
      "Epoch [150/200], Loss: 0.0071\n",
      "Epoch [160/200], Loss: 0.0067\n",
      "Epoch [170/200], Loss: 0.0068\n",
      "Epoch [180/200], Loss: 0.0068\n",
      "Epoch [190/200], Loss: 0.0065\n",
      "Epoch [200/200], Loss: 0.0060\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-163.836, test=-27.812) total time=  25.6s\n",
      "Epoch [10/200], Loss: 0.0243\n",
      "Epoch [20/200], Loss: 0.0194\n",
      "Epoch [30/200], Loss: 0.0161\n",
      "Epoch [40/200], Loss: 0.0150\n",
      "Epoch [50/200], Loss: 0.0146\n",
      "Epoch [60/200], Loss: 0.0138\n",
      "Epoch [70/200], Loss: 0.0131\n",
      "Epoch [80/200], Loss: 0.0111\n",
      "Epoch [90/200], Loss: 0.0113\n",
      "Epoch [100/200], Loss: 0.0107\n",
      "Epoch [110/200], Loss: 0.0105\n",
      "Epoch [120/200], Loss: 0.0098\n",
      "Epoch [130/200], Loss: 0.0091\n",
      "Epoch [140/200], Loss: 0.0087\n",
      "Epoch [150/200], Loss: 0.0088\n",
      "Epoch [160/200], Loss: 0.0087\n",
      "Epoch [170/200], Loss: 0.0085\n",
      "Epoch [180/200], Loss: 0.0092\n",
      "Epoch [190/200], Loss: 0.0083\n",
      "Epoch [200/200], Loss: 0.0079\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-125.807, test=-27.856) total time=  17.5s\n",
      "Epoch [10/200], Loss: 0.0199\n",
      "Epoch [20/200], Loss: 0.0160\n",
      "Epoch [30/200], Loss: 0.0138\n",
      "Epoch [40/200], Loss: 0.0111\n",
      "Epoch [50/200], Loss: 0.0096\n",
      "Epoch [60/200], Loss: 0.0088\n",
      "Epoch [70/200], Loss: 0.0071\n",
      "Epoch [80/200], Loss: 0.0060\n",
      "Epoch [90/200], Loss: 0.0051\n",
      "Epoch [100/200], Loss: 0.0046\n",
      "Epoch [110/200], Loss: 0.0042\n",
      "Epoch [120/200], Loss: 0.0038\n",
      "Epoch [130/200], Loss: 0.0038\n",
      "Epoch [140/200], Loss: 0.0035\n",
      "Epoch [150/200], Loss: 0.0033\n",
      "Epoch [160/200], Loss: 0.0031\n",
      "Epoch [170/200], Loss: 0.0030\n",
      "Epoch [180/200], Loss: 0.0027\n",
      "Epoch [190/200], Loss: 0.0028\n",
      "Epoch [200/200], Loss: 0.0025\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-134.320, test=-90.321) total time=  24.9s\n",
      "Epoch [10/200], Loss: 0.0202\n",
      "Epoch [20/200], Loss: 0.0154\n",
      "Epoch [30/200], Loss: 0.0121\n",
      "Epoch [40/200], Loss: 0.0105\n",
      "Epoch [50/200], Loss: 0.0100\n",
      "Epoch [60/200], Loss: 0.0086\n",
      "Epoch [70/200], Loss: 0.0076\n",
      "Epoch [80/200], Loss: 0.0073\n",
      "Epoch [90/200], Loss: 0.0066\n",
      "Epoch [100/200], Loss: 0.0063\n",
      "Epoch [110/200], Loss: 0.0058\n",
      "Epoch [120/200], Loss: 0.0053\n",
      "Epoch [130/200], Loss: 0.0048\n",
      "Epoch [140/200], Loss: 0.0048\n",
      "Epoch [150/200], Loss: 0.0046\n",
      "Epoch [160/200], Loss: 0.0041\n",
      "Epoch [170/200], Loss: 0.0043\n",
      "Epoch [180/200], Loss: 0.0037\n",
      "Epoch [190/200], Loss: 0.0036\n",
      "Epoch [200/200], Loss: 0.0033\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-117.257, test=-32.513) total time=  24.9s\n",
      "Epoch [10/200], Loss: 0.0273\n",
      "Epoch [20/200], Loss: 0.0182\n",
      "Epoch [30/200], Loss: 0.0160\n",
      "Epoch [40/200], Loss: 0.0141\n",
      "Epoch [50/200], Loss: 0.0131\n",
      "Epoch [60/200], Loss: 0.0119\n",
      "Epoch [70/200], Loss: 0.0110\n",
      "Epoch [80/200], Loss: 0.0103\n",
      "Epoch [90/200], Loss: 0.0096\n",
      "Epoch [100/200], Loss: 0.0089\n",
      "Epoch [110/200], Loss: 0.0085\n",
      "Epoch [120/200], Loss: 0.0077\n",
      "Epoch [130/200], Loss: 0.0070\n",
      "Epoch [140/200], Loss: 0.0072\n",
      "Epoch [150/200], Loss: 0.0065\n",
      "Epoch [160/200], Loss: 0.0061\n",
      "Epoch [170/200], Loss: 0.0058\n",
      "Epoch [180/200], Loss: 0.0058\n",
      "Epoch [190/200], Loss: 0.0054\n",
      "Epoch [200/200], Loss: 0.0049\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-123.678, test=-27.419) total time=  16.9s\n",
      "Epoch [10/200], Loss: 0.0235\n",
      "Epoch [20/200], Loss: 0.0183\n",
      "Epoch [30/200], Loss: 0.0144\n",
      "Epoch [40/200], Loss: 0.0127\n",
      "Epoch [50/200], Loss: 0.0113\n",
      "Epoch [60/200], Loss: 0.0107\n",
      "Epoch [70/200], Loss: 0.0101\n",
      "Epoch [80/200], Loss: 0.0093\n",
      "Epoch [90/200], Loss: 0.0086\n",
      "Epoch [100/200], Loss: 0.0075\n",
      "Epoch [110/200], Loss: 0.0078\n",
      "Epoch [120/200], Loss: 0.0063\n",
      "Epoch [130/200], Loss: 0.0059\n",
      "Epoch [140/200], Loss: 0.0060\n",
      "Epoch [150/200], Loss: 0.0059\n",
      "Epoch [160/200], Loss: 0.0057\n",
      "Epoch [170/200], Loss: 0.0047\n",
      "Epoch [180/200], Loss: 0.0053\n",
      "Epoch [190/200], Loss: 0.0060\n",
      "Epoch [200/200], Loss: 0.0049\n",
      "[CV 1/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-145.378, test=-81.880) total time=  14.6s\n",
      "Epoch [10/200], Loss: 0.0172\n",
      "Epoch [20/200], Loss: 0.0132\n",
      "Epoch [30/200], Loss: 0.0112\n",
      "Epoch [40/200], Loss: 0.0098\n",
      "Epoch [50/200], Loss: 0.0092\n",
      "Epoch [60/200], Loss: 0.0090\n",
      "Epoch [70/200], Loss: 0.0087\n",
      "Epoch [80/200], Loss: 0.0083\n",
      "Epoch [90/200], Loss: 0.0075\n",
      "Epoch [100/200], Loss: 0.0080\n",
      "Epoch [110/200], Loss: 0.0075\n",
      "Epoch [120/200], Loss: 0.0069\n",
      "Epoch [130/200], Loss: 0.0073\n",
      "Epoch [140/200], Loss: 0.0060\n",
      "Epoch [150/200], Loss: 0.0069\n",
      "Epoch [160/200], Loss: 0.0061\n",
      "Epoch [170/200], Loss: 0.0057\n",
      "Epoch [180/200], Loss: 0.0064\n",
      "Epoch [190/200], Loss: 0.0059\n",
      "Epoch [200/200], Loss: 0.0055\n",
      "[CV 2/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-138.640, test=-44.740) total time=  14.6s\n",
      "Epoch [10/200], Loss: 0.0195\n",
      "Epoch [20/200], Loss: 0.0143\n",
      "Epoch [30/200], Loss: 0.0120\n",
      "Epoch [40/200], Loss: 0.0117\n",
      "Epoch [50/200], Loss: 0.0106\n",
      "Epoch [60/200], Loss: 0.0103\n",
      "Epoch [70/200], Loss: 0.0096\n",
      "Epoch [80/200], Loss: 0.0098\n",
      "Epoch [90/200], Loss: 0.0091\n",
      "Epoch [100/200], Loss: 0.0110\n",
      "Epoch [110/200], Loss: 0.0079\n",
      "Epoch [120/200], Loss: 0.0076\n",
      "Epoch [130/200], Loss: 0.0084\n",
      "Epoch [140/200], Loss: 0.0071\n",
      "Epoch [150/200], Loss: 0.0077\n",
      "Epoch [160/200], Loss: 0.0076\n",
      "Epoch [170/200], Loss: 0.0063\n",
      "Epoch [180/200], Loss: 0.0065\n",
      "Epoch [190/200], Loss: 0.0062\n",
      "Epoch [200/200], Loss: 0.0069\n",
      "[CV 3/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-124.601, test=-31.064) total time=   9.8s\n",
      "Epoch [10/200], Loss: 0.0241\n",
      "Epoch [20/200], Loss: 0.0196\n",
      "Epoch [30/200], Loss: 0.0155\n",
      "Epoch [40/200], Loss: 0.0132\n",
      "Epoch [50/200], Loss: 0.0115\n",
      "Epoch [60/200], Loss: 0.0106\n",
      "Epoch [70/200], Loss: 0.0087\n",
      "Epoch [80/200], Loss: 0.0082\n",
      "Epoch [90/200], Loss: 0.0069\n",
      "Epoch [100/200], Loss: 0.0066\n",
      "Epoch [110/200], Loss: 0.0062\n",
      "Epoch [120/200], Loss: 0.0058\n",
      "Epoch [130/200], Loss: 0.0055\n",
      "Epoch [140/200], Loss: 0.0050\n",
      "Epoch [150/200], Loss: 0.0042\n",
      "Epoch [160/200], Loss: 0.0041\n",
      "Epoch [170/200], Loss: 0.0043\n",
      "Epoch [180/200], Loss: 0.0042\n",
      "Epoch [190/200], Loss: 0.0038\n",
      "Epoch [200/200], Loss: 0.0039\n",
      "[CV 1/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-147.597, test=-92.680) total time=  14.3s\n",
      "Epoch [10/200], Loss: 0.0181\n",
      "Epoch [20/200], Loss: 0.0129\n",
      "Epoch [30/200], Loss: 0.0110\n",
      "Epoch [40/200], Loss: 0.0097\n",
      "Epoch [50/200], Loss: 0.0087\n",
      "Epoch [60/200], Loss: 0.0078\n",
      "Epoch [70/200], Loss: 0.0081\n",
      "Epoch [80/200], Loss: 0.0074\n",
      "Epoch [90/200], Loss: 0.0070\n",
      "Epoch [100/200], Loss: 0.0066\n",
      "Epoch [110/200], Loss: 0.0064\n",
      "Epoch [120/200], Loss: 0.0056\n",
      "Epoch [130/200], Loss: 0.0054\n",
      "Epoch [140/200], Loss: 0.0054\n",
      "Epoch [150/200], Loss: 0.0053\n",
      "Epoch [160/200], Loss: 0.0051\n",
      "Epoch [170/200], Loss: 0.0048\n",
      "Epoch [180/200], Loss: 0.0043\n",
      "Epoch [190/200], Loss: 0.0044\n",
      "Epoch [200/200], Loss: 0.0039\n",
      "[CV 2/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-132.886, test=-36.599) total time=  14.4s\n",
      "Epoch [10/200], Loss: 0.0200\n",
      "Epoch [20/200], Loss: 0.0151\n",
      "Epoch [30/200], Loss: 0.0131\n",
      "Epoch [40/200], Loss: 0.0110\n",
      "Epoch [50/200], Loss: 0.0097\n",
      "Epoch [60/200], Loss: 0.0091\n",
      "Epoch [70/200], Loss: 0.0088\n",
      "Epoch [80/200], Loss: 0.0082\n",
      "Epoch [90/200], Loss: 0.0072\n",
      "Epoch [100/200], Loss: 0.0066\n",
      "Epoch [110/200], Loss: 0.0068\n",
      "Epoch [120/200], Loss: 0.0065\n",
      "Epoch [130/200], Loss: 0.0067\n",
      "Epoch [140/200], Loss: 0.0061\n",
      "Epoch [150/200], Loss: 0.0062\n",
      "Epoch [160/200], Loss: 0.0060\n",
      "Epoch [170/200], Loss: 0.0052\n",
      "Epoch [180/200], Loss: 0.0050\n",
      "Epoch [190/200], Loss: 0.0048\n",
      "Epoch [200/200], Loss: 0.0045\n",
      "[CV 3/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-111.078, test=-27.609) total time=   9.4s\n",
      "\n",
      "Parameter Search CV Results:\n",
      "=============================\n",
      "Best Parameters:  {'batch_size': 32, 'epochs': 200, 'l2_reg': 0, 'lr': 0.001}\n",
      "Best Cross-Validation Score:  -50.084326999401924\n",
      "Epoch [10/200], Loss: 0.0215\n",
      "Epoch [20/200], Loss: 0.0166\n",
      "Epoch [30/200], Loss: 0.0130\n",
      "Epoch [40/200], Loss: 0.0103\n",
      "Epoch [50/200], Loss: 0.0093\n",
      "Epoch [60/200], Loss: 0.0082\n",
      "Epoch [70/200], Loss: 0.0074\n",
      "Epoch [80/200], Loss: 0.0068\n",
      "Epoch [90/200], Loss: 0.0063\n",
      "Epoch [100/200], Loss: 0.0059\n",
      "Epoch [110/200], Loss: 0.0054\n",
      "Epoch [120/200], Loss: 0.0051\n",
      "Epoch [130/200], Loss: 0.0048\n",
      "Epoch [140/200], Loss: 0.0044\n",
      "Epoch [150/200], Loss: 0.0043\n",
      "Epoch [160/200], Loss: 0.0040\n",
      "Epoch [170/200], Loss: 0.0038\n",
      "Epoch [180/200], Loss: 0.0035\n",
      "Epoch [190/200], Loss: 0.0036\n",
      "Epoch [200/200], Loss: 0.0034\n",
      "\n",
      "Train Metrics: {'mse': 0.022328660559339387, 'mae': 0.10879452643638796, 'r2': -0.004006841803231011, 'pearson_corr': 0.6516978933618037, 'connectome_corr': 0.6207027015075497, 'connectome_r2': -0.11108837701387934, 'geodesic_distance': 7.358211240490762}\n",
      "Test Metrics: {'mse': 0.0313619542059771, 'mae': 0.14188355599085248, 'r2': -12.453074423813904, 'pearson_corr': 0.4778766161171019, 'connectome_corr': 0.3841057207420934, 'connectome_r2': -13.601026471955251, 'geodesic_distance': 9.283223509108042}\n",
      "BEST VAL SCORE -50.084326999401924\n",
      "BEST MODEL PARAMS {'batch_size': 32, 'dropout': 0.05, 'epochs': 200, 'hidden_dims': [128, 64], 'input_dim': 20, 'l2_reg': 0, 'lr': 0.001, 'max_grad_norm': 1.0, 'output_dim': 1}\n",
      "CPU Usage: 15.8%\n",
      "RAM Usage: 19.7%\n",
      "Available RAM: 808.3G\n",
      "Total RAM: 1007.0G\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  1% |\n",
      "\n",
      " Test fold num: 4\n",
      "(7482, 20) (7482,) (702, 20) (702,)\n",
      "SEARCH METHOD ('grid', 'mse')\n",
      "1\n",
      "2\n",
      "3\n",
      "GPU model input size 20\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Epoch [10/200], Loss: 0.0154\n",
      "Epoch [20/200], Loss: 0.0134\n",
      "Epoch [30/200], Loss: 0.0116\n",
      "Epoch [40/200], Loss: 0.0104\n",
      "Epoch [50/200], Loss: 0.0098\n",
      "Epoch [60/200], Loss: 0.0089\n",
      "Epoch [70/200], Loss: 0.0081\n",
      "Epoch [80/200], Loss: 0.0082\n",
      "Epoch [90/200], Loss: 0.0079\n",
      "Epoch [100/200], Loss: 0.0078\n",
      "Epoch [110/200], Loss: 0.0077\n",
      "Epoch [120/200], Loss: 0.0073\n",
      "Epoch [130/200], Loss: 0.0075\n",
      "Epoch [140/200], Loss: 0.0074\n",
      "Epoch [150/200], Loss: 0.0075\n",
      "Epoch [160/200], Loss: 0.0074\n",
      "Epoch [170/200], Loss: 0.0068\n",
      "Epoch [180/200], Loss: 0.0075\n",
      "Epoch [190/200], Loss: 0.0073\n",
      "Epoch [200/200], Loss: 0.0076\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-544.140, test=-60.379) total time=  56.8s\n",
      "Epoch [10/200], Loss: 0.0222\n",
      "Epoch [20/200], Loss: 0.0197\n",
      "Epoch [30/200], Loss: 0.0166\n",
      "Epoch [40/200], Loss: 0.0147\n",
      "Epoch [50/200], Loss: 0.0127\n",
      "Epoch [60/200], Loss: 0.0128\n",
      "Epoch [70/200], Loss: 0.0116\n",
      "Epoch [80/200], Loss: 0.0105\n",
      "Epoch [90/200], Loss: 0.0106\n",
      "Epoch [100/200], Loss: 0.0107\n",
      "Epoch [110/200], Loss: 0.0104\n",
      "Epoch [120/200], Loss: 0.0096\n",
      "Epoch [130/200], Loss: 0.0105\n",
      "Epoch [140/200], Loss: 0.0096\n",
      "Epoch [150/200], Loss: 0.0099\n",
      "Epoch [160/200], Loss: 0.0100\n",
      "Epoch [170/200], Loss: 0.0088\n",
      "Epoch [180/200], Loss: 0.0096\n",
      "Epoch [190/200], Loss: 0.0093\n",
      "Epoch [200/200], Loss: 0.0091\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-328.078, test=-58.009) total time=  56.9s\n",
      "Epoch [10/200], Loss: 0.0233\n",
      "Epoch [20/200], Loss: 0.0169\n",
      "Epoch [30/200], Loss: 0.0159\n",
      "Epoch [40/200], Loss: 0.0142\n",
      "Epoch [50/200], Loss: 0.0140\n",
      "Epoch [60/200], Loss: 0.0122\n",
      "Epoch [70/200], Loss: 0.0120\n",
      "Epoch [80/200], Loss: 0.0119\n",
      "Epoch [90/200], Loss: 0.0125\n",
      "Epoch [100/200], Loss: 0.0101\n",
      "Epoch [110/200], Loss: 0.0091\n",
      "Epoch [120/200], Loss: 0.0094\n",
      "Epoch [130/200], Loss: 0.0104\n",
      "Epoch [140/200], Loss: 0.0094\n",
      "Epoch [150/200], Loss: 0.0077\n",
      "Epoch [160/200], Loss: 0.0087\n",
      "Epoch [170/200], Loss: 0.0074\n",
      "Epoch [180/200], Loss: 0.0071\n",
      "Epoch [190/200], Loss: 0.0068\n",
      "Epoch [200/200], Loss: 0.0079\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-179.658, test=-323.496) total time=  17.4s\n",
      "Epoch [10/200], Loss: 0.0155\n",
      "Epoch [20/200], Loss: 0.0117\n",
      "Epoch [30/200], Loss: 0.0093\n",
      "Epoch [40/200], Loss: 0.0076\n",
      "Epoch [50/200], Loss: 0.0066\n",
      "Epoch [60/200], Loss: 0.0056\n",
      "Epoch [70/200], Loss: 0.0051\n",
      "Epoch [80/200], Loss: 0.0043\n",
      "Epoch [90/200], Loss: 0.0043\n",
      "Epoch [100/200], Loss: 0.0039\n",
      "Epoch [110/200], Loss: 0.0037\n",
      "Epoch [120/200], Loss: 0.0035\n",
      "Epoch [130/200], Loss: 0.0033\n",
      "Epoch [140/200], Loss: 0.0032\n",
      "Epoch [150/200], Loss: 0.0032\n",
      "Epoch [160/200], Loss: 0.0029\n",
      "Epoch [170/200], Loss: 0.0027\n",
      "Epoch [180/200], Loss: 0.0026\n",
      "Epoch [190/200], Loss: 0.0027\n",
      "Epoch [200/200], Loss: 0.0025\n",
      "[CV 1/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-377.121, test=-73.223) total time=  55.1s\n",
      "Epoch [10/200], Loss: 0.0218\n",
      "Epoch [20/200], Loss: 0.0168\n",
      "Epoch [30/200], Loss: 0.0138\n",
      "Epoch [40/200], Loss: 0.0115\n",
      "Epoch [50/200], Loss: 0.0096\n",
      "Epoch [60/200], Loss: 0.0083\n",
      "Epoch [70/200], Loss: 0.0071\n",
      "Epoch [80/200], Loss: 0.0065\n",
      "Epoch [90/200], Loss: 0.0063\n",
      "Epoch [100/200], Loss: 0.0052\n",
      "Epoch [110/200], Loss: 0.0048\n",
      "Epoch [120/200], Loss: 0.0046\n",
      "Epoch [130/200], Loss: 0.0044\n",
      "Epoch [140/200], Loss: 0.0040\n",
      "Epoch [150/200], Loss: 0.0038\n",
      "Epoch [160/200], Loss: 0.0036\n",
      "Epoch [170/200], Loss: 0.0038\n",
      "Epoch [180/200], Loss: 0.0034\n",
      "Epoch [190/200], Loss: 0.0032\n",
      "Epoch [200/200], Loss: 0.0031\n",
      "[CV 2/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-443.034, test=-66.872) total time=  55.3s\n",
      "Epoch [10/200], Loss: 0.0238\n",
      "Epoch [20/200], Loss: 0.0185\n",
      "Epoch [30/200], Loss: 0.0157\n",
      "Epoch [40/200], Loss: 0.0141\n",
      "Epoch [50/200], Loss: 0.0122\n",
      "Epoch [60/200], Loss: 0.0124\n",
      "Epoch [70/200], Loss: 0.0108\n",
      "Epoch [80/200], Loss: 0.0100\n",
      "Epoch [90/200], Loss: 0.0096\n",
      "Epoch [100/200], Loss: 0.0086\n",
      "Epoch [110/200], Loss: 0.0084\n",
      "Epoch [120/200], Loss: 0.0072\n",
      "Epoch [130/200], Loss: 0.0065\n",
      "Epoch [140/200], Loss: 0.0065\n",
      "Epoch [150/200], Loss: 0.0060\n",
      "Epoch [160/200], Loss: 0.0057\n",
      "Epoch [170/200], Loss: 0.0051\n",
      "Epoch [180/200], Loss: 0.0051\n",
      "Epoch [190/200], Loss: 0.0046\n",
      "Epoch [200/200], Loss: 0.0043\n",
      "[CV 3/3] END batch_size=32, epochs=200, l2_reg=0, lr=0.001;, score=(train=-154.143, test=-327.498) total time=  16.9s\n",
      "Epoch [10/200], Loss: 0.0165\n",
      "Epoch [20/200], Loss: 0.0123\n",
      "Epoch [30/200], Loss: 0.0110\n",
      "Epoch [40/200], Loss: 0.0097\n",
      "Epoch [50/200], Loss: 0.0092\n",
      "Epoch [60/200], Loss: 0.0077\n",
      "Epoch [70/200], Loss: 0.0070\n",
      "Epoch [80/200], Loss: 0.0064\n",
      "Epoch [90/200], Loss: 0.0064\n",
      "Epoch [100/200], Loss: 0.0062\n",
      "Epoch [110/200], Loss: 0.0061\n",
      "Epoch [120/200], Loss: 0.0061\n",
      "Epoch [130/200], Loss: 0.0060\n",
      "Epoch [140/200], Loss: 0.0055\n",
      "Epoch [150/200], Loss: 0.0061\n",
      "Epoch [160/200], Loss: 0.0055\n",
      "Epoch [170/200], Loss: 0.0051\n",
      "Epoch [180/200], Loss: 0.0056\n",
      "Epoch [190/200], Loss: 0.0061\n",
      "Epoch [200/200], Loss: 0.0054\n",
      "[CV 1/3] END batch_size=64, epochs=200, l2_reg=0.001, lr=0.001;, score=(train=-466.619, test=-63.686) total time=  32.1s\n",
      "Epoch [10/200], Loss: 0.0223\n",
      "Epoch [20/200], Loss: 0.0181\n",
      "Epoch [30/200], Loss: 0.0166\n",
      "Epoch [140/200], Loss: 0.0047\n",
      "Epoch [150/200], Loss: 0.0046\n",
      "Epoch [160/200], Loss: 0.0043\n",
      "Epoch [170/200], Loss: 0.0041\n",
      "Epoch [180/200], Loss: 0.0039\n",
      "Epoch [190/200], Loss: 0.0039\n",
      "Epoch [200/200], Loss: 0.0035\n",
      "[CV 2/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-350.023, test=-46.627) total time=  31.0s\n",
      "Epoch [10/200], Loss: 0.0186\n",
      "Epoch [20/200], Loss: 0.0139\n",
      "Epoch [30/200], Loss: 0.0121\n",
      "Epoch [40/200], Loss: 0.0108\n",
      "Epoch [50/200], Loss: 0.0092\n",
      "Epoch [60/200], Loss: 0.0096\n",
      "Epoch [70/200], Loss: 0.0090\n",
      "Epoch [80/200], Loss: 0.0081\n",
      "Epoch [90/200], Loss: 0.0070\n",
      "Epoch [100/200], Loss: 0.0075\n",
      "Epoch [110/200], Loss: 0.0070\n",
      "Epoch [120/200], Loss: 0.0063\n",
      "Epoch [130/200], Loss: 0.0064\n",
      "Epoch [140/200], Loss: 0.0061\n",
      "Epoch [150/200], Loss: 0.0054\n",
      "Epoch [160/200], Loss: 0.0058\n",
      "Epoch [170/200], Loss: 0.0047\n",
      "Epoch [180/200], Loss: 0.0047\n",
      "Epoch [190/200], Loss: 0.0048\n",
      "Epoch [200/200], Loss: 0.0044\n",
      "[CV 3/3] END batch_size=64, epochs=200, l2_reg=0, lr=0.001;, score=(train=-122.656, test=-301.660) total time=   9.8s\n",
      "\n",
      "Parameter Search CV Results:\n",
      "=============================\n",
      "Best Parameters:  {'batch_size': 64, 'epochs': 200, 'l2_reg': 0.001, 'lr': 0.001}\n",
      "Best Cross-Validation Score:  -127.65608912954706\n",
      "Epoch [10/200], Loss: 0.0193\n",
      "Epoch [20/200], Loss: 0.0165\n",
      "Epoch [30/200], Loss: 0.0154\n",
      "Epoch [40/200], Loss: 0.0140\n",
      "Epoch [50/200], Loss: 0.0131\n",
      "Epoch [60/200], Loss: 0.0118\n",
      "Epoch [70/200], Loss: 0.0113\n",
      "Epoch [80/200], Loss: 0.0110\n",
      "Epoch [90/200], Loss: 0.0103\n",
      "Epoch [100/200], Loss: 0.0101\n",
      "Epoch [110/200], Loss: 0.0104\n",
      "Epoch [120/200], Loss: 0.0099\n",
      "Epoch [130/200], Loss: 0.0099\n",
      "Epoch [140/200], Loss: 0.0098\n",
      "Epoch [150/200], Loss: 0.0100\n",
      "Epoch [160/200], Loss: 0.0091\n",
      "Epoch [170/200], Loss: 0.0093\n",
      "Epoch [180/200], Loss: 0.0091\n",
      "Epoch [190/200], Loss: 0.0092\n",
      "Epoch [200/200], Loss: 0.0092\n",
      "\n",
      "Train Metrics: {'mse': 0.09115714811526686, 'mae': 0.22307868994562957, 'r2': -7.593857614088717, 'pearson_corr': 0.5414749683892565, 'connectome_corr': 0.43704860123995776, 'connectome_r2': -8.00521210046245, 'geodesic_distance': 10.459753967376173}\n",
      "Test Metrics: {'mse': 0.12786529580289893, 'mae': 0.2939439519396404, 'r2': -4.817025542565129, 'pearson_corr': 0.4660192338807159, 'connectome_corr': 0.242925124722804, 'connectome_r2': -8.27589352358587, 'geodesic_distance': 4.876808971704795}\n",
      "BEST VAL SCORE -127.65608912954706\n",
      "BEST MODEL PARAMS {'batch_size': 64, 'dropout': 0.05, 'epochs': 200, 'hidden_dims': [128, 64], 'input_dim': 20, 'l2_reg': 0.001, 'lr': 0.001, 'max_grad_norm': 1.0, 'output_dim': 1}\n",
      "CPU Usage: 23.9%\n",
      "RAM Usage: 19.3%\n",
      "Available RAM: 812.6G\n",
      "Total RAM: 1007.0G\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  1% |\n",
      "Simulation results have been saved.\n",
      "resolution 1.01\n",
      "seed 5\n",
      "computing eig of laplacian\n",
      "computing eig of adjacency\n",
      "Number of components explaining 95.0% of the variance: 34\n",
      "\n",
      " Test fold num: 1\n",
      "(8930, 20) (8930,) (342, 20) (342,)\n",
      "SEARCH METHOD ('grid', 'mse')\n",
      "2\n",
      "3\n",
      "GPU model input size 20\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    }
   ],
   "source": [
    "resolutions = [1.01]\n",
    "seeds = [1, 2, 4, 5, 42]\n",
    "\n",
    "for r in resolutions:\n",
    "    for s in seeds:\n",
    "        print('resolution', r)\n",
    "        print('seed', s)\n",
    "        single_sim_run(\n",
    "            cv_type='community',\n",
    "            random_seed=s,\n",
    "            resolution=r,\n",
    "            model_type='mlp',\n",
    "            feature_type=['structural_spectralA'],\n",
    "            summary_measure='10', # 10 or 20 are the candidates here (start with 10)\n",
    "            use_gpu=True,\n",
    "            use_shared_regions=False,\n",
    "            test_shared_regions=False,\n",
    "            save_sim=True,\n",
    "            search_method=('grid', 'mse')\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae109a0",
   "metadata": {},
   "source": [
    "Genetics + SpectralA MLP runs for community splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ddff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolutions = [1.01]\n",
    "seeds = [1, 2, 4, 5, 42]\n",
    "\n",
    "for r in resolutions:\n",
    "    for s in seeds:\n",
    "        print('resolution', r)\n",
    "        print('seed', s)\n",
    "        single_sim_run(\n",
    "            cv_type='community',\n",
    "            random_seed=s,\n",
    "            resolution=r,\n",
    "            model_type='mlp',\n",
    "            feature_type=['transcriptome', 'structural_spectralA'],\n",
    "            summary_measure='10', # 10 or 20 are the candidates here (start with 10)\n",
    "            use_gpu=True,\n",
    "            use_shared_regions=False,\n",
    "            test_shared_regions=False,\n",
    "            save_sim=True,\n",
    "            search_method=('grid', 'mse')\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d6122",
   "metadata": {},
   "source": [
    "SpectralA linear model runs for community splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44400d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolution 1.01\n",
      "seed 1\n",
      "computing eig of laplacian\n",
      "computing eig of adjacency\n",
      "Number of components explaining 95.0% of the variance: 34\n",
      "\n",
      " Test fold num: 1\n",
      "(6320, 20) (6320,) (1122, 20) (1122,)\n",
      "SEARCH METHOD ('grid', 'mse')\n",
      "2\n",
      "3\n",
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "[CV 1/2] END .............alpha=0, solver=auto;, score=-0.078 total time=   0.0s\n",
      "[CV 2/2] END .............alpha=0, solver=auto;, score=-0.063 total time=   0.0s\n",
      "[CV 1/2] END .........alpha=0.001, solver=auto;, score=-0.078 total time=   0.0s\n",
      "[CV 2/2] END .........alpha=0.001, solver=auto;, score=-0.063 total time=   0.0s\n",
      "[CV 1/2] END ..........alpha=0.01, solver=auto;, score=-0.078 total time=   0.0s\n",
      "[CV 2/2] END ..........alpha=0.01, solver=auto;, score=-0.063 total time=   0.0s\n",
      "[CV 1/2] END ...........alpha=0.1, solver=auto;, score=-0.077 total time=   0.0s\n",
      "[CV 2/2] END ...........alpha=0.1, solver=auto;, score=-0.064 total time=   0.0s\n",
      "[CV 1/2] END ...........alpha=1.0, solver=auto;, score=-0.070 total time=   0.0s\n",
      "[CV 2/2] END ...........alpha=1.0, solver=auto;, score=-0.070 total time=   0.0s\n",
      "[CV 1/2] END ............alpha=10, solver=auto;, score=-0.059 total time=   0.0s\n",
      "[CV 2/2] END ............alpha=10, solver=auto;, score=-0.084 total time=   0.0s\n",
      "[CV 1/2] END ...........alpha=100, solver=auto;, score=-0.072 total time=   0.0s\n",
      "[CV 2/2] END ...........alpha=100, solver=auto;, score=-0.092 total time=   0.0s\n",
      "[CV 1/2] END ..........alpha=1000, solver=auto;, score=-0.080 total time=   0.0s\n",
      "[CV 2/2] END ..........alpha=1000, solver=auto;, score=-0.093 total time=   0.0s\n",
      "\n",
      "Parameter Search CV Results:\n",
      "=============================\n",
      "Best Parameters:  {'alpha': 1.0, 'solver': 'auto'}\n",
      "Best Cross-Validation Score:  -0.07003627462348766\n",
      "\n",
      "Train Metrics: {'mse': 0.02488147785297358, 'mae': 0.11849918012678448, 'r2': -2.781344924149053, 'pearson_corr': 0.47991033589746457, 'connectome_corr': 0.3451356911720517, 'connectome_r2': -2.9823160739762886, 'geodesic_distance': 12.603824608504123}\n",
      "Test Metrics: {'mse': 0.14117814730368244, 'mae': 0.3056269441983176, 'r2': -2.145829107561798, 'pearson_corr': 0.37441338882034525, 'connectome_corr': 0.3021509941715073, 'connectome_r2': -2.822493306396843, 'geodesic_distance': 11.423359911615275}\n",
      "BEST VAL SCORE -0.07003627462348766\n",
      "BEST MODEL PARAMS {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}\n",
      "CPU Usage: 22.8%\n",
      "RAM Usage: 17.6%\n",
      "Available RAM: 310.9G\n",
      "Total RAM: 377.1G\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "\n",
      " Test fold num: 2\n",
      "(6806, 20) (6806,) (930, 20) (930,)\n",
      "SEARCH METHOD ('grid', 'mse')\n",
      "1\n",
      "3\n",
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "[CV 1/2] END .............alpha=0, solver=auto;, score=-0.225 total time=   0.0s\n",
      "[CV 2/2] END .............alpha=0, solver=auto;, score=-0.177 total time=   0.0s\n",
      "[CV 1/2] END .........alpha=0.001, solver=auto;, score=-0.225 total time=   0.0s\n",
      "[CV 2/2] END .........alpha=0.001, solver=auto;, score=-0.176 total time=   0.0s\n",
      "[CV 1/2] END ..........alpha=0.01, solver=auto;, score=-0.224 total time=   0.0s\n",
      "[CV 2/2] END ..........alpha=0.01, solver=auto;, score=-0.172 total time=   0.0s\n",
      "[CV 1/2] END ...........alpha=0.1, solver=auto;, score=-0.221 total time=   0.0s\n",
      "[CV 2/2] END ...........alpha=0.1, solver=auto;, score=-0.145 total time=   0.0s\n",
      "[CV 1/2] END ...........alpha=1.0, solver=auto;, score=-0.199 total time=   0.0s\n",
      "[CV 2/2] END ...........alpha=1.0, solver=auto;, score=-0.092 total time=   0.0s\n",
      "[CV 1/2] END ............alpha=10, solver=auto;, score=-0.142 total time=   0.0s\n",
      "[CV 2/2] END ............alpha=10, solver=auto;, score=-0.083 total time=   0.0s\n",
      "[CV 1/2] END ...........alpha=100, solver=auto;, score=-0.115 total time=   0.0s\n",
      "[CV 2/2] END ...........alpha=100, solver=auto;, score=-0.089 total time=   0.0s\n",
      "[CV 1/2] END ..........alpha=1000, solver=auto;, score=-0.111 total time=   0.0s\n",
      "[CV 2/2] END ..........alpha=1000, solver=auto;, score=-0.091 total time=   0.0s\n",
      "\n",
      "Parameter Search CV Results:\n",
      "=============================\n",
      "Best Parameters:  {'alpha': 1000, 'solver': 'auto'}\n",
      "Best Cross-Validation Score:  -0.10110201298606845\n",
      "\n",
      "Train Metrics: {'mse': 0.033703597696778664, 'mae': 0.13480008320737705, 'r2': -9.618330191435602, 'pearson_corr': 0.2031459183633031, 'connectome_corr': 0.3028379445711472, 'connectome_r2': -10.210002560431816, 'geodesic_distance': 12.493890513240324}\n",
      "Test Metrics: {'mse': 0.0734246387075227, 'mae': 0.2287373447107125, 'r2': -2.1148633127818623, 'pearson_corr': 0.514734387561776, 'connectome_corr': 0.0352817268512121, 'connectome_r2': -3.7422938570238897, 'geodesic_distance': 6.49604605641125}\n",
      "BEST VAL SCORE -0.10110201298606845\n",
      "BEST MODEL PARAMS {'alpha': 1000, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}\n",
      "CPU Usage: 24.0%\n",
      "RAM Usage: 17.5%\n",
      "Available RAM: 311.0G\n",
      "Total RAM: 377.1G\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "\n",
      " Test fold num: 3\n",
      "(4160, 20) (4160,) (2352, 20) (2352,)\n",
      "SEARCH METHOD ('grid', 'mse')\n",
      "1\n",
      "2\n",
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "[CV 1/2] END .............alpha=0, solver=auto;, score=-0.053 total time=   0.0s\n",
      "[CV 2/2] END .............alpha=0, solver=auto;, score=-0.160 total time=   0.0s\n",
      "[CV 1/2] END .........alpha=0.001, solver=auto;, score=-0.053 total time=   0.0s\n",
      "[CV 2/2] END .........alpha=0.001, solver=auto;, score=-0.160 total time=   0.0s\n",
      "[CV 1/2] END ..........alpha=0.01, solver=auto;, score=-0.053 total time=   0.0s\n",
      "[CV 2/2] END ..........alpha=0.01, solver=auto;, score=-0.156 total time=   0.0s\n",
      "[CV 1/2] END ...........alpha=0.1, solver=auto;, score=-0.052 total time=   0.0s\n",
      "[CV 2/2] END ...........alpha=0.1, solver=auto;, score=-0.129 total time=   0.0s\n",
      "[CV 1/2] END ...........alpha=1.0, solver=auto;, score=-0.052 total time=   0.0s\n",
      "[CV 2/2] END ...........alpha=1.0, solver=auto;, score=-0.057 total time=   0.0s\n",
      "[CV 1/2] END ............alpha=10, solver=auto;, score=-0.053 total time=   0.0s\n",
      "[CV 2/2] END ............alpha=10, solver=auto;, score=-0.022 total time=   0.0s\n",
      "[CV 1/2] END ...........alpha=100, solver=auto;, score=-0.053 total time=   0.0s\n",
      "[CV 2/2] END ...........alpha=100, solver=auto;, score=-0.021 total time=   0.0s\n",
      "[CV 1/2] END ..........alpha=1000, solver=auto;, score=-0.053 total time=   0.0s\n",
      "[CV 2/2] END ..........alpha=1000, solver=auto;, score=-0.021 total time=   0.0s\n",
      "\n",
      "Parameter Search CV Results:\n",
      "=============================\n",
      "Best Parameters:  {'alpha': 100, 'solver': 'auto'}\n",
      "Best Cross-Validation Score:  -0.03663943747348923\n",
      "\n",
      "Train Metrics: {'mse': 0.03085520313555442, 'mae': 0.12731214614393044, 'r2': -3.366379699068535, 'pearson_corr': 0.32362932520119597, 'connectome_corr': 0.2420585548336433, 'connectome_r2': -3.704484257294372, 'geodesic_distance': 8.101812643630035}\n",
      "Test Metrics: {'mse': 0.059088250456185654, 'mae': 0.2159687723641121, 'r2': -39.77099826581573, 'pearson_corr': 0.25347958522146263, 'connectome_corr': 0.2712499492026379, 'connectome_r2': -43.15450456556858, 'geodesic_distance': 8.125096378261441}\n",
      "BEST VAL SCORE -0.03663943747348923\n",
      "BEST MODEL PARAMS {'alpha': 100, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}\n",
      "CPU Usage: 24.7%\n",
      "RAM Usage: 17.5%\n",
      "Available RAM: 311.1G\n",
      "Total RAM: 377.1G\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "Simulation results have been saved.\n",
      "resolution 1.01\n",
      "seed 2\n",
      "computing eig of laplacian\n",
      "computing eig of adjacency\n"
     ]
    }
   ],
   "source": [
    "# RIDGE\n",
    "\n",
    "resolutions = [1.01]\n",
    "seeds = [1, 2, 4, 5, 42]\n",
    "\n",
    "for r in resolutions:\n",
    "    for s in seeds:\n",
    "        print('resolution', r)\n",
    "        print('seed', s)\n",
    "        single_sim_run(\n",
    "            cv_type='community',\n",
    "            random_seed=s,\n",
    "            resolution=r,\n",
    "            model_type='ridge',\n",
    "            feature_type=['structural_spectralA'],\n",
    "            summary_measure='10', # 10 or 20 are the candidates here (start with 10)\n",
    "            use_gpu=False,\n",
    "            use_shared_regions=False,\n",
    "            test_shared_regions=False,\n",
    "            save_sim=True,\n",
    "            search_method=('grid', 'mse')\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf77e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLS\n",
    "\n",
    "resolutions = [1.01]\n",
    "seeds = [1, 2, 4, 5, 42]\n",
    "\n",
    "for r in resolutions:\n",
    "    for s in seeds:\n",
    "        print('resolution', r)\n",
    "        print('seed', s)\n",
    "        single_sim_run(\n",
    "            cv_type='community',\n",
    "            random_seed=s,\n",
    "            resolution=r,\n",
    "            model_type='pls',\n",
    "            feature_type=['structural_spectralA'],\n",
    "            summary_measure='10', # 10 or 20 are the candidates here (start with 10)\n",
    "            use_gpu=False,\n",
    "            use_shared_regions=False,\n",
    "            test_shared_regions=False,\n",
    "            save_sim=True,\n",
    "            search_method=('grid', 'mse')\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cab035",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd46d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "main_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
