{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98363b8f-1d61-429d-865a-3d8213cf3406",
   "metadata": {},
   "source": [
    "## Sim Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83562164-b395-4948-85bd-0cc2a4d2c0e9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25060b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b29dd74e-acf1-4701-bb72-ce3701d3d123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/enigmatoolbox-2.0.3-py3.11.egg/enigmatoolbox/utils/useful.py:10: PendingDeprecationWarning: Importing from numpy.matlib is deprecated since 1.19.0. The matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray. \n",
      "  import numpy.matlib as npm\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/enigmatoolbox-2.0.3-py3.11.egg/enigmatoolbox/plotting/colormaps.py:6: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  autumn = cm.get_cmap('autumn', 256)\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/enigmatoolbox-2.0.3-py3.11.egg/enigmatoolbox/plotting/colormaps.py:8: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  winter = cm.get_cmap('winter_r', 256)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from env.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566563ca-070f-4671-a98a-338fea600261",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data.data_utils' from '/scratch/asr655/neuroinformatics/GeneEx2Conn/data/data_utils.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import data\n",
    "\n",
    "import models\n",
    "import sim.sim\n",
    "import sim.sim_utils\n",
    "from sim.sim_utils import bytes2human, print_system_usage\n",
    "from sim.sim import Simulation\n",
    "from sim.sim_run import single_sim_run\n",
    "\n",
    "importlib.reload(sim.sim)\n",
    "importlib.reload(sim.sim_run)\n",
    "importlib.reload(models.train_val)\n",
    "importlib.reload(data.data_utils)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa8bad-5d12-46eb-a39f-18057f3923d7",
   "metadata": {},
   "source": [
    "#### Check job specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b7c8d67-a18c-4208-b20f-8ba13fd58e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage: 2.5%\n",
      "RAM Usage: 3.9%\n",
      "Available RAM: 1.4T\n",
      "Total RAM: 1.5T\n",
      "52.4G\n"
     ]
    }
   ],
   "source": [
    "print_system_usage()\n",
    "\n",
    "total = psutil.disk_usage('/').total\n",
    "print(bytes2human(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e4c0fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Available GPUs: 1\n",
      "GPU 0: NVIDIA H100 80GB HBM3 - Memory Allocated: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "\n",
    "# Check available GPUs\n",
    "print(f\"Available GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)} - Memory Allocated: {torch.cuda.memory_allocated(i)/1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a6a997-879a-4f47-97ec-03355acc2b49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost version: 2.0.3\n",
      "cupy version: 13.1.0\n",
      "GPU found 0\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost version:\", xgboost.__version__)\n",
    "print(\"cupy version:\", cp.__version__)\n",
    "\n",
    "GPUtil.getAvailable()\n",
    "\n",
    "# if a number is seen a GPU is available\n",
    "GPUtil.getGPUs()\n",
    "\n",
    "DEVICE_ID_LIST = GPUtil.getFirstAvailable()\n",
    "DEVICE_ID = DEVICE_ID_LIST[0] # grab first element from list\n",
    "if DEVICE_ID != None: \n",
    "    print('GPU found', DEVICE_ID)\n",
    "    use_gpu = True\n",
    "\n",
    "    GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9658fa0e-ab6d-415e-8445-47b1ddfa0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "\n",
    "# Clear GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6495ec",
   "metadata": {},
   "source": [
    "## Simulation tests <a id=\"sims\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f8932-4f1a-4718-aa14-43008697f95a",
   "metadata": {},
   "source": [
    "### Model Parameter Counts\n",
    "\n",
    "#### **Linear Models**\n",
    "- **PCA Bilinear:** 730  _(27 PCs)_\n",
    "- **PLS Bilinear:** 101  _(10 PLS components)_\n",
    "- **Bilinear Low-rank:** 73,800  _(rank 10)_\n",
    "- **PLS MLP:** 158,993  _(10 PLS components, including PLS projection matrices)_\n",
    "- **PCA MLP:** 47,873  _(27 PCs, 2-layer)_\n",
    "\n",
    "---\n",
    "\n",
    "#### **MLP and SMT Models**\n",
    "\n",
    "#### 2-Layer Models\n",
    "- **MLP:** 3,812,609\n",
    "- **SMT:** 1,399,947\n",
    "- **MLP w/ CLS:** 3,814,145\n",
    "- **SMT w/ CLS:** 1,405,579\n",
    "\n",
    "#### 3-Layer Models\n",
    "- **MLP:** 7,723,777\n",
    "- **SMT:** 2,162,315\n",
    "- **MLP w/ CLS:** 7,726,849\n",
    "- **SMT w/ CLS:** 2,173,067\n",
    "\n",
    "---\n",
    "\n",
    "### Coord MLP Parameter Counts\n",
    "- **[32]:** 321\n",
    "- **[64, 32]:** 2,753\n",
    "- **[128, 64]:** 9,601\n",
    "- **[256, 128]:** 35,685\n",
    "- **[512, 256, 128]:** 169,729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17fd21a5-d6af-40d3-b99b-32d9ce3ff955",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch._dynamo.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b00250-46cd-4bcd-8db3-a658d06f1b2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components for 95% variance PCA: 27\n",
      "Warning: Cell type data only available for cortical regions. Padding array with zeros for subcortical regions (400->456)\n",
      "Warning: Cell type data only available for cortical regions. Padding array with zeros for subcortical regions (400->456)\n",
      "Warning: Cell type data only available for cortical regions. Padding array with zeros for subcortical regions (400->456)\n",
      "Warning: SC measure not available for UKBB dataset, returning HCP S456 SC\n",
      "Warning: SC measure not available for UKBB dataset, returning HCP S456 SC\n",
      "Number of 1s: 36662, Number of 0s: 171274, Class balance (1s): 0.176\n",
      "Warning: SC measure not available for UKBB dataset, returning HCP S456 SC\n",
      "Warning: SC measure not available for UKBB dataset, returning HCP S456 SC\n",
      "Number of 1s: 17738, Number of 0s: 190198, Class balance (1s): 0.085\n",
      "X shape: (455, 7380)\n",
      "X_pca shape: (455, 27)\n",
      "X_cell_types_Jorstad shape: (455, 24)\n",
      "X_cell_types_LakeDFC shape: (455, 18)\n",
      "X_cell_types_LakeVIS shape: (455, 18)\n",
      "Y_sc shape: (455, 455)\n",
      "Y_sc_spectralL shape: (455, 455)\n",
      "Y_sc_spectralA shape: (455, 456)\n",
      "Y_fc shape: (455, 455)\n",
      "Coordinates shape: (455, 3)\n",
      "Y shape (455, 455)\n",
      "feature_name: transcriptome, processing_type: None\n",
      "features ['transcriptome']\n",
      "Feature matrix, X, generated... expanding to pairwise dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  return LooseVersion(v) >= LooseVersion(check)\n",
      "\n",
      "ERROR: Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masratzan\u001b[0m (\u001b[33malexander-ratzan-new-york-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. Additional properties are not allowed ('best_parameters' was unexpected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 2ijbq53r\n",
      "Sweep URL: https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r\n",
      "Initialized sweep with ID: 2ijbq53r\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hd8les5s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taug_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdeep_hidden_dims: [512, 256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_output_dim: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_dim: 14760\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tprefetch_factor: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttoken_encoder_dim: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_dropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_alibi: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention_pooling: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n",
      "ERROR: Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:258: ResourceWarning: unclosed file <_io.TextIOWrapper name='/scratch/asr655/neuroinformatics/GeneEx2Conn/wandb/sweep-2ijbq53r/config-hd8les5s.yaml' mode='r' encoding='utf-8'>\n",
      "  self._sweep_config = config_util.dict_from_config_file(\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/ipywidgets/widgets/widget.py:528: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "WARNING: <frozen abc>:123: ResourceWarning: unclosed <socket.socket fd=72, family=2, type=1, proto=0, laddr=('127.0.0.1', 60728), raddr=('127.0.0.1', 44299)>\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/asr655/neuroinformatics/GeneEx2Conn/wandb/run-20250828_170854-hd8les5s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/hd8les5s' target=\"_blank\">shared_transformer_transcriptome_FC_random42_fold0_innerCV</a></strong> to <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/hd8les5s' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/hd8les5s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing inner fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of learnable parameters in SMT model: 1036802\n",
      "Using device: cuda\n",
      "GPU 0: NVIDIA H100 80GB HBM3 - Memory Allocated: 0.00 GB\n",
      "Best val loss so far at epoch 1: 0.0404\n",
      "Epoch 5/100, Train Loss: 0.1286, Val Loss: 0.0553, Time: 4.88s\n",
      "Epoch 10/100, Train Loss: 0.1026, Val Loss: 0.0461, Time: 5.58s\n",
      "Epoch 15/100, Train Loss: 0.0878, Val Loss: 0.0484, Time: 5.59s\n",
      "Best val loss so far at epoch 17: 0.0385\n",
      "Best val loss so far at epoch 19: 0.0371\n",
      "Best val loss so far at epoch 20: 0.0358\n",
      "Epoch 20/100, Train Loss: 0.0661, Val Loss: 0.0358, Time: 5.78s\n",
      "Best val loss so far at epoch 21: 0.0357\n",
      "Best val loss so far at epoch 25: 0.0351\n",
      "Epoch 25/100, Train Loss: 0.0597, Val Loss: 0.0351, Time: 5.22s\n",
      "Epoch 30/100, Train Loss: 0.0539, Val Loss: 0.0363, Time: 4.88s\n",
      "Best val loss so far at epoch 32: 0.0350\n",
      "Epoch 35/100, Train Loss: 0.0521, Val Loss: 0.0371, Time: 4.56s\n",
      "Epoch 40/100, Train Loss: 0.0532, Val Loss: 0.0352, Time: 4.86s\n",
      "\n",
      "LR REDUCED: 0.000050 → 0.000015 at Val Loss: 0.035259\n",
      "Epoch 45/100, Train Loss: 0.0491, Val Loss: 0.0357, Time: 4.53s\n",
      "Epoch 50/100, Train Loss: 0.0497, Val Loss: 0.0354, Time: 4.89s\n",
      "Best val loss so far at epoch 51: 0.0350\n",
      "Epoch 55/100, Train Loss: 0.0446, Val Loss: 0.0362, Time: 4.09s\n",
      "Best val loss so far at epoch 56: 0.0347\n",
      "Epoch 60/100, Train Loss: 0.0437, Val Loss: 0.0352, Time: 4.04s\n",
      "Best val loss so far at epoch 61: 0.0345\n",
      "Best val loss so far at epoch 62: 0.0345\n",
      "\n",
      "LR REDUCED: 0.000015 → 0.000005 at Val Loss: 0.035432\n",
      "Epoch 65/100, Train Loss: 0.0431, Val Loss: 0.0346, Time: 3.86s\n",
      "Epoch 70/100, Train Loss: 0.0409, Val Loss: 0.0356, Time: 3.71s\n",
      "Epoch 75/100, Train Loss: 0.0432, Val Loss: 0.0349, Time: 4.01s\n",
      "Best val loss so far at epoch 78: 0.0344\n",
      "Epoch 80/100, Train Loss: 0.0433, Val Loss: 0.0350, Time: 3.95s\n",
      "\n",
      "LR REDUCED: 0.000005 → 0.000001 at Val Loss: 0.035185\n",
      "Epoch 85/100, Train Loss: 0.0454, Val Loss: 0.0352, Time: 4.19s\n",
      "Epoch 90/100, Train Loss: 0.0437, Val Loss: 0.0352, Time: 4.08s\n",
      "Epoch 95/100, Train Loss: 0.0367, Val Loss: 0.0354, Time: 3.31s\n",
      "Saved best model to models/saved_models/UKBB_SMT_seed42fold0.pt\n",
      "\n",
      "Reached final epoch 100. Restoring best model with Val Loss: 0.0344, Pearson Correlation: 0.1630\n",
      "Processing inner fold 1\n",
      "Processing inner fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>fold0_epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>fold0_train_loss</td><td>█▆▆▅▄▃▃▃▂▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>fold0_val_loss</td><td>▁▃▅█▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>inner_fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_train_loss</td><td>▁</td></tr><tr><td>mean_train_pearson</td><td>▁</td></tr><tr><td>mean_val_loss</td><td>▁</td></tr><tr><td>mean_val_pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>fold0_epoch</td><td>99</td></tr><tr><td>fold0_train_loss</td><td>0.03776</td></tr><tr><td>fold0_val_loss</td><td>0.03463</td></tr><tr><td>inner_fold</td><td>0</td></tr><tr><td>mean_train_loss</td><td>0.03776</td></tr><tr><td>mean_train_pearson</td><td>0.2005</td></tr><tr><td>mean_val_loss</td><td>0.03463</td></tr><tr><td>mean_val_pearson</td><td>0.1629</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">shared_transformer_transcriptome_FC_random42_fold0_innerCV</strong> at: <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/hd8les5s' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/hd8les5s</a><br/> View project at: <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250828_170854-hd8les5s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oceeya1s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taug_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdeep_hidden_dims: [512, 256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_output_dim: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_dim: 14760\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tprefetch_factor: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttoken_encoder_dim: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_dropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_alibi: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention_pooling: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:258: ResourceWarning: unclosed file <_io.TextIOWrapper name='/scratch/asr655/neuroinformatics/GeneEx2Conn/wandb/sweep-2ijbq53r/config-oceeya1s.yaml' mode='r' encoding='utf-8'>\n",
      "  self._sweep_config = config_util.dict_from_config_file(\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/ipywidgets/widgets/widget.py:528: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/asr655/neuroinformatics/GeneEx2Conn/wandb/run-20250828_171717-oceeya1s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/oceeya1s' target=\"_blank\">shared_transformer_transcriptome_FC_random42_fold0_innerCV</a></strong> to <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/oceeya1s' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/oceeya1s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing inner fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /scratch/asr655/neuroinformatics/GeneEx2Conn/sim/sim_utils.py:345: ResourceWarning: unclosed <socket.socket fd=76, family=2, type=1, proto=0, laddr=('127.0.0.1', 51218), raddr=('127.0.0.1', 38031)>\n",
      "  gc.collect()\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of learnable parameters in SMT model: 1036802\n",
      "Using device: cuda\n",
      "GPU 0: NVIDIA H100 80GB HBM3 - Memory Allocated: 0.07 GB\n",
      "Best val loss so far at epoch 1: 0.0543\n",
      "Epoch 5/100, Train Loss: 0.0980, Val Loss: 0.0891, Time: 4.75s\n",
      "Best val loss so far at epoch 9: 0.0478\n",
      "Epoch 10/100, Train Loss: 0.0790, Val Loss: 0.0628, Time: 5.47s\n",
      "Best val loss so far at epoch 11: 0.0392\n",
      "Best val loss so far at epoch 12: 0.0372\n",
      "Best val loss so far at epoch 15: 0.0362\n",
      "Epoch 15/100, Train Loss: 0.0597, Val Loss: 0.0362, Time: 4.63s\n",
      "Epoch 20/100, Train Loss: 0.0553, Val Loss: 0.0378, Time: 5.23s\n",
      "Epoch 25/100, Train Loss: 0.0495, Val Loss: 0.0431, Time: 4.89s\n",
      "Best val loss so far at epoch 30: 0.0334\n",
      "Epoch 30/100, Train Loss: 0.0442, Val Loss: 0.0334, Time: 4.82s\n",
      "Epoch 35/100, Train Loss: 0.0400, Val Loss: 0.0611, Time: 4.81s\n",
      "Best val loss so far at epoch 40: 0.0288\n",
      "Epoch 40/100, Train Loss: 0.0316, Val Loss: 0.0288, Time: 4.19s\n",
      "Best val loss so far at epoch 41: 0.0277\n",
      "Best val loss so far at epoch 43: 0.0243\n",
      "Epoch 45/100, Train Loss: 0.0312, Val Loss: 0.0348, Time: 4.71s\n",
      "Epoch 50/100, Train Loss: 0.0277, Val Loss: 0.0934, Time: 4.56s\n",
      "Best val loss so far at epoch 51: 0.0235\n",
      "Epoch 55/100, Train Loss: 0.0247, Val Loss: 0.0379, Time: 4.56s\n",
      "Best val loss so far at epoch 58: 0.0228\n",
      "Epoch 60/100, Train Loss: 0.0221, Val Loss: 0.0250, Time: 4.55s\n",
      "Best val loss so far at epoch 61: 0.0225\n",
      "\n",
      "LR REDUCED: 0.000100 → 0.000030 at Val Loss: 0.037458\n",
      "Best val loss so far at epoch 65: 0.0209\n",
      "Epoch 65/100, Train Loss: 0.0199, Val Loss: 0.0209, Time: 4.51s\n",
      "Best val loss so far at epoch 67: 0.0205\n",
      "Best val loss so far at epoch 70: 0.0204\n",
      "Epoch 70/100, Train Loss: 0.0166, Val Loss: 0.0204, Time: 4.20s\n",
      "Epoch 75/100, Train Loss: 0.0154, Val Loss: 0.0221, Time: 4.04s\n",
      "Best val loss so far at epoch 78: 0.0202\n",
      "Epoch 80/100, Train Loss: 0.0146, Val Loss: 0.0206, Time: 4.11s\n",
      "Best val loss so far at epoch 85: 0.0198\n",
      "Epoch 85/100, Train Loss: 0.0145, Val Loss: 0.0198, Time: 4.09s\n",
      "\n",
      "LR REDUCED: 0.000030 → 0.000009 at Val Loss: 0.021549\n",
      "Epoch 90/100, Train Loss: 0.0105, Val Loss: 0.0200, Time: 3.71s\n",
      "Epoch 95/100, Train Loss: 0.0114, Val Loss: 0.0231, Time: 3.79s\n",
      "Saved best model to models/saved_models/UKBB_SMT_seed42fold0.pt\n",
      "\n",
      "Reached final epoch 100. Restoring best model with Val Loss: 0.0198, Pearson Correlation: 0.6760\n",
      "Processing inner fold 1\n",
      "Processing inner fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>fold0_epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>fold0_train_loss</td><td>█▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fold0_val_loss</td><td>▁▃█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>inner_fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_train_loss</td><td>▁</td></tr><tr><td>mean_train_pearson</td><td>▁</td></tr><tr><td>mean_val_loss</td><td>▁</td></tr><tr><td>mean_val_pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>fold0_epoch</td><td>99</td></tr><tr><td>fold0_train_loss</td><td>0.009</td></tr><tr><td>fold0_val_loss</td><td>0.02016</td></tr><tr><td>inner_fold</td><td>0</td></tr><tr><td>mean_train_loss</td><td>0.009</td></tr><tr><td>mean_train_pearson</td><td>0.90343</td></tr><tr><td>mean_val_loss</td><td>0.02016</td></tr><tr><td>mean_val_pearson</td><td>0.67606</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">shared_transformer_transcriptome_FC_random42_fold0_innerCV</strong> at: <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/oceeya1s' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/oceeya1s</a><br/> View project at: <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250828_171717-oceeya1s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 948kz8hf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taug_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdeep_hidden_dims: [512, 256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_output_dim: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_dim: 14760\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tprefetch_factor: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttoken_encoder_dim: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_dropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_alibi: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention_pooling: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:258: ResourceWarning: unclosed file <_io.TextIOWrapper name='/scratch/asr655/neuroinformatics/GeneEx2Conn/wandb/sweep-2ijbq53r/config-948kz8hf.yaml' mode='r' encoding='utf-8'>\n",
      "  self._sweep_config = config_util.dict_from_config_file(\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/ipywidgets/widgets/widget.py:528: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/asr655/neuroinformatics/GeneEx2Conn/wandb/run-20250828_172522-948kz8hf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/948kz8hf' target=\"_blank\">shared_transformer_transcriptome_FC_random42_fold0_innerCV</a></strong> to <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/948kz8hf' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/948kz8hf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing inner fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /scratch/asr655/neuroinformatics/GeneEx2Conn/sim/sim_utils.py:345: ResourceWarning: unclosed <socket.socket fd=78, family=2, type=1, proto=0, laddr=('127.0.0.1', 58916), raddr=('127.0.0.1', 37053)>\n",
      "  gc.collect()\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of learnable parameters in SMT model: 1036802\n",
      "Using device: cuda\n",
      "GPU 0: NVIDIA H100 80GB HBM3 - Memory Allocated: 0.07 GB\n",
      "Best val loss so far at epoch 1: 0.0482\n",
      "Best val loss so far at epoch 4: 0.0471\n",
      "Epoch 5/100, Train Loss: 0.0666, Val Loss: 0.0501, Time: 5.02s\n",
      "Best val loss so far at epoch 6: 0.0355\n",
      "Best val loss so far at epoch 9: 0.0347\n",
      "Epoch 10/100, Train Loss: 0.0551, Val Loss: 0.0347, Time: 4.99s\n",
      "Best val loss so far at epoch 14: 0.0346\n",
      "Epoch 15/100, Train Loss: 0.0529, Val Loss: 0.0349, Time: 4.69s\n",
      "Best val loss so far at epoch 18: 0.0346\n",
      "Epoch 20/100, Train Loss: 0.0492, Val Loss: 0.0346, Time: 4.47s\n",
      "Epoch 25/100, Train Loss: 0.0519, Val Loss: 0.0347, Time: 5.01s\n",
      "\n",
      "LR REDUCED: 0.000200 → 0.000060 at Val Loss: 0.034622\n",
      "Best val loss so far at epoch 28: 0.0346\n",
      "Epoch 30/100, Train Loss: 0.0518, Val Loss: 0.0347, Time: 4.95s\n",
      "Epoch 35/100, Train Loss: 0.0538, Val Loss: 0.0346, Time: 5.27s\n",
      "Best val loss so far at epoch 36: 0.0346\n",
      "Epoch 40/100, Train Loss: 0.0469, Val Loss: 0.0347, Time: 4.37s\n",
      "Epoch 45/100, Train Loss: 0.0501, Val Loss: 0.0347, Time: 4.82s\n",
      "\n",
      "LR REDUCED: 0.000060 → 0.000018 at Val Loss: 0.034755\n",
      "Epoch 50/100, Train Loss: 0.0472, Val Loss: 0.0348, Time: 4.35s\n",
      "Epoch 55/100, Train Loss: 0.0441, Val Loss: 0.0348, Time: 4.13s\n",
      "Epoch 60/100, Train Loss: 0.0392, Val Loss: 0.0349, Time: 3.60s\n",
      "Epoch 65/100, Train Loss: 0.0437, Val Loss: 0.0349, Time: 4.11s\n",
      "Epoch 70/100, Train Loss: 0.0389, Val Loss: 0.0349, Time: 3.58s\n",
      "\n",
      "LR REDUCED: 0.000018 → 0.000005 at Val Loss: 0.034882\n",
      "Epoch 75/100, Train Loss: 0.0415, Val Loss: 0.0348, Time: 3.84s\n",
      "Epoch 80/100, Train Loss: 0.0406, Val Loss: 0.0348, Time: 3.72s\n",
      "Saved best model to models/saved_models/UKBB_SMT_seed42fold0.pt\n",
      "\n",
      "Early stopping triggered at epoch 81. Restoring best model with Val Loss: 0.0346, Pearson Correlation: 0.0332\n",
      "Processing inner fold 1\n",
      "Processing inner fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>fold0_epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>fold0_train_loss</td><td>█▆▃▃▂▂▂▂▃▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>fold0_val_loss</td><td>▄█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>inner_fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_train_loss</td><td>▁</td></tr><tr><td>mean_train_pearson</td><td>▁</td></tr><tr><td>mean_val_loss</td><td>▁</td></tr><tr><td>mean_val_pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>fold0_epoch</td><td>80</td></tr><tr><td>fold0_train_loss</td><td>0.03884</td></tr><tr><td>fold0_val_loss</td><td>0.03481</td></tr><tr><td>inner_fold</td><td>0</td></tr><tr><td>mean_train_loss</td><td>0.03884</td></tr><tr><td>mean_train_pearson</td><td>0.07855</td></tr><tr><td>mean_val_loss</td><td>0.03481</td></tr><tr><td>mean_val_pearson</td><td>0.03321</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">shared_transformer_transcriptome_FC_random42_fold0_innerCV</strong> at: <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/948kz8hf' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/948kz8hf</a><br/> View project at: <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250828_172522-948kz8hf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tpsuvd3c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taug_prob: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdeep_hidden_dims: [512, 256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_output_dim: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_dim: 14760\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tprefetch_factor: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttoken_encoder_dim: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttransformer_dropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_alibi: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_attention_pooling: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:258: ResourceWarning: unclosed file <_io.TextIOWrapper name='/scratch/asr655/neuroinformatics/GeneEx2Conn/wandb/sweep-2ijbq53r/config-tpsuvd3c.yaml' mode='r' encoding='utf-8'>\n",
      "  self._sweep_config = config_util.dict_from_config_file(\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/ipywidgets/widgets/widget.py:528: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/asr655/neuroinformatics/GeneEx2Conn/wandb/run-20250828_173155-tpsuvd3c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/tpsuvd3c' target=\"_blank\">shared_transformer_transcriptome_FC_random42_fold0_innerCV</a></strong> to <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/2ijbq53r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/tpsuvd3c' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/tpsuvd3c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing inner fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /scratch/asr655/neuroinformatics/GeneEx2Conn/sim/sim_utils.py:345: ResourceWarning: unclosed <socket.socket fd=77, family=2, type=1, proto=0, laddr=('127.0.0.1', 48380), raddr=('127.0.0.1', 34443)>\n",
      "  gc.collect()\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of learnable parameters in SMT model: 1036802\n",
      "Using device: cuda\n",
      "GPU 0: NVIDIA H100 80GB HBM3 - Memory Allocated: 0.07 GB\n",
      "Best val loss so far at epoch 1: 0.0394\n",
      "Best val loss so far at epoch 3: 0.0383\n",
      "Best val loss so far at epoch 4: 0.0366\n",
      "Best val loss so far at epoch 5: 0.0345\n",
      "Epoch 5/100, Train Loss: 0.0715, Val Loss: 0.0345, Time: 5.71s\n",
      "Best val loss so far at epoch 6: 0.0341\n",
      "Best val loss so far at epoch 7: 0.0338\n",
      "Epoch 10/100, Train Loss: 0.0500, Val Loss: 0.0373, Time: 5.46s\n",
      "Best val loss so far at epoch 12: 0.0280\n",
      "Epoch 15/100, Train Loss: 0.0347, Val Loss: 0.0294, Time: 5.02s\n",
      "Best val loss so far at epoch 16: 0.0265\n",
      "Best val loss so far at epoch 20: 0.0255\n",
      "Epoch 20/100, Train Loss: 0.0389, Val Loss: 0.0255, Time: 6.32s\n",
      "Epoch 25/100, Train Loss: 0.0350, Val Loss: 0.0326, Time: 6.25s\n",
      "Best val loss so far at epoch 26: 0.0218\n",
      "Best val loss so far at epoch 27: 0.0209\n",
      "Epoch 30/100, Train Loss: 0.0152, Val Loss: 0.0357, Time: 4.08s\n",
      "Epoch 35/100, Train Loss: 0.0181, Val Loss: 0.0214, Time: 4.67s\n",
      "Epoch 40/100, Train Loss: 0.0164, Val Loss: 0.0372, Time: 4.47s\n",
      "Best val loss so far at epoch 44: 0.0207\n",
      "Epoch 45/100, Train Loss: 0.0167, Val Loss: 0.0226, Time: 4.62s\n",
      "\n",
      "LR REDUCED: 0.000300 → 0.000090 at Val Loss: 0.022437\n",
      "Best val loss so far at epoch 48: 0.0198\n",
      "Best val loss so far at epoch 50: 0.0188\n",
      "Epoch 50/100, Train Loss: 0.0152, Val Loss: 0.0188, Time: 4.47s\n",
      "Epoch 55/100, Train Loss: 0.0136, Val Loss: 0.0190, Time: 4.28s\n",
      "Epoch 60/100, Train Loss: 0.0155, Val Loss: 0.0193, Time: 4.56s\n",
      "Epoch 65/100, Train Loss: 0.0132, Val Loss: 0.0215, Time: 4.32s\n",
      "Epoch 70/100, Train Loss: 0.0107, Val Loss: 0.0232, Time: 4.14s\n",
      "\n",
      "LR REDUCED: 0.000090 → 0.000027 at Val Loss: 0.019112\n",
      "Best val loss so far at epoch 72: 0.0184\n",
      "Best val loss so far at epoch 73: 0.0182\n",
      "Epoch 75/100, Train Loss: 0.0094, Val Loss: 0.0185, Time: 3.86s\n",
      "Epoch 80/100, Train Loss: 0.0116, Val Loss: 0.0190, Time: 4.14s\n",
      "Epoch 85/100, Train Loss: 0.0101, Val Loss: 0.0203, Time: 3.94s\n",
      "Epoch 90/100, Train Loss: 0.0044, Val Loss: 0.0199, Time: 3.24s\n",
      "\n",
      "LR REDUCED: 0.000027 → 0.000008 at Val Loss: 0.019157\n",
      "Epoch 95/100, Train Loss: 0.0056, Val Loss: 0.0185, Time: 3.49s\n",
      "Saved best model to models/saved_models/UKBB_SMT_seed42fold0.pt\n",
      "\n",
      "Reached final epoch 100. Restoring best model with Val Loss: 0.0182, Pearson Correlation: 0.7021\n",
      "Processing inner fold 1\n",
      "Processing inner fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>fold0_epoch</td><td>▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>fold0_train_loss</td><td>██▆▅▄▄▃▃▂▃▃▂▃▃▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>fold0_val_loss</td><td>▄█▄▄▄▄▃▃▂▆▂▁▂▂▂▃▃▂▂▂▃▂▂▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>inner_fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_train_loss</td><td>▁</td></tr><tr><td>mean_train_pearson</td><td>▁</td></tr><tr><td>mean_val_loss</td><td>▁</td></tr><tr><td>mean_val_pearson</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>fold0_epoch</td><td>99</td></tr><tr><td>fold0_train_loss</td><td>0.00422</td></tr><tr><td>fold0_val_loss</td><td>0.01867</td></tr><tr><td>inner_fold</td><td>0</td></tr><tr><td>mean_train_loss</td><td>0.00422</td></tr><tr><td>mean_train_pearson</td><td>0.96396</td></tr><tr><td>mean_val_loss</td><td>0.01867</td></tr><tr><td>mean_val_pearson</td><td>0.70208</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">shared_transformer_transcriptome_FC_random42_fold0_innerCV</strong> at: <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/tpsuvd3c' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/tpsuvd3c</a><br/> View project at: <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250828_173155-tpsuvd3c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sorting runs by +summary_metrics.mean_val_loss\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST CONFIG {'nhead': 4, 'epochs': 100, 'd_model': 128, 'aug_prob': 0.3, 'input_dim': 14760, 'use_alibi': True, 'batch_size': 1024, 'num_layers': 4, 'num_workers': 2, 'dropout_rate': 0.2, 'weight_decay': 1e-05, 'learning_rate': 0.0003, 'prefetch_factor': 4, 'deep_hidden_dims': [512, 256, 128], 'token_encoder_dim': 60, 'encoder_output_dim': 10, 'transformer_dropout': 0.2, 'use_attention_pooling': True}\n",
      "Number of learnable parameters in SMT model: 1036802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/ipywidgets/widgets/widget.py:528: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/asr655/neuroinformatics/GeneEx2Conn/wandb/run-20250828_173952-g2dk8nyo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/g2dk8nyo' target=\"_blank\">shared_transformer_transcriptome_FC_random42_fold0_final_eval</a></strong> to <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/g2dk8nyo' target=\"_blank\">https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/runs/g2dk8nyo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU 0: NVIDIA H100 80GB HBM3 - Memory Allocated: 0.07 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/_weakrefset.py:58: ResourceWarning: unclosed <socket.socket fd=78, family=2, type=1, proto=0, laddr=('127.0.0.1', 33122), raddr=('127.0.0.1', 41371)>\n",
      "  item = pop()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss so far at epoch 1: 0.0387\n"
     ]
    }
   ],
   "source": [
    "    single_sim_run(\n",
    "                  feature_type=[{'transcriptome': None}],\n",
    "                  train_shared_regions=False,\n",
    "                  test_shared_regions=False,\n",
    "                  omit_subcortical=False,\n",
    "                  dataset='UKBB',\n",
    "                  parcellation='S456',\n",
    "                  hemisphere='both',\n",
    "                  connectome_target='FC',\n",
    "                  binarize=None,\n",
    "                  impute_strategy='mirror_interpolate',\n",
    "                  sort_genes='refgenome',\n",
    "                  gene_list='0.2',\n",
    "                  cv_type='random',\n",
    "                  random_seed=42,\n",
    "                  search_method=('wandb', 'mse', 5),\n",
    "                  track_wandb=True,\n",
    "                  skip_cv=False,\n",
    "                  model_type='shared_transformer',\n",
    "                  use_gpu=True,\n",
    "                  null_model='none',\n",
    "                  use_folds=[0]\n",
    "                  )\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Clear CPU memory\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75344412-4f00-4522-9b4a-9ff4a5530eba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_sim_run(\n",
    "              feature_type=[{'transcriptome': None}],\n",
    "              train_shared_regions=False,\n",
    "              test_shared_regions=False,\n",
    "              omit_subcortical=False,\n",
    "              dataset='UKBB',\n",
    "              parcellation='S456',\n",
    "              hemisphere='both',\n",
    "              connectome_target='FC',\n",
    "              binarize=None,\n",
    "              impute_strategy='mirror_interpolate',\n",
    "              sort_genes='refgenome',\n",
    "              gene_list='0.2',\n",
    "              cv_type='random',\n",
    "              random_seed=42,\n",
    "              search_method=('wandb', 'mse', 4),\n",
    "              track_wandb=False,\n",
    "              skip_cv=True,\n",
    "              model_type='shared_transformer_cls',\n",
    "              use_gpu=True,\n",
    "              null_model='none',\n",
    "              use_folds=[0]\n",
    "              )\n",
    "\n",
    "# Clear GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Clear CPU memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2fd5af-b3f6-4ffa-b014-36473709c0df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "main_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
