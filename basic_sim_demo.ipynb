{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98363b8f-1d61-429d-865a-3d8213cf3406",
   "metadata": {},
   "source": [
    "## Sim Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83562164-b395-4948-85bd-0cc2a4d2c0e9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25060b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29dd74e-acf1-4701-bb72-ce3701d3d123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/enigmatoolbox-2.0.3-py3.11.egg/enigmatoolbox/utils/useful.py:10: PendingDeprecationWarning: Importing from numpy.matlib is deprecated since 1.19.0. The matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray. \n",
      "  import numpy.matlib as npm\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/enigmatoolbox-2.0.3-py3.11.egg/enigmatoolbox/plotting/colormaps.py:6: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  autumn = cm.get_cmap('autumn', 256)\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/enigmatoolbox-2.0.3-py3.11.egg/enigmatoolbox/plotting/colormaps.py:8: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  winter = cm.get_cmap('winter_r', 256)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from env.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "566563ca-070f-4671-a98a-338fea600261",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resorting genes by reference genome order\n",
      "Resorting genes by reference genome order\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'data.data_load' from '/scratch/asr655/neuroinformatics/GeneEx2Conn/data/data_load.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import data\n",
    "\n",
    "import models\n",
    "import sim.sim\n",
    "import sim.sim_utils\n",
    "from sim.sim_utils import bytes2human, print_system_usage\n",
    "from sim.sim import Simulation\n",
    "from sim.sim_run import single_sim_run\n",
    "\n",
    "importlib.reload(sim.sim)\n",
    "importlib.reload(sim.sim_run)\n",
    "importlib.reload(models.train_val)\n",
    "importlib.reload(data.data_utils)\n",
    "importlib.reload(data.data_load)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa8bad-5d12-46eb-a39f-18057f3923d7",
   "metadata": {},
   "source": [
    "#### Check job specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b7c8d67-a18c-4208-b20f-8ba13fd58e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage: 18.9%\n",
      "RAM Usage: 8.0%\n",
      "Available RAM: 1.4T\n",
      "Total RAM: 1.5T\n",
      "52.4G\n"
     ]
    }
   ],
   "source": [
    "print_system_usage()\n",
    "\n",
    "total = psutil.disk_usage('/').total\n",
    "print(bytes2human(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4c0fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Available GPUs: 1\n",
      "GPU 0: NVIDIA H100 80GB HBM3 - Memory Allocated: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "\n",
    "# Check available GPUs\n",
    "print(f\"Available GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)} - Memory Allocated: {torch.cuda.memory_allocated(i)/1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a6a997-879a-4f47-97ec-03355acc2b49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost version: 2.0.3\n",
      "cupy version: 13.1.0\n",
      "GPU found 0\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  1% |\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost version:\", xgboost.__version__)\n",
    "print(\"cupy version:\", cp.__version__)\n",
    "\n",
    "GPUtil.getAvailable()\n",
    "\n",
    "# if a number is seen a GPU is available\n",
    "GPUtil.getGPUs()\n",
    "\n",
    "DEVICE_ID_LIST = GPUtil.getFirstAvailable()\n",
    "DEVICE_ID = DEVICE_ID_LIST[0] # grab first element from list\n",
    "if DEVICE_ID != None: \n",
    "    print('GPU found', DEVICE_ID)\n",
    "    use_gpu = True\n",
    "\n",
    "    GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9658fa0e-ab6d-415e-8445-47b1ddfa0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "\n",
    "# Clear GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6495ec",
   "metadata": {},
   "source": [
    "## Simulation tests <a id=\"sims\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64c7e53-4469-4036-8500-c5b68b123af1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resorting genes by reference genome order\n",
      "Resorting genes by reference genome order\n",
      "Number of components for 95% variance PCA: 27\n",
      "Resorting genes by reference genome order\n",
      "Number of 1s: 36662, Number of 0s: 171274, Class balance (1s): 0.176\n",
      "Number of 1s: 11988, Number of 0s: 195948, Class balance (1s): 0.058\n",
      "X shape: (455, 7380)\n",
      "X_pca shape: (455, 27)\n",
      "X_pca_full shape: (455, 455)\n",
      "Y_sc shape: (455, 455)\n",
      "Y_sc_spectralL shape: (455, 455)\n",
      "Y_sc_spectralA shape: (455, 456)\n",
      "Y_fc shape: (455, 455)\n",
      "Coordinates shape: (455, 3)\n",
      "connectome target FC\n",
      "Y shape (455, 455)\n",
      "feature_name: transcriptome, processing_type: None\n",
      "features ['transcriptome']\n",
      "Feature matrix, X, generated... expanding to pairwise dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  return LooseVersion(v) >= LooseVersion(check)\n",
      "\n",
      "ERROR: Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masratzan\u001b[0m (\u001b[33malexander-ratzan-new-york-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. Additional properties are not allowed ('best_parameters' was unexpected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: k9jvggh2\n",
      "Sweep URL: https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/k9jvggh2\n",
      "Initialized sweep with ID: k9jvggh2\n",
      "2\n",
      "3\n",
      "4\n",
      "BEST CONFIG {'input_dim': 14760, 'token_encoder_dim': 60, 'd_model': 128, 'encoder_output_dim': 10, 'use_alibi': True, 'nhead': 4, 'num_layers': 4, 'deep_hidden_dims': [512, 256, 128], 'transformer_dropout': 0.2, 'dropout_rate': 0.2, 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'batch_size': 512, 'aug_prob': 0.3, 'aug_style': 'curriculum_swap_linear_decay', 'epochs': 90, 'num_workers': 2, 'prefetch_factor': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of learnable parameters in SMT model: 2162315\n",
      "Using device: cuda\n",
      "GPU 0: NVIDIA H100 80GB HBM3 - Memory Allocated: 0.01 GB\n",
      "Best val loss so far at epoch 1: 0.0316\n",
      "Best val loss so far at epoch 3: 0.0244\n",
      "Epoch 5/90, Train Loss: 0.0649, Val Loss: 0.0259, Time: 5.71s\n",
      "Best val loss so far at epoch 7: 0.0217\n",
      "Best val loss so far at epoch 8: 0.0192\n",
      "Best val loss so far at epoch 9: 0.0179\n",
      "Best val loss so far at epoch 10: 0.0164\n",
      "Epoch 10/90, Train Loss: 0.0418, Val Loss: 0.0164, Time: 5.76s\n",
      "Best val loss so far at epoch 15: 0.0164\n",
      "Epoch 15/90, Train Loss: 0.0350, Val Loss: 0.0164, Time: 6.00s\n",
      "Best val loss so far at epoch 16: 0.0161\n",
      "Best val loss so far at epoch 19: 0.0160\n",
      "Epoch 20/90, Train Loss: 0.0286, Val Loss: 0.0178, Time: 5.86s\n",
      "Best val loss so far at epoch 23: 0.0157\n",
      "Best val loss so far at epoch 24: 0.0149\n",
      "Epoch 25/90, Train Loss: 0.0218, Val Loss: 0.0153, Time: 5.48s\n",
      "Best val loss so far at epoch 28: 0.0143\n",
      "Epoch 30/90, Train Loss: 0.0230, Val Loss: 0.0158, Time: 5.65s\n",
      "Epoch 35/90, Train Loss: 0.0243, Val Loss: 0.0151, Time: 5.80s\n",
      "Best val loss so far at epoch 36: 0.0139\n",
      "Epoch 40/90, Train Loss: 0.0184, Val Loss: 0.0140, Time: 5.44s\n",
      "Best val loss so far at epoch 41: 0.0137\n",
      "Epoch 45/90, Train Loss: 0.0177, Val Loss: 0.0149, Time: 5.48s\n",
      "Epoch 50/90, Train Loss: 0.0182, Val Loss: 0.0140, Time: 5.43s\n",
      "Epoch 55/90, Train Loss: 0.0143, Val Loss: 0.0138, Time: 5.28s\n"
     ]
    }
   ],
   "source": [
    "single_sim_run(\n",
    "              feature_type=[{'transcriptome': None}],\n",
    "              omit_subcortical=False,\n",
    "              parcellation='S456',\n",
    "              hemisphere='both',\n",
    "              dataset='HCP',\n",
    "              connectome_target='FC',\n",
    "              impute_strategy='mirror_interpolate',\n",
    "              sort_genes='refgenome',\n",
    "              gene_list='0.2',\n",
    "              cv_type='random',\n",
    "              random_seed=42,\n",
    "              search_method=('wandb', 'mse', 5),\n",
    "              track_wandb=False,\n",
    "              skip_cv=True,\n",
    "              model_type='shared_transformer',\n",
    "              use_gpu=True, \n",
    "              null_model='none',\n",
    "              use_folds=[0])\n",
    "\n",
    "# Clear GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "# Clear CPU memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c8223d-cbd6-4f55-ae0f-3b7e3fc3b3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "main_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
