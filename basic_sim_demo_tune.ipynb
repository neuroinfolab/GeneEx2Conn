{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98363b8f-1d61-429d-865a-3d8213cf3406",
   "metadata": {},
   "source": [
    "## Sim Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83562164-b395-4948-85bd-0cc2a4d2c0e9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25060b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b29dd74e-acf1-4701-bb72-ce3701d3d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "566563ca-070f-4671-a98a-338fea600261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute_root_path /scratch/asr655/neuroinformatics/GeneEx2Conn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'sim.sim_run' from '/scratch/asr655/neuroinformatics/GeneEx2Conn/sim/sim_run.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import data\n",
    "\n",
    "import models\n",
    "import sim.sim\n",
    "import sim.sim_utils\n",
    "from sim.sim_utils import bytes2human, print_system_usage\n",
    "from sim.sim import Simulation\n",
    "from sim.sim_run import single_sim_run\n",
    "\n",
    "importlib.reload(sim.sim)\n",
    "importlib.reload(sim.sim_run) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa8bad-5d12-46eb-a39f-18057f3923d7",
   "metadata": {},
   "source": [
    "#### Check job specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b7c8d67-a18c-4208-b20f-8ba13fd58e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage: 33.5%\n",
      "RAM Usage: 5.4%\n",
      "Available RAM: 1.4T\n",
      "Total RAM: 1.5T\n",
      "52.4G\n"
     ]
    }
   ],
   "source": [
    "print_system_usage()\n",
    "\n",
    "total = psutil.disk_usage('/').total\n",
    "print(bytes2human(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e4c0fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Available GPUs: 1\n",
      "GPU 0: NVIDIA H100 80GB HBM3 - Memory Allocated: 1.62 GB\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "\n",
    "# Check available GPUs\n",
    "print(f\"Available GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)} - Memory Allocated: {torch.cuda.memory_allocated(i)/1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6a6a997-879a-4f47-97ec-03355acc2b49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost version: 2.0.3\n",
      "cupy version: 13.1.0\n",
      "GPU found 0\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  4% |\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost version:\", xgboost.__version__)\n",
    "print(\"cupy version:\", cp.__version__)\n",
    "\n",
    "GPUtil.getAvailable()\n",
    "\n",
    "# if a number is seen a GPU is available\n",
    "GPUtil.getGPUs()\n",
    "\n",
    "DEVICE_ID_LIST = GPUtil.getFirstAvailable()\n",
    "DEVICE_ID = DEVICE_ID_LIST[0] # grab first element from list\n",
    "if DEVICE_ID != None: \n",
    "    print('GPU found', DEVICE_ID)\n",
    "    use_gpu = True\n",
    "\n",
    "    GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9658fa0e-ab6d-415e-8445-47b1ddfa0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "\n",
    "# Clear GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6495ec",
   "metadata": {},
   "source": [
    "#### Simulation tests <a id=\"sims\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f8932-4f1a-4718-aa14-43008697f95a",
   "metadata": {},
   "source": [
    "**Model Parameter Count**\n",
    "- PCA Bilinear : 730 (27 PCs)\n",
    "- PLS Bilinear : 101 (10 PLS components)\n",
    "- Bilinear Lowrank : 73,800 (rank 10)\n",
    "- PLS MLP : 158,993 (10 PLS components, including PLS projection matrices)\n",
    "- PCA MLP : 47,873 (27 PCs)\n",
    "(2 layer)\n",
    "- MLP : 3,812,609\n",
    "- SMT : 1,399,947\n",
    "- MLP w/ CLS : 3,814,145\n",
    "- SMT w/ CLS : 1,405,579\n",
    "(3 layer)\n",
    "- MLP : 7,723,777\n",
    "- SMT : 2,162,315\n",
    "- MLP w/ CLS : 7,726,849\n",
    "- SMT w/ CLS : 2,173,067"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b9390",
   "metadata": {},
   "source": [
    "**Coord MLP Parameter Count** \n",
    "- [32]: 321\n",
    "- [64, 32]: 2,753\n",
    "- [128, 64]: 9,601\n",
    "- [256, 128]: 35,685\n",
    "- [512, 256, 128]: 169,729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcdec908-6551-4616-957b-f0908fa4adb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components for 95% variance PCA: 27\n",
      "Number of 1s: 36662, Number of 0s: 171274, Class balance (1s): 0.176\n",
      "Number of 1s: 17738, Number of 0s: 190198, Class balance (1s): 0.085\n",
      "X shape: (455, 7380)\n",
      "X_pca shape: (455, 27)\n",
      "Y_sc shape: (455, 455)\n",
      "Y_sc_spectralL shape: (455, 455)\n",
      "Y_sc_spectralA shape: (455, 456)\n",
      "Y_fc shape: (455, 455)\n",
      "Coordinates shape: (455, 3)\n",
      "Y shape (455, 455)\n",
      "Network coverage: 100.0% of regions\n",
      "Network sizes: [113, 113, 113, 116]\n",
      "feature_name:  transcriptome\n",
      "processing_type:  None\n",
      "features ['transcriptome']\n",
      "X generated... expanding to pairwise dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. Additional properties are not allowed ('best_parameters' was unexpected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: mullt3eg\n",
      "Sweep URL: https://wandb.ai/alexander-ratzan-new-york-university/gx2conn/sweeps/mullt3eg\n",
      "Initialized sweep with ID: mullt3eg\n",
      "2\n",
      "3\n",
      "4\n",
      "BEST CONFIG {'input_dim': 14760, 'binarize': False, 'token_encoder_dim': 60, 'd_model': 128, 'encoder_output_dim': 10, 'use_alibi': True, 'nhead': 2, 'num_layers': 2, 'deep_hidden_dims': [8192, 4096, 2048, 1024, 512, 256, 128], 'transformer_dropout': 0.2, 'dropout_rate': 0.2, 'learning_rate': 9e-05, 'weight_decay': 0.0001, 'batch_size': 512, 'aug_prob': 0.3, 'epochs': 70}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of learnable parameters in SMT model: 65302155\n",
      "Using device: cuda\n",
      "GPU 0: NVIDIA H100 80GB HBM3 - Memory Allocated: 3.44 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17] failed to eagerly compile backwards for dynamic, suppressing in case backwards not needed\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17] Traceback (most recent call last):\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 547, in aot_dispatch_autograd\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     compiled_bw_func = aot_config.bw_compiler(\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]                        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/backends/common.py\", line 47, in _wrapped_bw_compiler\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return disable(disable(bw_compiler)(*args, **kwargs))\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 600, in _fn\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return fn(*args, **kwargs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_utils_internal.py\", line 84, in wrapper_function\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return StrobelightCompileTimeProfiler.profile_compile_time(\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_strobelight/compile_time_profiler.py\", line 129, in profile_compile_time\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return func(*args, **kwargs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     r = func(*args, **kwargs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]         ^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 1454, in bw_compiler\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return inner_compile(\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/repro/after_aot.py\", line 84, in debug_wrapper\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return fn(*args, **kwargs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return func(*args, **kwds)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return func(*args, **kwds)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     r = func(*args, **kwargs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]         ^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 527, in compile_fx_inner\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     compiled_graph = fx_codegen_and_compile(\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return func(*args, **kwds)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 746, in fx_codegen_and_compile\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     _recursive_post_grad_passes(gm, is_inference=is_inference)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 263, in _recursive_post_grad_passes\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     post_grad_passes(gm, is_inference)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/post_grad.py\", line 130, in post_grad_passes\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     decompose_auto_functionalized(gm.graph)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/post_grad.py\", line 718, in decompose_auto_functionalized\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     graph_pass.apply(graph)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/pattern_matcher.py\", line 1700, in apply\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     entry.apply(m, graph, node)  # type: ignore[arg-type]\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/pattern_matcher.py\", line 1009, in apply\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     self.handler(match, *match.args, **match.kwargs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/post_grad.py\", line 716, in replacement\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     match.replace_by_example(decomp, flat_args, run_dce=False)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/pattern_matcher.py\", line 236, in replace_by_example\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     replacement = trace_fn(\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]                   ^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return func(*args, **kwargs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/pattern_matcher.py\", line 1796, in fwd_only\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     gm = make_fx(fn, select_decomp_table(), tracing_mode=\"real\")(*args)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 1421, in wrapped\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return make_fx_tracer.trace(f, *args)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 1367, in trace\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return self._trace_inner(f, *args)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 1354, in _trace_inner\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     t = dispatch_trace(\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]         ^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_compile.py\", line 31, in inner\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return disable_fn(*args, **kwargs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 600, in _fn\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return fn(*args, **kwargs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 642, in dispatch_trace\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     graph = tracer.trace(root, concrete_args)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 600, in _fn\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return fn(*args, **kwargs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/_symbolic_trace.py\", line 822, in trace\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     (self.create_arg(fn(*args)),),\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]                      ^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 660, in wrapped\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     out = f(*tensors)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]           ^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"<string>\", line 1, in <lambda>\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/post_grad.py\", line 714, in decomp\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return auto_functionalized_dense(*args, only_clone_these_tensors, **kwargs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_higher_order_ops/auto_functionalize.py\", line 127, in auto_functionalized_dense\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     clone_preserve_strides(kwargs[name])\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_prims_common/__init__.py\", line 1938, in clone_preserve_strides\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     buffer = torch.as_strided(x, (needed_size,), (1,), 0).clone()\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 705, in __torch_function__\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return func(*args, **kwargs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_stats.py\", line 21, in wrapper\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return fn(*args, **kwargs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 755, in __torch_dispatch__\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return self.inner_torch_dispatch(func, types, args, kwargs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 790, in inner_torch_dispatch\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return proxy_call(self, func, self.pre_dispatch, args, kwargs)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 398, in proxy_call\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     proxy_flat_args_kwargs = [\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]                              ^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 400, in <listcomp>\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     fetch_sym_proxy(proxy_mode.tracer)(e)\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 297, in inner\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     return get_proxy_slot(e, tracer)()\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 812, in _compute_proxy\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     n_args = tuple(\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]              ^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 813, in <genexpr>\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     get_proxy_slot(a, self.tracer)().node if isinstance(a, py_sym_types) else a\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 812, in _compute_proxy\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     n_args = tuple(\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]              ^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 813, in <genexpr>\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     get_proxy_slot(a, self.tracer)().node if isinstance(a, py_sym_types) else a\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 215, in <lambda>\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     tracer.create_proxy('call_function', torch.ops.aten.sym_storage_offset.default, (proxy,)), x))\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:05.943000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/17] TypeError: TracerBase.create_proxy() missing 1 required positional argument: 'kwargs'\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18] failed to eagerly compile backwards for dynamic, suppressing in case backwards not needed\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18] Traceback (most recent call last):\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 547, in aot_dispatch_autograd\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     compiled_bw_func = aot_config.bw_compiler(\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]                        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/backends/common.py\", line 47, in _wrapped_bw_compiler\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return disable(disable(bw_compiler)(*args, **kwargs))\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 600, in _fn\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_utils_internal.py\", line 84, in wrapper_function\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return StrobelightCompileTimeProfiler.profile_compile_time(\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_strobelight/compile_time_profiler.py\", line 129, in profile_compile_time\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return func(*args, **kwargs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]         ^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 1454, in bw_compiler\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return inner_compile(\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/repro/after_aot.py\", line 84, in debug_wrapper\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]         ^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 527, in compile_fx_inner\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     compiled_graph = fx_codegen_and_compile(\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]                      ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 746, in fx_codegen_and_compile\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     _recursive_post_grad_passes(gm, is_inference=is_inference)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 263, in _recursive_post_grad_passes\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     post_grad_passes(gm, is_inference)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/post_grad.py\", line 130, in post_grad_passes\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     decompose_auto_functionalized(gm.graph)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/post_grad.py\", line 718, in decompose_auto_functionalized\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     graph_pass.apply(graph)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/pattern_matcher.py\", line 1700, in apply\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     entry.apply(m, graph, node)  # type: ignore[arg-type]\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/pattern_matcher.py\", line 1009, in apply\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     self.handler(match, *match.args, **match.kwargs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/post_grad.py\", line 716, in replacement\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     match.replace_by_example(decomp, flat_args, run_dce=False)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/pattern_matcher.py\", line 236, in replace_by_example\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     replacement = trace_fn(\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]                   ^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return func(*args, **kwargs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/pattern_matcher.py\", line 1796, in fwd_only\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     gm = make_fx(fn, select_decomp_table(), tracing_mode=\"real\")(*args)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 1421, in wrapped\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return make_fx_tracer.trace(f, *args)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 1367, in trace\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return self._trace_inner(f, *args)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 1354, in _trace_inner\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     t = dispatch_trace(\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]         ^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_compile.py\", line 31, in inner\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return disable_fn(*args, **kwargs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 600, in _fn\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 642, in dispatch_trace\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     graph = tracer.trace(root, concrete_args)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 600, in _fn\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/_symbolic_trace.py\", line 822, in trace\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     (self.create_arg(fn(*args)),),\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]                      ^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 660, in wrapped\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     out = f(*tensors)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]           ^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"<string>\", line 1, in <lambda>\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/post_grad.py\", line 714, in decomp\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return auto_functionalized_dense(*args, only_clone_these_tensors, **kwargs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_higher_order_ops/auto_functionalize.py\", line 127, in auto_functionalized_dense\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     clone_preserve_strides(kwargs[name])\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_prims_common/__init__.py\", line 1938, in clone_preserve_strides\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     buffer = torch.as_strided(x, (needed_size,), (1,), 0).clone()\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 705, in __torch_function__\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return func(*args, **kwargs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_stats.py\", line 21, in wrapper\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 755, in __torch_dispatch__\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return self.inner_torch_dispatch(func, types, args, kwargs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 790, in inner_torch_dispatch\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return proxy_call(self, func, self.pre_dispatch, args, kwargs)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 398, in proxy_call\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     proxy_flat_args_kwargs = [\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]                              ^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 400, in <listcomp>\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     fetch_sym_proxy(proxy_mode.tracer)(e)\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 297, in inner\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     return get_proxy_slot(e, tracer)()\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 812, in _compute_proxy\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     n_args = tuple(\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]              ^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 813, in <genexpr>\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     get_proxy_slot(a, self.tracer)().node if isinstance(a, py_sym_types) else a\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 812, in _compute_proxy\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     n_args = tuple(\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]              ^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 813, in <genexpr>\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     get_proxy_slot(a, self.tracer)().node if isinstance(a, py_sym_types) else a\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py\", line 215, in <lambda>\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     tracer.create_proxy('call_function', torch.ops.aten.sym_storage_offset.default, (proxy,)), x))\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0602 20:57:10.337000 22681688094528 torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:551] [0/18] TypeError: TracerBase.create_proxy() missing 1 required positional argument: 'kwargs'\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18] Ignored guard Ne(369*s1*s6*((128//s6)), 1) == True, this could result in accuracy problems\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18] Stack (most recent call last):\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/autograd/function.py\", line 306, in apply\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return user_fn(self, *args)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 1861, in backward\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     out = call_compiled_backward()\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 1805, in call_compiled_backward\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     CompiledFunction.compiled_bw = aot_config.bw_compiler(\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/backends/common.py\", line 47, in _wrapped_bw_compiler\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return disable(disable(bw_compiler)(*args, **kwargs))\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 600, in _fn\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_utils_internal.py\", line 84, in wrapper_function\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return StrobelightCompileTimeProfiler.profile_compile_time(\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_strobelight/compile_time_profiler.py\", line 129, in profile_compile_time\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwargs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 1454, in bw_compiler\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return inner_compile(\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/repro/after_aot.py\", line 84, in debug_wrapper\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 527, in compile_fx_inner\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     compiled_graph = fx_codegen_and_compile(\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 738, in fx_codegen_and_compile\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     fake_mode = fake_tensor_prop(gm, example_inputs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 379, in fake_tensor_prop\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     FakeTensorProp(gm, mode=fake_mode).propagate_dont_convert_inputs(\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/passes/fake_tensor_prop.py\", line 69, in propagate_dont_convert_inputs\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return super().run(*args)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 146, in run\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     self.env[node] = self.run_node(node)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/passes/fake_tensor_prop.py\", line 37, in run_node\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     result = super().run_node(n)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 203, in run_node\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 275, in call_function\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return target(*args, **kwargs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_ops.py\", line 667, in __call__\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self_._op(*args, **kwargs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_stats.py\", line 21, in wrapper\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1061, in __torch_dispatch__\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self.dispatch(func, types, args, kwargs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1450, in dispatch\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self._cached_dispatch_impl(func, types, args, kwargs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1153, in _cached_dispatch_impl\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     output = self._dispatch_impl(func, types, args, kwargs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1757, in _dispatch_impl\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_ops.py\", line 667, in __call__\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self_._op(*args, **kwargs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_meta_registrations.py\", line 4807, in meta_select_scatter\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return utils.clone_preserve_strides(self)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_prims_common/__init__.py\", line 1938, in clone_preserve_strides\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     buffer = torch.as_strided(x, (needed_size,), (1,), 0).clone()\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/sym_node.py\", line 466, in guard_size_oblivious\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = self.shape_env.evaluate_expr(\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/recording.py\", line 245, in wrapper\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5215, in evaluate_expr\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     self._check_frozen(expr, concrete_val)\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5027, in _check_frozen\n",
      "W0602 20:57:10.872000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     log.warning(\"Ignored guard %s == %s, this could result in accuracy problems\", expr, concrete_val, stack_info=True)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18] Ignored guard Eq(369*s1*s6*((128//s6)), 1) == False, this could result in accuracy problems\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18] Stack (most recent call last):\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/autograd/function.py\", line 306, in apply\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return user_fn(self, *args)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 1861, in backward\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     out = call_compiled_backward()\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 1805, in call_compiled_backward\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     CompiledFunction.compiled_bw = aot_config.bw_compiler(\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/backends/common.py\", line 47, in _wrapped_bw_compiler\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return disable(disable(bw_compiler)(*args, **kwargs))\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 600, in _fn\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_utils_internal.py\", line 84, in wrapper_function\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return StrobelightCompileTimeProfiler.profile_compile_time(\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_strobelight/compile_time_profiler.py\", line 129, in profile_compile_time\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwargs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 1454, in bw_compiler\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return inner_compile(\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/repro/after_aot.py\", line 84, in debug_wrapper\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 527, in compile_fx_inner\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     compiled_graph = fx_codegen_and_compile(\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 738, in fx_codegen_and_compile\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     fake_mode = fake_tensor_prop(gm, example_inputs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 379, in fake_tensor_prop\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     FakeTensorProp(gm, mode=fake_mode).propagate_dont_convert_inputs(\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/passes/fake_tensor_prop.py\", line 69, in propagate_dont_convert_inputs\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return super().run(*args)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 146, in run\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     self.env[node] = self.run_node(node)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/passes/fake_tensor_prop.py\", line 37, in run_node\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     result = super().run_node(n)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 203, in run_node\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 275, in call_function\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return target(*args, **kwargs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_ops.py\", line 667, in __call__\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self_._op(*args, **kwargs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_stats.py\", line 21, in wrapper\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1061, in __torch_dispatch__\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self.dispatch(func, types, args, kwargs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1450, in dispatch\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self._cached_dispatch_impl(func, types, args, kwargs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1153, in _cached_dispatch_impl\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     output = self._dispatch_impl(func, types, args, kwargs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1757, in _dispatch_impl\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_ops.py\", line 667, in __call__\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self_._op(*args, **kwargs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_meta_registrations.py\", line 4807, in meta_select_scatter\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return utils.clone_preserve_strides(self)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_prims_common/__init__.py\", line 1938, in clone_preserve_strides\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     buffer = torch.as_strided(x, (needed_size,), (1,), 0).clone()\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/sym_node.py\", line 414, in guard_bool\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = self.shape_env.evaluate_expr(self.expr, self.hint, fx_node=self.fx_node)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/recording.py\", line 245, in wrapper\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5215, in evaluate_expr\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     self._check_frozen(expr, concrete_val)\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5027, in _check_frozen\n",
      "W0602 20:57:10.875000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     log.warning(\"Ignored guard %s == %s, this could result in accuracy problems\", expr, concrete_val, stack_info=True)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18] Ignored guard Ne(369*s1*s4*((128//s4)), 1) == True, this could result in accuracy problems\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18] Stack (most recent call last):\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/autograd/function.py\", line 306, in apply\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return user_fn(self, *args)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 1861, in backward\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     out = call_compiled_backward()\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 1805, in call_compiled_backward\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     CompiledFunction.compiled_bw = aot_config.bw_compiler(\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/backends/common.py\", line 47, in _wrapped_bw_compiler\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return disable(disable(bw_compiler)(*args, **kwargs))\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 600, in _fn\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_utils_internal.py\", line 84, in wrapper_function\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return StrobelightCompileTimeProfiler.profile_compile_time(\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_strobelight/compile_time_profiler.py\", line 129, in profile_compile_time\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwargs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 1454, in bw_compiler\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return inner_compile(\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/repro/after_aot.py\", line 84, in debug_wrapper\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 527, in compile_fx_inner\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     compiled_graph = fx_codegen_and_compile(\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 738, in fx_codegen_and_compile\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     fake_mode = fake_tensor_prop(gm, example_inputs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 379, in fake_tensor_prop\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     FakeTensorProp(gm, mode=fake_mode).propagate_dont_convert_inputs(\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/passes/fake_tensor_prop.py\", line 69, in propagate_dont_convert_inputs\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return super().run(*args)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 146, in run\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     self.env[node] = self.run_node(node)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/passes/fake_tensor_prop.py\", line 37, in run_node\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     result = super().run_node(n)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 203, in run_node\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 275, in call_function\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return target(*args, **kwargs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_ops.py\", line 667, in __call__\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self_._op(*args, **kwargs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_stats.py\", line 21, in wrapper\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1061, in __torch_dispatch__\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self.dispatch(func, types, args, kwargs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1450, in dispatch\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self._cached_dispatch_impl(func, types, args, kwargs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1153, in _cached_dispatch_impl\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     output = self._dispatch_impl(func, types, args, kwargs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1757, in _dispatch_impl\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_ops.py\", line 667, in __call__\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self_._op(*args, **kwargs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_meta_registrations.py\", line 4807, in meta_select_scatter\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return utils.clone_preserve_strides(self)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_prims_common/__init__.py\", line 1938, in clone_preserve_strides\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     buffer = torch.as_strided(x, (needed_size,), (1,), 0).clone()\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/sym_node.py\", line 466, in guard_size_oblivious\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = self.shape_env.evaluate_expr(\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/recording.py\", line 245, in wrapper\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5215, in evaluate_expr\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     self._check_frozen(expr, concrete_val)\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5027, in _check_frozen\n",
      "W0602 20:57:10.945000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     log.warning(\"Ignored guard %s == %s, this could result in accuracy problems\", expr, concrete_val, stack_info=True)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18] Ignored guard Eq(369*s1*s4*((128//s4)), 1) == False, this could result in accuracy problems\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18] Stack (most recent call last):\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/autograd/function.py\", line 306, in apply\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return user_fn(self, *args)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 1861, in backward\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     out = call_compiled_backward()\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 1805, in call_compiled_backward\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     CompiledFunction.compiled_bw = aot_config.bw_compiler(\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/backends/common.py\", line 47, in _wrapped_bw_compiler\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return disable(disable(bw_compiler)(*args, **kwargs))\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 600, in _fn\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_utils_internal.py\", line 84, in wrapper_function\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return StrobelightCompileTimeProfiler.profile_compile_time(\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_strobelight/compile_time_profiler.py\", line 129, in profile_compile_time\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwargs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 1454, in bw_compiler\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return inner_compile(\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/repro/after_aot.py\", line 84, in debug_wrapper\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 527, in compile_fx_inner\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     compiled_graph = fx_codegen_and_compile(\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 738, in fx_codegen_and_compile\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     fake_mode = fake_tensor_prop(gm, example_inputs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 379, in fake_tensor_prop\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     FakeTensorProp(gm, mode=fake_mode).propagate_dont_convert_inputs(\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/passes/fake_tensor_prop.py\", line 69, in propagate_dont_convert_inputs\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return super().run(*args)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 146, in run\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     self.env[node] = self.run_node(node)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/passes/fake_tensor_prop.py\", line 37, in run_node\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     result = super().run_node(n)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 203, in run_node\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/interpreter.py\", line 275, in call_function\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return target(*args, **kwargs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_ops.py\", line 667, in __call__\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self_._op(*args, **kwargs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_stats.py\", line 21, in wrapper\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1061, in __torch_dispatch__\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self.dispatch(func, types, args, kwargs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1450, in dispatch\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self._cached_dispatch_impl(func, types, args, kwargs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1153, in _cached_dispatch_impl\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     output = self._dispatch_impl(func, types, args, kwargs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1757, in _dispatch_impl\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_ops.py\", line 667, in __call__\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self_._op(*args, **kwargs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_meta_registrations.py\", line 4807, in meta_select_scatter\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return utils.clone_preserve_strides(self)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_prims_common/__init__.py\", line 1938, in clone_preserve_strides\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     buffer = torch.as_strided(x, (needed_size,), (1,), 0).clone()\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/sym_node.py\", line 414, in guard_bool\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = self.shape_env.evaluate_expr(self.expr, self.hint, fx_node=self.fx_node)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/recording.py\", line 245, in wrapper\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5215, in evaluate_expr\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     self._check_frozen(expr, concrete_val)\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5027, in _check_frozen\n",
      "W0602 20:57:10.948000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     log.warning(\"Ignored guard %s == %s, this could result in accuracy problems\", expr, concrete_val, stack_info=True)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18] Ignored guard Eq((128//s6), 1) == False, this could result in accuracy problems\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18] Stack (most recent call last):\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/autograd/function.py\", line 306, in apply\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return user_fn(self, *args)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 1861, in backward\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     out = call_compiled_backward()\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 1805, in call_compiled_backward\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     CompiledFunction.compiled_bw = aot_config.bw_compiler(\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/backends/common.py\", line 47, in _wrapped_bw_compiler\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return disable(disable(bw_compiler)(*args, **kwargs))\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 600, in _fn\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_utils_internal.py\", line 84, in wrapper_function\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return StrobelightCompileTimeProfiler.profile_compile_time(\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_strobelight/compile_time_profiler.py\", line 129, in profile_compile_time\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 1454, in bw_compiler\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return inner_compile(\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/repro/after_aot.py\", line 84, in debug_wrapper\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 527, in compile_fx_inner\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     compiled_graph = fx_codegen_and_compile(\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 746, in fx_codegen_and_compile\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     _recursive_post_grad_passes(gm, is_inference=is_inference)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 263, in _recursive_post_grad_passes\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     post_grad_passes(gm, is_inference)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/post_grad.py\", line 129, in post_grad_passes\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     reinplace_inplaceable_ops(gm.graph)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/reinplace.py\", line 549, in reinplace_inplaceable_ops\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     canonicalize_view_scatter_ops(graph)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/reinplace.py\", line 319, in canonicalize_view_scatter_ops\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     handle_view_scatter(node)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/reinplace.py\", line 278, in handle_view_scatter\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     new_node = graph_call_function(\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/reinplace.py\", line 45, in graph_call_function\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     fake_result = fn(*fake_args, **fake_kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/reinplace.py\", line 82, in _generalized_scatter\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return _inplace_generalized_scatter(out, src, view_ops)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/reinplace.py\", line 70, in _inplace_generalized_scatter\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     tmp.copy_(src)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_stats.py\", line 21, in wrapper\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1061, in __torch_dispatch__\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self.dispatch(func, types, args, kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1450, in dispatch\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self._cached_dispatch_impl(func, types, args, kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1153, in _cached_dispatch_impl\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     output = self._dispatch_impl(func, types, args, kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1730, in _dispatch_impl\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     op_impl_out = op_impl(self, func, *args, **kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_impls.py\", line 150, in dispatch_to_op_implementations_dict\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return op_implementations_dict[func](fake_mode, func, *args, **kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_impls.py\", line 569, in multi_device_op_default\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return run_and_return_new_tensor_of_input_device(fake_mode, func, args, kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_impls.py\", line 479, in run_and_return_new_tensor_of_input_device\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     out = func(*args, **kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_ops.py\", line 667, in __call__\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self_._op(*args, **kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/sym_node.py\", line 414, in guard_bool\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = self.shape_env.evaluate_expr(self.expr, self.hint, fx_node=self.fx_node)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/recording.py\", line 245, in wrapper\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5215, in evaluate_expr\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     self._check_frozen(expr, concrete_val)\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5027, in _check_frozen\n",
      "W0602 20:57:10.985000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     log.warning(\"Ignored guard %s == %s, this could result in accuracy problems\", expr, concrete_val, stack_info=True)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18] Ignored guard Eq((128//s4), 1) == False, this could result in accuracy problems\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18] Stack (most recent call last):\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/autograd/function.py\", line 306, in apply\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return user_fn(self, *args)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 1861, in backward\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     out = call_compiled_backward()\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\", line 1805, in call_compiled_backward\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     CompiledFunction.compiled_bw = aot_config.bw_compiler(\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/backends/common.py\", line 47, in _wrapped_bw_compiler\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return disable(disable(bw_compiler)(*args, **kwargs))\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 600, in _fn\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_utils_internal.py\", line 84, in wrapper_function\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return StrobelightCompileTimeProfiler.profile_compile_time(\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_strobelight/compile_time_profiler.py\", line 129, in profile_compile_time\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 1454, in bw_compiler\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return inner_compile(\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/repro/after_aot.py\", line 84, in debug_wrapper\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/debug.py\", line 304, in inner\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = func(*args, **kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 527, in compile_fx_inner\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     compiled_graph = fx_codegen_and_compile(\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/contextlib.py\", line 81, in inner\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return func(*args, **kwds)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 746, in fx_codegen_and_compile\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     _recursive_post_grad_passes(gm, is_inference=is_inference)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py\", line 263, in _recursive_post_grad_passes\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     post_grad_passes(gm, is_inference)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/post_grad.py\", line 129, in post_grad_passes\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     reinplace_inplaceable_ops(gm.graph)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/reinplace.py\", line 549, in reinplace_inplaceable_ops\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     canonicalize_view_scatter_ops(graph)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/reinplace.py\", line 319, in canonicalize_view_scatter_ops\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     handle_view_scatter(node)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/reinplace.py\", line 278, in handle_view_scatter\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     new_node = graph_call_function(\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/reinplace.py\", line 45, in graph_call_function\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     fake_result = fn(*fake_args, **fake_kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/reinplace.py\", line 82, in _generalized_scatter\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return _inplace_generalized_scatter(out, src, view_ops)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/reinplace.py\", line 70, in _inplace_generalized_scatter\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     tmp.copy_(src)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_stats.py\", line 21, in wrapper\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1061, in __torch_dispatch__\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self.dispatch(func, types, args, kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1450, in dispatch\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self._cached_dispatch_impl(func, types, args, kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1153, in _cached_dispatch_impl\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     output = self._dispatch_impl(func, types, args, kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1730, in _dispatch_impl\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     op_impl_out = op_impl(self, func, *args, **kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_impls.py\", line 150, in dispatch_to_op_implementations_dict\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return op_implementations_dict[func](fake_mode, func, *args, **kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_impls.py\", line 569, in multi_device_op_default\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return run_and_return_new_tensor_of_input_device(fake_mode, func, args, kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_impls.py\", line 479, in run_and_return_new_tensor_of_input_device\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     out = func(*args, **kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/_ops.py\", line 667, in __call__\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return self_._op(*args, **kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/sym_node.py\", line 414, in guard_bool\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     r = self.shape_env.evaluate_expr(self.expr, self.hint, fx_node=self.fx_node)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/recording.py\", line 245, in wrapper\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     return fn(*args, **kwargs)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5215, in evaluate_expr\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     self._check_frozen(expr, concrete_val)\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 5027, in _check_frozen\n",
      "W0602 20:57:10.992000 22664771003968 torch/fx/experimental/symbolic_shapes.py:5027] [0/18]     log.warning(\"Ignored guard %s == %s, this could result in accuracy problems\", expr, concrete_val, stack_info=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TracerBase.create_proxy() missing 1 required positional argument: 'kwargs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m single_sim_run(\n\u001b[1;32m      2\u001b[0m               feature_type\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranscriptome\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}],\n\u001b[1;32m      3\u001b[0m               use_shared_regions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m               test_shared_regions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m               omit_subcortical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m               parcellation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS400\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m               hemisphere\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m               connectome_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFC\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m               binarize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m               impute_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmirror_interpolate\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m               sort_genes\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefgenome\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m               gene_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.2\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m               cv_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspatial\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m               random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m,\n\u001b[1;32m     15\u001b[0m               search_method\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwandb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m5\u001b[39m),\n\u001b[1;32m     16\u001b[0m               track_wandb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m               skip_cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m               model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshared_transformer\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m               use_gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     20\u001b[0m               null_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     21\u001b[0m               use_folds\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     22\u001b[0m               )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Clear GPU memory\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n",
      "File \u001b[0;32m/scratch/asr655/neuroinformatics/GeneEx2Conn/sim/sim_run.py:148\u001b[0m, in \u001b[0;36msingle_sim_run\u001b[0;34m(feature_type, use_shared_regions, test_shared_regions, omit_subcortical, parcellation, hemisphere, connectome_target, binarize, impute_strategy, sort_genes, gene_list, cv_type, resolution, random_seed, search_method, track_wandb, skip_cv, model_type, use_gpu, null_model, use_folds)\u001b[0m\n\u001b[1;32m    126\u001b[0m sim \u001b[38;5;241m=\u001b[39m Simulation(\n\u001b[1;32m    127\u001b[0m                 feature_type\u001b[38;5;241m=\u001b[39mfeature_type,\n\u001b[1;32m    128\u001b[0m                 use_shared_regions\u001b[38;5;241m=\u001b[39muse_shared_regions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 null_model\u001b[38;5;241m=\u001b[39mnull_model\n\u001b[1;32m    145\u001b[0m             )\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m search_method[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwandb\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 148\u001b[0m     sim\u001b[38;5;241m.\u001b[39mrun_sim_torch(search_method, track_wandb, use_folds)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     sim\u001b[38;5;241m.\u001b[39mrun_sim(search_method, track_wandb)\n",
      "File \u001b[0;32m/scratch/asr655/neuroinformatics/GeneEx2Conn/sim/sim.py:347\u001b[0m, in \u001b[0;36mSimulation.run_sim_torch\u001b[0;34m(self, search_method, track_wandb, use_folds)\u001b[0m\n\u001b[1;32m    345\u001b[0m             train_history \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregion_pair_dataset, train_indices, test_indices)\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m--> 347\u001b[0m         train_history \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregion_pair_dataset, train_indices_expanded, test_indices_expanded)\n\u001b[1;32m    349\u001b[0m \u001b[38;5;66;03m# Evaluate on the test fold\u001b[39;00m\n\u001b[1;32m    350\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m Subset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregion_pair_dataset, train_indices_expanded)\n",
      "File \u001b[0;32m/scratch/asr655/neuroinformatics/GeneEx2Conn/models/transformer_models.py:253\u001b[0m, in \u001b[0;36mSharedSelfAttentionModel.fit\u001b[0;34m(self, dataset, train_indices, test_indices, verbose)\u001b[0m\n\u001b[1;32m    251\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    252\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_model(\u001b[38;5;28mself\u001b[39m, train_loader, test_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatience, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler, verbose\u001b[38;5;241m=\u001b[39mverbose, dataset\u001b[38;5;241m=\u001b[39mdataset)\n",
      "File \u001b[0;32m/scratch/asr655/neuroinformatics/GeneEx2Conn/models/train_val.py:23\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, epochs, criterion, optimizer, patience, scheduler, verbose, dataset)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     21\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m    \n\u001b[0;32m---> 23\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_epoch(model, train_loader, criterion, optimizer, device, epoch, scaler\u001b[38;5;241m=\u001b[39mscaler, dataset\u001b[38;5;241m=\u001b[39mdataset)\n\u001b[1;32m     24\u001b[0m     train_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_loader:\n",
      "File \u001b[0;32m/scratch/asr655/neuroinformatics/GeneEx2Conn/models/train_val.py:95\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, criterion, optimizer, device, epoch, scaler, dataset)\u001b[0m\n\u001b[1;32m     93\u001b[0m         predictions \u001b[38;5;241m=\u001b[39m model(batch_X)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     94\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(predictions, batch_y)\n\u001b[0;32m---> 95\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     96\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[1;32m     97\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    523\u001b[0m )\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m _engine_run_backward(\n\u001b[1;32m    290\u001b[0m     tensors,\n\u001b[1;32m    291\u001b[0m     grad_tensors_,\n\u001b[1;32m    292\u001b[0m     retain_graph,\n\u001b[1;32m    293\u001b[0m     create_graph,\n\u001b[1;32m    294\u001b[0m     inputs,\n\u001b[1;32m    295\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    296\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    297\u001b[0m )\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/autograd/function.py:306\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m     )\n\u001b[1;32m    305\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m user_fn(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:1861\u001b[0m, in \u001b[0;36mAOTDispatchAutograd.post_compile.<locals>.CompiledFunction.backward\u001b[0;34m(ctx, *flat_args)\u001b[0m\n\u001b[1;32m   1859\u001b[0m     out \u001b[38;5;241m=\u001b[39m CompiledFunctionBackward\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39mall_args)\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1861\u001b[0m     out \u001b[38;5;241m=\u001b[39m call_compiled_backward()\n\u001b[1;32m   1863\u001b[0m \u001b[38;5;66;03m# TODO: figure out how to refactor the backward properly so I can use aot_dispatch_subclass_wrapper() here.\u001b[39;00m\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m CompiledFunction\u001b[38;5;241m.\u001b[39mmaybe_subclass_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:1805\u001b[0m, in \u001b[0;36mAOTDispatchAutograd.post_compile.<locals>.CompiledFunction.backward.<locals>.call_compiled_backward\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1799\u001b[0m     context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1800\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableAutocast \u001b[38;5;28;01mif\u001b[39;00m disable_amp \u001b[38;5;28;01melse\u001b[39;00m nullcontext\n\u001b[1;32m   1801\u001b[0m     )\n\u001b[1;32m   1802\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(saved_context), compile_context(\n\u001b[1;32m   1803\u001b[0m         saved_compile_context\n\u001b[1;32m   1804\u001b[0m     ), context(), track_graph_compiling(aot_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1805\u001b[0m         CompiledFunction\u001b[38;5;241m.\u001b[39mcompiled_bw \u001b[38;5;241m=\u001b[39m aot_config\u001b[38;5;241m.\u001b[39mbw_compiler(\n\u001b[1;32m   1806\u001b[0m             bw_module, placeholder_list\n\u001b[1;32m   1807\u001b[0m         )\n\u001b[1;32m   1809\u001b[0m out \u001b[38;5;241m=\u001b[39m call_func_at_runtime_with_args(\n\u001b[1;32m   1810\u001b[0m     CompiledFunction\u001b[38;5;241m.\u001b[39mcompiled_bw,\n\u001b[1;32m   1811\u001b[0m     all_args,\n\u001b[1;32m   1812\u001b[0m     steal_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1813\u001b[0m     disable_amp\u001b[38;5;241m=\u001b[39mdisable_amp,\n\u001b[1;32m   1814\u001b[0m )\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;66;03m# TODO: replace this with FunctionalizedRngRuntimeWrapper.post_compile\u001b[39;00m\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/backends/common.py:47\u001b[0m, in \u001b[0;36mAotAutograd.__call__.<locals>._wrapped_bw_compiler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_bw_compiler\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# stop TorchDynamo from trying to compile our generated backwards pass\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disable(disable(bw_compiler)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    602\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_utils_internal.py:84\u001b[0m, in \u001b[0;36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     83\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler\u001b[38;5;241m.\u001b[39mprofile_compile_time(\n\u001b[1;32m     85\u001b[0m     function, phase_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     86\u001b[0m )\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_strobelight/compile_time_profiler.py:129\u001b[0m, in \u001b[0;36mStrobelightCompileTimeProfiler.profile_compile_time\u001b[0;34m(cls, func, phase_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprofile_compile_time\u001b[39m(\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mcls\u001b[39m, func: Any, phase_name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    127\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39menabled:\n\u001b[0;32m--> 129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprofiler is not set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py:231\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (dynamo_timed)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    230\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 231\u001b[0m     r \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    232\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    233\u001b[0m compilation_time_metrics[key]\u001b[38;5;241m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:1454\u001b[0m, in \u001b[0;36mcompile_fx.<locals>.bw_compiler\u001b[0;34m(model, example_inputs)\u001b[0m\n\u001b[1;32m   1450\u001b[0m     user_visible_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(\n\u001b[1;32m   1451\u001b[0m         n\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m model_outputs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n, torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mNode)\n\u001b[1;32m   1452\u001b[0m     )\n\u001b[1;32m   1453\u001b[0m fixed \u001b[38;5;241m=\u001b[39m count_tangents(model)\n\u001b[0;32m-> 1454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_compile(\n\u001b[1;32m   1455\u001b[0m     model,\n\u001b[1;32m   1456\u001b[0m     example_inputs,\n\u001b[1;32m   1457\u001b[0m     static_input_idxs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(fixed)),\n\u001b[1;32m   1458\u001b[0m     cudagraphs\u001b[38;5;241m=\u001b[39mcudagraphs,\n\u001b[1;32m   1459\u001b[0m     is_backward\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1460\u001b[0m     graph_id\u001b[38;5;241m=\u001b[39mgraph_id,\n\u001b[1;32m   1461\u001b[0m     boxed_forward_device_index\u001b[38;5;241m=\u001b[39mforward_device,\n\u001b[1;32m   1462\u001b[0m     user_visible_outputs\u001b[38;5;241m=\u001b[39muser_visible_outputs,\n\u001b[1;32m   1463\u001b[0m )\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/repro/after_aot.py:84\u001b[0m, in \u001b[0;36mwrap_compiler_debug.<locals>.debug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrepro_after \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdynamo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# with fake inputs\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     inner_compiled_fn \u001b[38;5;241m=\u001b[39m compiler_fn(gm, example_inputs)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# need a different serialization strategy\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrepro_after \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/debug.py:304\u001b[0m, in \u001b[0;36mDebugContext.wrap.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DebugContext():\n\u001b[0;32m--> 304\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py:231\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (dynamo_timed)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    230\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 231\u001b[0m     r \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    232\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    233\u001b[0m compilation_time_metrics[key]\u001b[38;5;241m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:527\u001b[0m, in \u001b[0;36mcompile_fx_inner\u001b[0;34m(gm, example_inputs, cudagraphs, static_input_idxs, is_backward, graph_id, cpp_wrapper, aot_mode, is_inference, boxed_forward_device_index, user_visible_outputs, layout_opt, extern_node_serializer)\u001b[0m\n\u001b[1;32m    517\u001b[0m     compiled_graph \u001b[38;5;241m=\u001b[39m FxGraphCache\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m    518\u001b[0m         fx_codegen_and_compile,\n\u001b[1;32m    519\u001b[0m         gm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m         remote\u001b[38;5;241m=\u001b[39mfx_graph_remote_cache,\n\u001b[1;32m    525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 527\u001b[0m     compiled_graph \u001b[38;5;241m=\u001b[39m fx_codegen_and_compile(\n\u001b[1;32m    528\u001b[0m         gm, example_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgraph_kwargs  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    531\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFX codegen and compilation took \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# check cudagraph disabling reasons from inductor lowering\u001b[39;00m\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:746\u001b[0m, in \u001b[0;36mfx_codegen_and_compile\u001b[0;34m(gm, example_inputs, cudagraphs, static_input_idxs, is_backward, graph_id, cpp_wrapper, aot_mode, is_inference, user_visible_outputs, layout_opt, extern_node_serializer)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# pattern matcher passes might not preserve striding information\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;66;03m# on node.meta[\"val\"]. if in the future we rely on these being\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# correct we will need to fix.\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m V\u001b[38;5;241m.\u001b[39mset_fake_mode(fake_mode):\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;66;03m# has some issues with memory in training\u001b[39;00m\n\u001b[0;32m--> 746\u001b[0m     _recursive_post_grad_passes(gm, is_inference\u001b[38;5;241m=\u001b[39mis_inference)\n\u001b[1;32m    747\u001b[0m     V\u001b[38;5;241m.\u001b[39mdebug\u001b[38;5;241m.\u001b[39mfx_graph_transformed(gm, example_inputs)\n\u001b[1;32m    748\u001b[0m     post_grad_graphs_log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    750\u001b[0m         lazy_format_graph_code(\n\u001b[1;32m    751\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAFTER POST GRAD\u001b[39m\u001b[38;5;124m\"\u001b[39m, gm, include_stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, include_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    752\u001b[0m         ),\n\u001b[1;32m    753\u001b[0m     )\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:263\u001b[0m, in \u001b[0;36m_recursive_post_grad_passes\u001b[0;34m(gm, is_inference)\u001b[0m\n\u001b[1;32m    261\u001b[0m     subgraph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(gm, subgraph_name)\n\u001b[1;32m    262\u001b[0m     _recursive_post_grad_passes(subgraph, is_inference)\n\u001b[0;32m--> 263\u001b[0m post_grad_passes(gm, is_inference)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/post_grad.py:130\u001b[0m, in \u001b[0;36mpost_grad_passes\u001b[0;34m(gm, is_inference)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Keep these last, since they introduces mutation. Look at\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# ./fx_passes/README.md for a discussion of mutation invariants.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m reinplace_inplaceable_ops(gm\u001b[38;5;241m.\u001b[39mgraph)\n\u001b[0;32m--> 130\u001b[0m decompose_auto_functionalized(gm\u001b[38;5;241m.\u001b[39mgraph)\n\u001b[1;32m    132\u001b[0m gm\u001b[38;5;241m.\u001b[39mrecompile()\n\u001b[1;32m    133\u001b[0m optimus_scuba_log[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafter_recompile_post_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m upload_graph(gm\u001b[38;5;241m.\u001b[39mgraph)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/post_grad.py:718\u001b[0m, in \u001b[0;36mdecompose_auto_functionalized\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m auto_functionalized_dense(\u001b[38;5;241m*\u001b[39margs, only_clone_these_tensors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mmatch\u001b[39;00m\u001b[38;5;241m.\u001b[39mreplace_by_example(decomp, flat_args, run_dce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 718\u001b[0m graph_pass\u001b[38;5;241m.\u001b[39mapply(graph)\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mfind_nodes(\n\u001b[1;32m    720\u001b[0m     op\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_function\u001b[39m\u001b[38;5;124m\"\u001b[39m, target\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mhigher_order\u001b[38;5;241m.\u001b[39mauto_functionalized\n\u001b[1;32m    721\u001b[0m ):\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_functionalized was not removed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/pattern_matcher.py:1700\u001b[0m, in \u001b[0;36mPatternMatcherPass.apply\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_match(m) \u001b[38;5;129;01mand\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mextra_check(m):\n\u001b[1;32m   1699\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1700\u001b[0m     entry\u001b[38;5;241m.\u001b[39mapply(m, graph, node)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1701\u001b[0m     counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minductor\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpattern_matcher_count\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1702\u001b[0m     counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minductor\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpattern_matcher_nodes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(m\u001b[38;5;241m.\u001b[39mnodes)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/pattern_matcher.py:1009\u001b[0m, in \u001b[0;36mGraphPatternEntry.apply\u001b[0;34m(self, match, graph, node)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, match: Match, graph: torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mGraph, node: torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mNode) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39minserting_before(node):\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandler(match, \u001b[38;5;241m*\u001b[39mmatch\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmatch\u001b[38;5;241m.\u001b[39mkwargs)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/post_grad.py:716\u001b[0m, in \u001b[0;36mdecompose_auto_functionalized.<locals>.replacement\u001b[0;34m(match, *args, **kwargs)\u001b[0m\n\u001b[1;32m    713\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(flat_args, spec)\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auto_functionalized_dense(\u001b[38;5;241m*\u001b[39margs, only_clone_these_tensors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 716\u001b[0m \u001b[38;5;28;01mmatch\u001b[39;00m\u001b[38;5;241m.\u001b[39mreplace_by_example(decomp, flat_args, run_dce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/pattern_matcher.py:236\u001b[0m, in \u001b[0;36mMatch.replace_by_example\u001b[0;34m(self, replacement_fn, args, trace_fn, run_dce)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     trace_fn \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(fwd_only, run_dce\u001b[38;5;241m=\u001b[39mrun_dce)\n\u001b[0;32m--> 236\u001b[0m replacement \u001b[38;5;241m=\u001b[39m trace_fn(\n\u001b[1;32m    237\u001b[0m     replacement_fn, torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mmap_arg(args, \u001b[38;5;28;01mlambda\u001b[39;00m arg: arg\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    238\u001b[0m )\n\u001b[1;32m    239\u001b[0m ReplacementPatternEntry\u001b[38;5;241m.\u001b[39mreplace_with_graph(\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39mgraph,\n\u001b[1;32m    242\u001b[0m     replacement,\n\u001b[1;32m    243\u001b[0m     args,\n\u001b[1;32m    244\u001b[0m )\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/pattern_matcher.py:1796\u001b[0m, in \u001b[0;36mfwd_only\u001b[0;34m(fn, args, run_dce)\u001b[0m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;66;03m# TODO - look into using aot autograd, asserting no mutating ops here\u001b[39;00m\n\u001b[1;32m   1795\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m enable_python_dispatcher():\n\u001b[0;32m-> 1796\u001b[0m     gm \u001b[38;5;241m=\u001b[39m make_fx(fn, select_decomp_table(), tracing_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1798\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx_passes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpost_grad\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m remove_noop_ops\n\u001b[1;32m   1800\u001b[0m remove_noop_ops(gm\u001b[38;5;241m.\u001b[39mgraph)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:1421\u001b[0m, in \u001b[0;36mmake_fx.<locals>.wrapped\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m make_fx_tracer\u001b[38;5;241m.\u001b[39mtrace(f, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:1367\u001b[0m, in \u001b[0;36m_MakefxTracer.trace\u001b[0;34m(self, f, *args)\u001b[0m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrace\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mGraphModule:\n\u001b[1;32m   1366\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_modes_from_inputs(f, args):\n\u001b[0;32m-> 1367\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_inner(f, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:1354\u001b[0m, in \u001b[0;36m_MakefxTracer._trace_inner\u001b[0;34m(self, f, *args)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;66;03m# We disable the autocast cache as the autocast cache causes type conversions on parameters to\u001b[39;00m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;66;03m# check a cache, which introduces untracked tensors into the graph\u001b[39;00m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;66;03m# We also disable tracing by any other tensor proxy-based tracers except the current. The\u001b[39;00m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;66;03m# purpose of `make_fx` is to produce graphmodules as a side effect; its internal execution is\u001b[39;00m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;66;03m# thus irrelevant to any external functional trace.\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m decompose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecomposition_table), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfake_tensor_mode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_dispatcher_mode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy_function_mode, \\\n\u001b[1;32m   1352\u001b[0m      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy_mode\u001b[38;5;241m.\u001b[39msym_mode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtorch_fn_metadata_mode, \\\n\u001b[1;32m   1353\u001b[0m      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy_mode, disable_autocast_cache(), _set_make_fx_tracer(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1354\u001b[0m     t \u001b[38;5;241m=\u001b[39m dispatch_trace(\n\u001b[1;32m   1355\u001b[0m         wrap_key(func, args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfx_tracer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_dispatch),\n\u001b[1;32m   1356\u001b[0m         tracer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfx_tracer,\n\u001b[1;32m   1357\u001b[0m         concrete_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(phs)\n\u001b[1;32m   1358\u001b[0m     )\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;66;03m# TODO: kind of a bad way to do it, should maybe figure out a better way\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracing_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbolic\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_compile.py:31\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     29\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m disable_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    602\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:642\u001b[0m, in \u001b[0;36mdispatch_trace\u001b[0;34m(root, tracer, concrete_args)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_dynamo\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdispatch_trace\u001b[39m(\n\u001b[1;32m    638\u001b[0m         root: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, Callable],\n\u001b[1;32m    639\u001b[0m         tracer: Tracer,\n\u001b[1;32m    640\u001b[0m         concrete_args: Optional[Tuple[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    641\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GraphModule:\n\u001b[0;32m--> 642\u001b[0m     graph \u001b[38;5;241m=\u001b[39m tracer\u001b[38;5;241m.\u001b[39mtrace(root, concrete_args)\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx_passes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdedupe_symint_uses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dedupe_symints\n\u001b[1;32m    644\u001b[0m     dedupe_symints(graph)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    602\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/_symbolic_trace.py:822\u001b[0m, in \u001b[0;36mTracer.trace\u001b[0;34m(self, root, concrete_args)\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_search:\n\u001b[1;32m    816\u001b[0m             _autowrap_check(\n\u001b[1;32m    817\u001b[0m                 patcher, module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_function_ids\n\u001b[1;32m    818\u001b[0m             )\n\u001b[1;32m    819\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_node(\n\u001b[1;32m    820\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    821\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 822\u001b[0m             (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_arg(fn(\u001b[38;5;241m*\u001b[39margs)),),\n\u001b[1;32m    823\u001b[0m             {},\n\u001b[1;32m    824\u001b[0m             type_expr\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__annotations__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    825\u001b[0m         )\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmodule_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:660\u001b[0m, in \u001b[0;36mwrap_key.<locals>.wrapped\u001b[0;34m(*proxies)\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, ProxyTorchDispatchMode)\n\u001b[1;32m    658\u001b[0m     track_tensor_tree(flat_tensors, flat_proxies, constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tracer\u001b[38;5;241m=\u001b[39mtracer)\n\u001b[0;32m--> 660\u001b[0m out \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39mtensors)\n\u001b[1;32m    661\u001b[0m out \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_map_only(\n\u001b[1;32m    662\u001b[0m     torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m t: get_proxy_slot(t, tracer, t, \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mproxy),\n\u001b[1;32m    664\u001b[0m     out\n\u001b[1;32m    665\u001b[0m )\n\u001b[1;32m    666\u001b[0m out \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_map_only(\n\u001b[1;32m    667\u001b[0m     (torch\u001b[38;5;241m.\u001b[39mScriptObject, FakeScriptObject),\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m t: get_proxy_slot(t, tracer, t, \u001b[38;5;28;01mlambda\u001b[39;00m x: x),\n\u001b[1;32m    669\u001b[0m     out\n\u001b[1;32m    670\u001b[0m )\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(arg0, arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13, arg14, arg15, arg16, arg17, arg18)\u001b[0m\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_inductor/fx_passes/post_grad.py:714\u001b[0m, in \u001b[0;36mdecompose_auto_functionalized.<locals>.replacement.<locals>.decomp\u001b[0;34m(*flat_args)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecomp\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_args):\n\u001b[1;32m    713\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(flat_args, spec)\n\u001b[0;32m--> 714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auto_functionalized_dense(\u001b[38;5;241m*\u001b[39margs, only_clone_these_tensors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_higher_order_ops/auto_functionalize.py:127\u001b[0m, in \u001b[0;36mauto_functionalized_dense\u001b[0;34m(_mutable_op, _only_clone_these_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         new_kwargs[name] \u001b[38;5;241m=\u001b[39m kwargs[name]\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m         new_kwargs[name] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 127\u001b[0m             clone_preserve_strides(kwargs[name])\n\u001b[1;32m    128\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m kwargs[name] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    129\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         )\n\u001b[1;32m    131\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(new_kwargs[name])\n\u001b[1;32m    132\u001b[0m out \u001b[38;5;241m=\u001b[39m _mutable_op(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/_prims_common/__init__.py:1938\u001b[0m, in \u001b[0;36mclone_preserve_strides\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1932\u001b[0m     old \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_dispatch_tls_is_dispatch_key_excluded(\n\u001b[1;32m   1933\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mDispatchKey\u001b[38;5;241m.\u001b[39mADInplaceOrView\n\u001b[1;32m   1934\u001b[0m     )\n\u001b[1;32m   1935\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_dispatch_tls_set_dispatch_key_excluded(\n\u001b[1;32m   1936\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mDispatchKey\u001b[38;5;241m.\u001b[39mADInplaceOrView, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1937\u001b[0m     )\n\u001b[0;32m-> 1938\u001b[0m     buffer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_strided(x, (needed_size,), (\u001b[38;5;241m1\u001b[39m,), \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m   1939\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mas_strided(buffer, x\u001b[38;5;241m.\u001b[39msize(), x\u001b[38;5;241m.\u001b[39mstride(), x\u001b[38;5;241m.\u001b[39mstorage_offset())\n\u001b[1;32m   1940\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:705\u001b[0m, in \u001b[0;36mTorchFunctionMetadataMode.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mtorch_fn_metadata \u001b[38;5;241m=\u001b[39m func\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mtorch_fn_counts[func] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mtorch_fn_counts\u001b[38;5;241m.\u001b[39mget(func, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 705\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_stats.py:21\u001b[0m, in \u001b[0;36mcount.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     simple_call_counter[fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     20\u001b[0m simple_call_counter[fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m] \u001b[38;5;241m=\u001b[39m simple_call_counter[fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:755\u001b[0m, in \u001b[0;36mProxyTorchDispatchMode.__torch_dispatch__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;129m@count\u001b[39m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__torch_dispatch__\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, types, args\u001b[38;5;241m=\u001b[39m(), kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msym_mode\u001b[38;5;241m.\u001b[39menable(\u001b[38;5;28;01mFalse\u001b[39;00m), set_original_aten_op(func):\n\u001b[0;32m--> 755\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_torch_dispatch(func, types, args, kwargs)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:790\u001b[0m, in \u001b[0;36mProxyTorchDispatchMode.inner_torch_dispatch\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m [prim\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mdefault]:\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 790\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m proxy_call(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_dispatch, args, kwargs)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:398\u001b[0m, in \u001b[0;36mproxy_call\u001b[0;34m(proxy_mode, func, pre_dispatch, args, kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    389\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt appears that you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre trying to get value out of a tracing tensor with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - erroring out! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms likely that this is caused by data-dependent control flow or similar.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt may be possible to trace this with dynamic shapes; try setting tracing_mode=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbolic\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min your make_fx call.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m         )\n\u001b[1;32m    395\u001b[0m proxy_flat_args_kwargs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    396\u001b[0m     e\u001b[38;5;241m.\u001b[39mproxy \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _ProxyTensor) \u001b[38;5;28;01melse\u001b[39;00m e \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m f_flat_args_kwargs\n\u001b[1;32m    397\u001b[0m ]\n\u001b[0;32m--> 398\u001b[0m proxy_flat_args_kwargs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    399\u001b[0m     (\n\u001b[1;32m    400\u001b[0m         fetch_sym_proxy(proxy_mode\u001b[38;5;241m.\u001b[39mtracer)(e)\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (SymInt, SymFloat, SymBool))\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m e\n\u001b[1;32m    403\u001b[0m     )\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m proxy_flat_args_kwargs\n\u001b[1;32m    405\u001b[0m ]\n\u001b[1;32m    406\u001b[0m proxy_args, proxy_kwargs \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(proxy_flat_args_kwargs, spec)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# When we trace through a torch.tensor invocation, you never actually\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# see a torch.ops.aten.tensor call. Instead, the way this function is\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# implemented internally is that we allocate a plain tensor (this is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# This is what the overload modification does.\u001b[39;00m\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:400\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    389\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt appears that you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre trying to get value out of a tracing tensor with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - erroring out! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms likely that this is caused by data-dependent control flow or similar.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt may be possible to trace this with dynamic shapes; try setting tracing_mode=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbolic\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min your make_fx call.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m         )\n\u001b[1;32m    395\u001b[0m proxy_flat_args_kwargs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    396\u001b[0m     e\u001b[38;5;241m.\u001b[39mproxy \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _ProxyTensor) \u001b[38;5;28;01melse\u001b[39;00m e \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m f_flat_args_kwargs\n\u001b[1;32m    397\u001b[0m ]\n\u001b[1;32m    398\u001b[0m proxy_flat_args_kwargs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    399\u001b[0m     (\n\u001b[0;32m--> 400\u001b[0m         fetch_sym_proxy(proxy_mode\u001b[38;5;241m.\u001b[39mtracer)(e)\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (SymInt, SymFloat, SymBool))\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m e\n\u001b[1;32m    403\u001b[0m     )\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m proxy_flat_args_kwargs\n\u001b[1;32m    405\u001b[0m ]\n\u001b[1;32m    406\u001b[0m proxy_args, proxy_kwargs \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(proxy_flat_args_kwargs, spec)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# When we trace through a torch.tensor invocation, you never actually\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# see a torch.ops.aten.tensor call. Instead, the way this function is\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# implemented internally is that we allocate a plain tensor (this is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# This is what the overload modification does.\u001b[39;00m\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:297\u001b[0m, in \u001b[0;36mfetch_sym_proxy.<locals>.inner\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(e\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mexpr)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;66;03m# NB: we REQUIRE all symints to be tracked\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_proxy_slot(e, tracer)()\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:812\u001b[0m, in \u001b[0;36mProxySymDispatchMode._compute_proxy\u001b[0;34m(self, func, args, out)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_proxy\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, args, out: Union[SymInt, SymFloat, SymBool]):\n\u001b[0;32m--> 812\u001b[0m     n_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    813\u001b[0m         get_proxy_slot(a, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer)()\u001b[38;5;241m.\u001b[39mnode \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, py_sym_types) \u001b[38;5;28;01melse\u001b[39;00m a\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args\n\u001b[1;32m    815\u001b[0m     )\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;66;03m# func doesn't have a __torch_function__ that Proxy can interpose, so\u001b[39;00m\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;66;03m# we gotta do it manually\u001b[39;00m\n\u001b[1;32m    819\u001b[0m     n_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mcreate_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_function\u001b[39m\u001b[38;5;124m\"\u001b[39m, func, n_args, {})\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:813\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_proxy\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, args, out: Union[SymInt, SymFloat, SymBool]):\n\u001b[1;32m    812\u001b[0m     n_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 813\u001b[0m         get_proxy_slot(a, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer)()\u001b[38;5;241m.\u001b[39mnode \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, py_sym_types) \u001b[38;5;28;01melse\u001b[39;00m a\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args\n\u001b[1;32m    815\u001b[0m     )\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;66;03m# func doesn't have a __torch_function__ that Proxy can interpose, so\u001b[39;00m\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;66;03m# we gotta do it manually\u001b[39;00m\n\u001b[1;32m    819\u001b[0m     n_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mcreate_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_function\u001b[39m\u001b[38;5;124m\"\u001b[39m, func, n_args, {})\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:812\u001b[0m, in \u001b[0;36mProxySymDispatchMode._compute_proxy\u001b[0;34m(self, func, args, out)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_proxy\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, args, out: Union[SymInt, SymFloat, SymBool]):\n\u001b[0;32m--> 812\u001b[0m     n_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    813\u001b[0m         get_proxy_slot(a, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer)()\u001b[38;5;241m.\u001b[39mnode \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, py_sym_types) \u001b[38;5;28;01melse\u001b[39;00m a\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args\n\u001b[1;32m    815\u001b[0m     )\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;66;03m# func doesn't have a __torch_function__ that Proxy can interpose, so\u001b[39;00m\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;66;03m# we gotta do it manually\u001b[39;00m\n\u001b[1;32m    819\u001b[0m     n_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mcreate_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_function\u001b[39m\u001b[38;5;124m\"\u001b[39m, func, n_args, {})\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:813\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_proxy\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, args, out: Union[SymInt, SymFloat, SymBool]):\n\u001b[1;32m    812\u001b[0m     n_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 813\u001b[0m         get_proxy_slot(a, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer)()\u001b[38;5;241m.\u001b[39mnode \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, py_sym_types) \u001b[38;5;28;01melse\u001b[39;00m a\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args\n\u001b[1;32m    815\u001b[0m     )\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;66;03m# func doesn't have a __torch_function__ that Proxy can interpose, so\u001b[39;00m\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;66;03m# we gotta do it manually\u001b[39;00m\n\u001b[1;32m    819\u001b[0m     n_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mcreate_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_function\u001b[39m\u001b[38;5;124m\"\u001b[39m, func, n_args, {})\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/torch/fx/experimental/proxy_tensor.py:215\u001b[0m, in \u001b[0;36mtrack_tensor.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    209\u001b[0m     try_set_proxy_slot(s, \u001b[38;5;28;01mlambda\u001b[39;00m x, i: set_meta(\n\u001b[1;32m    210\u001b[0m         tracer\u001b[38;5;241m.\u001b[39mcreate_proxy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_function\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39maten\u001b[38;5;241m.\u001b[39msym_stride\u001b[38;5;241m.\u001b[39mint, (proxy, i), {}), x), i)\n\u001b[1;32m    212\u001b[0m try_set_proxy_slot(tensor\u001b[38;5;241m.\u001b[39mnumel(), \u001b[38;5;28;01mlambda\u001b[39;00m x: set_meta(\n\u001b[1;32m    213\u001b[0m     tracer\u001b[38;5;241m.\u001b[39mcreate_proxy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_function\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39maten\u001b[38;5;241m.\u001b[39msym_numel\u001b[38;5;241m.\u001b[39mdefault, (proxy,), {}), x))\n\u001b[1;32m    214\u001b[0m try_set_proxy_slot(tensor\u001b[38;5;241m.\u001b[39mstorage_offset(), \u001b[38;5;28;01mlambda\u001b[39;00m x: set_meta(\n\u001b[0;32m--> 215\u001b[0m     tracer\u001b[38;5;241m.\u001b[39mcreate_proxy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_function\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39maten\u001b[38;5;241m.\u001b[39msym_storage_offset\u001b[38;5;241m.\u001b[39mdefault, (proxy,)), x))\n\u001b[1;32m    216\u001b[0m set_proxy_slot(tensor, tracer, _ProxyTensor(proxy, constant))\n",
      "\u001b[0;31mTypeError\u001b[0m: TracerBase.create_proxy() missing 1 required positional argument: 'kwargs'"
     ]
    }
   ],
   "source": [
    "single_sim_run(\n",
    "              feature_type=[{'transcriptome': None}],\n",
    "              use_shared_regions=False,\n",
    "              test_shared_regions=False,\n",
    "              omit_subcortical=False,\n",
    "              parcellation='S400',\n",
    "              hemisphere='both',\n",
    "              connectome_target='FC',\n",
    "              binarize=False,\n",
    "              impute_strategy='mirror_interpolate',\n",
    "              sort_genes='refgenome',\n",
    "              gene_list='0.2',\n",
    "              cv_type='spatial',\n",
    "              random_seed=9,\n",
    "              search_method=('wandb', 'mse', 5),\n",
    "              track_wandb=False,\n",
    "              skip_cv=True,\n",
    "              model_type='shared_transformer',\n",
    "              use_gpu=True, \n",
    "              null_model='none', \n",
    "              use_folds=[0]\n",
    "              )\n",
    "\n",
    "# Clear GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Clear CPU memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf847cd5-e27f-4b43-89a7-4d7baccce7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "main_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
