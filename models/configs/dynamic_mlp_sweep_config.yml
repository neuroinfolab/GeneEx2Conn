method: bayes
metric:
  name: mean_val_loss
  goal: minimize

### TRANSCRIPTOME, 100 parc full brain
parameters:
  input_dim:
    value: !!int 0
  hidden_dims:
    distribution: categorical
    values:
      - [256, 128]
      - [512, 256, 128]
  learning_rate:
    distribution: log_uniform_values
    min: 0.00005
    max: 0.0001
  batch_size:
    distribution: int_uniform
    min: 256
    max: 512
  dropout_rate:
    distribution: uniform
    min: 0.1
    max: 0.3
  weight_decay:
    distribution: log_uniform_values
    min: 0.00005
    max: 0.0005
  epochs:
    distribution: int_uniform
    min: 100
    max: 175

best_parameters: # best 01/28
  hidden_dims:
    values:     
    - [512, 256, 128]
  learning_rate:
    values: [0.0001]
  batch_size:
    values: [256]
  dropout_rate:
    values: [0.15]
  weight_decay:
    values: [0.0001]
  input_dim:
    value: !!int 0
  epochs:
    values: [150]

### EUCLIDEAN, 100 parc full brain
# parameters: 
#   input_dim:
#     value: !!int 0
#   hidden_dims:
#     distribution: categorical
#     values:
#       - [32, 16]
#       - [64, 32]
#       - [128, 64, 32]
#   learning_rate:
#     distribution: log_uniform_values
#     min: 0.00005
#     max: 0.0005
#   batch_size:
#     distribution: int_uniform
#     min: 64
#     max: 256
#   dropout_rate:
#     distribution: uniform
#     min: 0.0
#     max: 0.2
#   weight_decay:
#     distribution: log_uniform_values
#     min: 0.0001
#     max: 0.01
#   epochs:
#     distribution: int_uniform
#     min: 100
#     max: 200

# best_parameters: # best 01/28
#   input_dim:
#     value: !!int 0
#   hidden_dims:
#     values:     
#     - [64, 32]
#   learning_rate:
#     values: [0.0003]
#   batch_size:
#     values: [128]
#   dropout_rate:
#     values: [0.1]
#   weight_decay:
#     values: [0.002]
#   epochs:
#     values: [150]