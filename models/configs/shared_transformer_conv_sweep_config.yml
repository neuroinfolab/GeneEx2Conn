name: shared_transformer_conv
method: random
metric:
  name: mean_val_loss
  goal: minimize

parameters:
  input_dim:
    value: !!int 0
  kernel_size:             # Size of local gene motifs to learn
    values: [16, 32, 64]
  out_channels:           # Number of motif filters
    values: [16, 32]
  stride:                 # Stride between motifs
    values: [16, 32]
  num_tokens:            # Number of positionally relevant tokens
    values: [96, 128, 256]
  d_model:               # Latent dimension
    values: [64, 128]
  use_alibi:
    values: [True]
  nhead:
    values: [4]
  num_layers:
    values: [4]
  deep_hidden_dims:
    values:
      - [256, 128]
      - [512, 256, 128]
  transformer_dropout:
    values: [0.1, 0.2]
  dropout_rate:
    values: [0.1, 0.2]
  learning_rate:
    values: [0.0002, 0.0005]
  weight_decay:
    values: [0.00001, .0]
  batch_size:
    values: [1024]
  aug_prob:
    values: [0, 0.3, 0.45]
  epochs:
    values: [90, 110]
  num_workers:
    values: [2]
  prefetch_factor:
    values: [4]
  
best_parameters:
  input_dim:
    value: !!int 0
  kernel_size:
    values: [32]
  out_channels:
    values: [32]
  stride:
    values: [32]
  num_tokens:
    values: [128]
  d_model:
    values: [128]
  use_alibi:
    values: [True]
  nhead:
    values: [4]
  num_layers:
    values: [4]
  deep_hidden_dims:
    values:
      - [512, 256, 128]
  transformer_dropout:
    values: [0.1]
  dropout_rate:
    values: [0.1]
  learning_rate:
    values: [0.0005]
  weight_decay:
    values: [0.00001]
  batch_size:
    values: [1024]
  aug_prob:
    values: [0.3]
  epochs:
    values: [20]
  num_workers:
    values: [2]
  prefetch_factor:
    values: [4]