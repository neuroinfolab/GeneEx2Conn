{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98363b8f-1d61-429d-865a-3d8213cf3406",
   "metadata": {},
   "source": [
    "## Sim Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83562164-b395-4948-85bd-0cc2a4d2c0e9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25060b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29dd74e-acf1-4701-bb72-ce3701d3d123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "2025-09-16 13:01:48.546844: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-16 13:01:50.426994: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-16 13:01:52.464265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/enigmatoolbox-2.0.3-py3.11.egg/enigmatoolbox/utils/useful.py:10: PendingDeprecationWarning: Importing from numpy.matlib is deprecated since 1.19.0. The matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray. \n",
      "  import numpy.matlib as npm\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/enigmatoolbox-2.0.3-py3.11.egg/enigmatoolbox/plotting/colormaps.py:6: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  autumn = cm.get_cmap('autumn', 256)\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/enigmatoolbox-2.0.3-py3.11.egg/enigmatoolbox/plotting/colormaps.py:8: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  winter = cm.get_cmap('winter_r', 256)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from env.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "566563ca-070f-4671-a98a-338fea600261",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data.data_utils' from '/scratch/kl5565/GeneEx2Conn-master/data/data_utils.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import data\n",
    "\n",
    "import models\n",
    "import sim.sim\n",
    "import sim.sim_utils\n",
    "from sim.sim_utils import bytes2human, print_system_usage\n",
    "from sim.sim import Simulation\n",
    "from sim.sim_run import single_sim_run\n",
    "\n",
    "importlib.reload(sim.sim)\n",
    "importlib.reload(sim.sim_run)\n",
    "importlib.reload(models.train_val)\n",
    "importlib.reload(data.data_utils)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa8bad-5d12-46eb-a39f-18057f3923d7",
   "metadata": {},
   "source": [
    "#### Check job specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b7c8d67-a18c-4208-b20f-8ba13fd58e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage: 2.9%\n",
      "RAM Usage: 8.1%\n",
      "Available RAM: 346.5G\n",
      "Total RAM: 377.1G\n",
      "52.4G\n"
     ]
    }
   ],
   "source": [
    "print_system_usage()\n",
    "\n",
    "total = psutil.disk_usage('/').total\n",
    "print(bytes2human(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e4c0fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Available GPUs: 1\n",
      "GPU 0: Tesla V100-PCIE-32GB - Memory Allocated: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "\n",
    "# Check available GPUs\n",
    "print(f\"Available GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)} - Memory Allocated: {torch.cuda.memory_allocated(i)/1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6a6a997-879a-4f47-97ec-03355acc2b49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost version: 2.0.3\n",
      "cupy version: 13.1.0\n",
      "GPU found 0\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost version:\", xgboost.__version__)\n",
    "print(\"cupy version:\", cp.__version__)\n",
    "\n",
    "GPUtil.getAvailable()\n",
    "\n",
    "# if a number is seen a GPU is available\n",
    "GPUtil.getGPUs()\n",
    "\n",
    "DEVICE_ID_LIST = GPUtil.getFirstAvailable()\n",
    "DEVICE_ID = DEVICE_ID_LIST[0] # grab first element from list\n",
    "if DEVICE_ID != None: \n",
    "    print('GPU found', DEVICE_ID)\n",
    "    use_gpu = True\n",
    "\n",
    "    GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9658fa0e-ab6d-415e-8445-47b1ddfa0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "\n",
    "# Clear GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6495ec",
   "metadata": {},
   "source": [
    "## Simulation tests <a id=\"sims\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f8932-4f1a-4718-aa14-43008697f95a",
   "metadata": {},
   "source": [
    "### Model Parameter Counts\n",
    "\n",
    "#### **Linear Models**\n",
    "- **PCA Bilinear:** 730  _(27 PCs)_\n",
    "- **PLS Bilinear:** 101  _(10 PLS components)_\n",
    "- **Bilinear Low-rank:** 73,800  _(rank 10)_\n",
    "- **PLS MLP:** 158,993  _(10 PLS components, including PLS projection matrices)_\n",
    "- **PCA MLP:** 47,873  _(27 PCs, 2-layer)_\n",
    "\n",
    "---\n",
    "\n",
    "#### **MLP and SMT Models**\n",
    "\n",
    "#### 2-Layer Models\n",
    "- **MLP:** 3,812,609\n",
    "- **SMT:** 1,399,947\n",
    "- **MLP w/ CLS:** 3,814,145\n",
    "- **SMT w/ CLS:** 1,405,579\n",
    "\n",
    "#### 3-Layer Models\n",
    "- **MLP:** 7,723,777\n",
    "- **SMT:** 2,162,315\n",
    "- **MLP w/ CLS:** 7,726,849\n",
    "- **SMT w/ CLS:** 2,173,067\n",
    "\n",
    "---\n",
    "\n",
    "### Coord MLP Parameter Counts\n",
    "- **[32]:** 321\n",
    "- **[64, 32]:** 2,753\n",
    "- **[128, 64]:** 9,601\n",
    "- **[256, 128]:** 35,685\n",
    "- **[512, 256, 128]:** 169,729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "663682e3-77e7-43aa-8556-618bc4693953",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch._dynamo.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8766a4ad-9ed3-4278-a2a8-de6be74db84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components for 95% variance PCA: 27\n",
      "Number of 1s: 36662, Number of 0s: 171274, Class balance (1s): 0.176\n",
      "Number of 1s: 11988, Number of 0s: 195948, Class balance (1s): 0.058\n",
      "X shape: (339, 7380)\n",
      "X_pca shape: (339, 27)\n",
      "X_pca_full shape: (339, 455)\n",
      "X_cell_types_Jorstad shape: (339, 24)\n",
      "X_cell_types_LakeDFC shape: (339, 18)\n",
      "X_cell_types_LakeVIS shape: (339, 18)\n",
      "Y_sc shape: (339, 339)\n",
      "Y_sc_spectralL shape: (339, 399)\n",
      "Y_sc_spectralA shape: (339, 400)\n",
      "Y_fc shape: (339, 339)\n",
      "Coordinates shape: (339, 3)\n",
      "Y shape (339, 339)\n",
      "Network coverage: 100.0% of regions\n",
      "Network sizes: [84, 84, 84, 87]\n",
      "feature_name: transcriptome, processing_type: None\n",
      "features ['transcriptome']\n",
      "Feature matrix, X, generated... expanding to pairwise dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  return LooseVersion(v) >= LooseVersion(check)\n",
      "\n",
      "ERROR: Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkl5565\u001b[0m (\u001b[33mkl5565-new-york-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 36uuvq52\n",
      "Sweep URL: https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52\n",
      "Initialized sweep with ID: 36uuvq52\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4tmxc4h1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbinarize: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchannels: [16, 32, 64]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_hidden: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_dim: 14760\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_sizes: [7, 5, 3]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "ERROR: Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:258: ResourceWarning: unclosed file <_io.TextIOWrapper name='/scratch/kl5565/GeneEx2Conn-master/wandb/sweep-36uuvq52/config-4tmxc4h1.yaml' mode='r' encoding='utf-8'>\n",
      "  self._sweep_config = config_util.dict_from_config_file(\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/ipywidgets/widgets/widget.py:528: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/kl5565/GeneEx2Conn-master/wandb/run-20250916_130405-4tmxc4h1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kl5565-new-york-university/gx2conn/runs/4tmxc4h1' target=\"_blank\">cnn1d_transcriptome_FC_spatial42_fold0_innerCV</a></strong> to <a href='https://wandb.ai/kl5565-new-york-university/gx2conn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kl5565-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kl5565-new-york-university/gx2conn/runs/4tmxc4h1' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn/runs/4tmxc4h1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing inner fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /scratch/kl5565/GeneEx2Conn-master/sim/sim_utils.py:338: ResourceWarning: unclosed <socket.socket fd=72, family=2, type=1, proto=0, laddr=('127.0.0.1', 57018), raddr=('127.0.0.1', 41955)>\n",
      "  gc.collect()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU 0: Tesla V100-PCIE-32GB - Memory Allocated: 0.45 GB\n",
      "Best val loss so far at epoch 1: 0.0483\n",
      "Best val loss so far at epoch 2: 0.0466\n",
      "Best val loss so far at epoch 3: 0.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_train_loss</td><td>█▁▁</td></tr><tr><td>best_val_loss</td><td>█▂▁</td></tr><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>learning_rate</td><td>▁▁▁</td></tr><tr><td>train_batch_loss</td><td>█▃▅▆▂▄▅▆▁▅▅▂▄▄▇</td></tr><tr><td>val_loss</td><td>█▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_train_loss</td><td>0.0268</td></tr><tr><td>best_val_loss</td><td>0.04625</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>learning_rate</td><td>0.0005</td></tr><tr><td>train_batch_loss</td><td>0.02961</td></tr><tr><td>val_loss</td><td>0.04625</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cnn1d_transcriptome_FC_spatial42_fold0_innerCV</strong> at: <a href='https://wandb.ai/kl5565-new-york-university/gx2conn/runs/4tmxc4h1' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn/runs/4tmxc4h1</a><br/> View project at: <a href='https://wandb.ai/kl5565-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250916_130405-4tmxc4h1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 4tmxc4h1 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/scratch/kl5565/GeneEx2Conn-master/sim/sim.py\", line 254, in train_sweep_wrapper\n",
      "    return train_sweep_torch(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/kl5565/GeneEx2Conn-master/sim/sim_utils.py\", line 368, in train_sweep_torch\n",
      "    history = model.fit(dataset, train_indices_expanded, test_indices_expanded)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/kl5565/GeneEx2Conn-master/models/cnn_models.py\", line 172, in fit\n",
      "    return train_model(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/scratch/kl5565/GeneEx2Conn-master/models/train_val.py\", line 55, in train_model\n",
      "    predictions, targets = model.predict(val_loader)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/kl5565/GeneEx2Conn-master/models/cnn_models.py\", line 140, in predict\n",
      "    for batch in loader:\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 673, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "TypeError: 'DataLoader' object is not subscriptable\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 4tmxc4h1 errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/scratch/kl5565/GeneEx2Conn-master/sim/sim.py\", line 254, in train_sweep_wrapper\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return train_sweep_torch(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/scratch/kl5565/GeneEx2Conn-master/sim/sim_utils.py\", line 368, in train_sweep_torch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     history = model.fit(dataset, train_indices_expanded, test_indices_expanded)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/scratch/kl5565/GeneEx2Conn-master/models/cnn_models.py\", line 172, in fit\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return train_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/scratch/kl5565/GeneEx2Conn-master/models/train_val.py\", line 55, in train_model\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     predictions, targets = model.predict(val_loader)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/scratch/kl5565/GeneEx2Conn-master/models/cnn_models.py\", line 140, in predict\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     for batch in loader:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     data = self._next_data()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 673, in _next_data\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ~~~~~~~~~~~~^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: 'DataLoader' object is not subscriptable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mmdard6m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbinarize: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchannels: [16, 32, 64]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_hidden: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_dim: 14760\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_sizes: [7, 5, 3]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:258: ResourceWarning: unclosed file <_io.TextIOWrapper name='/scratch/kl5565/GeneEx2Conn-master/wandb/sweep-36uuvq52/config-mmdard6m.yaml' mode='r' encoding='utf-8'>\n",
      "  self._sweep_config = config_util.dict_from_config_file(\n",
      "\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/ipywidgets/widgets/widget.py:528: DeprecationWarning: The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "  self.comm = Comm(**args)\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/kl5565/GeneEx2Conn-master/wandb/run-20250916_131659-mmdard6m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kl5565-new-york-university/gx2conn/runs/mmdard6m' target=\"_blank\">cnn1d_transcriptome_FC_spatial42_fold0_innerCV</a></strong> to <a href='https://wandb.ai/kl5565-new-york-university/gx2conn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kl5565-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kl5565-new-york-university/gx2conn/runs/mmdard6m' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn/runs/mmdard6m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing inner fold 0\n",
      "Using device: cuda\n",
      "GPU 0: Tesla V100-PCIE-32GB - Memory Allocated: 3.17 GB\n",
      "Best val loss so far at epoch 1: 0.0458\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_train_loss</td><td>█▁▁</td></tr><tr><td>best_val_loss</td><td>▁</td></tr><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>learning_rate</td><td>▁▁▁</td></tr><tr><td>train_batch_loss</td><td>▆█▂▆▆▃▆▃▆▅▃▁▃▅▃</td></tr><tr><td>val_loss</td><td>▁█▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_train_loss</td><td>0.02203</td></tr><tr><td>best_val_loss</td><td>0.04583</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>learning_rate</td><td>0.0005</td></tr><tr><td>train_batch_loss</td><td>0.02148</td></tr><tr><td>val_loss</td><td>0.04604</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cnn1d_transcriptome_FC_spatial42_fold0_innerCV</strong> at: <a href='https://wandb.ai/kl5565-new-york-university/gx2conn/runs/mmdard6m' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn/runs/mmdard6m</a><br/> View project at: <a href='https://wandb.ai/kl5565-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250916_131659-mmdard6m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run mmdard6m errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/scratch/kl5565/GeneEx2Conn-master/sim/sim.py\", line 254, in train_sweep_wrapper\n",
      "    return train_sweep_torch(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/kl5565/GeneEx2Conn-master/sim/sim_utils.py\", line 368, in train_sweep_torch\n",
      "    history = model.fit(dataset, train_indices_expanded, test_indices_expanded)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/kl5565/GeneEx2Conn-master/models/cnn_models.py\", line 172, in fit\n",
      "    return train_model(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/scratch/kl5565/GeneEx2Conn-master/models/train_val.py\", line 55, in train_model\n",
      "    predictions, targets = model.predict(val_loader)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/kl5565/GeneEx2Conn-master/models/cnn_models.py\", line 140, in predict\n",
      "    for batch in loader:\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 673, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "TypeError: 'DataLoader' object is not subscriptable\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run mmdard6m errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/scratch/kl5565/GeneEx2Conn-master/sim/sim.py\", line 254, in train_sweep_wrapper\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return train_sweep_torch(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/scratch/kl5565/GeneEx2Conn-master/sim/sim_utils.py\", line 368, in train_sweep_torch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     history = model.fit(dataset, train_indices_expanded, test_indices_expanded)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/scratch/kl5565/GeneEx2Conn-master/models/cnn_models.py\", line 172, in fit\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return train_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/scratch/kl5565/GeneEx2Conn-master/models/train_val.py\", line 55, in train_model\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     predictions, targets = model.predict(val_loader)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/scratch/kl5565/GeneEx2Conn-master/models/cnn_models.py\", line 140, in predict\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     for batch in loader:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     data = self._next_data()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 673, in _next_data\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ~~~~~~~~~~~~^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: 'DataLoader' object is not subscriptable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n0xdrqai with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbinarize: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchannels: [32, 64, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_hidden: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_dim: 14760\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_sizes: [5, 5, 5]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:258: ResourceWarning: unclosed file <_io.TextIOWrapper name='/scratch/kl5565/GeneEx2Conn-master/wandb/sweep-36uuvq52/config-n0xdrqai.yaml' mode='r' encoding='utf-8'>\n",
      "  self._sweep_config = config_util.dict_from_config_file(\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/kl5565/GeneEx2Conn-master/wandb/run-20250916_133009-n0xdrqai</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kl5565-new-york-university/gx2conn/runs/n0xdrqai' target=\"_blank\">cnn1d_transcriptome_FC_spatial42_fold0_innerCV</a></strong> to <a href='https://wandb.ai/kl5565-new-york-university/gx2conn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kl5565-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kl5565-new-york-university/gx2conn/runs/n0xdrqai' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn/runs/n0xdrqai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing inner fold 0\n",
      "Using device: cuda\n",
      "GPU 0: Tesla V100-PCIE-32GB - Memory Allocated: 8.58 GB\n",
      "Best val loss so far at epoch 1: 0.0463\n",
      "Best val loss so far at epoch 2: 0.0457\n",
      "Best val loss so far at epoch 3: 0.0455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/ipython.py:89: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_train_loss</td><td>█▁▁</td></tr><tr><td>best_val_loss</td><td>█▃▁</td></tr><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>learning_rate</td><td>▁▁▁</td></tr><tr><td>train_batch_loss</td><td>█▇▁▅▆▃</td></tr><tr><td>val_loss</td><td>█▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_train_loss</td><td>0.02627</td></tr><tr><td>best_val_loss</td><td>0.04554</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_batch_loss</td><td>0.02455</td></tr><tr><td>val_loss</td><td>0.04554</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cnn1d_transcriptome_FC_spatial42_fold0_innerCV</strong> at: <a href='https://wandb.ai/kl5565-new-york-university/gx2conn/runs/n0xdrqai' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn/runs/n0xdrqai</a><br/> View project at: <a href='https://wandb.ai/kl5565-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250916_133009-n0xdrqai/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run n0xdrqai errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/scratch/kl5565/GeneEx2Conn-master/sim/sim.py\", line 254, in train_sweep_wrapper\n",
      "    return train_sweep_torch(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/kl5565/GeneEx2Conn-master/sim/sim_utils.py\", line 368, in train_sweep_torch\n",
      "    history = model.fit(dataset, train_indices_expanded, test_indices_expanded)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/kl5565/GeneEx2Conn-master/models/cnn_models.py\", line 172, in fit\n",
      "    return train_model(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/scratch/kl5565/GeneEx2Conn-master/models/train_val.py\", line 55, in train_model\n",
      "    predictions, targets = model.predict(val_loader)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/scratch/kl5565/GeneEx2Conn-master/models/cnn_models.py\", line 140, in predict\n",
      "    for batch in loader:\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 673, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "TypeError: 'DataLoader' object is not subscriptable\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run n0xdrqai errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/scratch/kl5565/GeneEx2Conn-master/sim/sim.py\", line 254, in train_sweep_wrapper\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return train_sweep_torch(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/scratch/kl5565/GeneEx2Conn-master/sim/sim_utils.py\", line 368, in train_sweep_torch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     history = model.fit(dataset, train_indices_expanded, test_indices_expanded)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/scratch/kl5565/GeneEx2Conn-master/models/cnn_models.py\", line 172, in fit\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return train_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/scratch/kl5565/GeneEx2Conn-master/models/train_val.py\", line 55, in train_model\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     predictions, targets = model.predict(val_loader)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/scratch/kl5565/GeneEx2Conn-master/models/cnn_models.py\", line 140, in predict\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     for batch in loader:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     data = self._next_data()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 673, in _next_data\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ~~~~~~~~~~~~^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: 'DataLoader' object is not subscriptable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4gw9t6tn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbinarize: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchannels: [16, 32, 64]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_hidden: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_dim: 14760\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_sizes: [7, 5, 3]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "WARNING: /ext3/miniconda3/lib/python3.11/site-packages/wandb/sdk/wandb_setup.py:258: ResourceWarning: unclosed file <_io.TextIOWrapper name='/scratch/kl5565/GeneEx2Conn-master/wandb/sweep-36uuvq52/config-4gw9t6tn.yaml' mode='r' encoding='utf-8'>\n",
      "  self._sweep_config = config_util.dict_from_config_file(\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6475cd78acab4908a3a021a95884ede1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0111121390428808, max=1.0))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/kl5565/GeneEx2Conn-master/wandb/run-20250916_134635-4gw9t6tn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kl5565-new-york-university/gx2conn/runs/4gw9t6tn' target=\"_blank\">cnn1d_transcriptome_FC_spatial42_fold0_innerCV</a></strong> to <a href='https://wandb.ai/kl5565-new-york-university/gx2conn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kl5565-new-york-university/gx2conn' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn/sweeps/36uuvq52</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kl5565-new-york-university/gx2conn/runs/4gw9t6tn' target=\"_blank\">https://wandb.ai/kl5565-new-york-university/gx2conn/runs/4gw9t6tn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing inner fold 0\n",
      "Using device: cuda\n",
      "GPU 0: Tesla V100-PCIE-32GB - Memory Allocated: 13.99 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#cnn\n",
    "single_sim_run(\n",
    "    dataset='HCP',\n",
    "    cv_type='spatial',\n",
    "    random_seed=42,\n",
    "    model_type='cnn1d',                 # ← 使用你的 CNN\n",
    "    use_gpu=True,\n",
    "    feature_type=[{'transcriptome': None}],  # 先用最简单特征\n",
    "    connectome_target='FC',\n",
    "    omit_subcortical=True, parcellation='S456', hemisphere='both',\n",
    "    gene_list='0.2',\n",
    "    search_method=('wandb','mse',10),\n",
    "    track_wandb=True,\n",
    "    skip_cv=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e41fd6-d272-4b02-9fc3-3984541973b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KERNEL_DISPLAY_NAME",
   "language": "python",
   "name": "geneex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
